\section{Preliminaries} \label{section_preliminaries}
In this section, we introduce the basic notions used throughout the paper.

Let $\Sigma$ be a finite set of edge labels. Define an \textit{edge-labeled directed graph} as a tuple $D = (V, E)$ with a set of nodes $V$ and a directed edge-relation $E \subseteq V \times \Sigma \times V$.  For a path $\pi$ in a graph $D$ we denote the unique word obtained by concatenating the labels of the edges along the path $\pi$ as $l(\pi)$. Also, we write $n \pi m$ to indicate that a path $\pi$ starts at node $n \in V$ and ends at node $m \in V$.

Similar to Hellings~\cite{hellingsRelational}, we deviate from the usual definition of a context-free grammar in \textit{Chomsky Normal Form}~\cite{chomsky} by not including a special start non-terminal, which will be specified in the path queries to the graph. Since every context-free grammar can be transformed into an equivalent one in Chomsky Normal Form and checking that an empty string is in the language is trivial, then it is sufficient to only consider grammars of the following type. A \textit{context-free grammar} is 3-tuple $G = (N, \Sigma, P)$ where $N$ is a finite set of non-terminals, $\Sigma$ is a finite set of terminals, and $P$ is a finite set of productions of the following forms:

\begin{itemize}
    \item $A \rightarrow B C$, for $A,B,C \in N$,
    \item $A \rightarrow x$, for $A \in N$ and $x \in \Sigma$.   
\end{itemize}

Note that we omit the rules of the form $A \rightarrow \varepsilon$, where $\varepsilon$ denotes an empty string. This does not limit the applicability of further algorithms because only the empty paths $m \pi m$ correspond to an empty string $\varepsilon$.

We use the conventional notation $A \xrightarrow{*} w$ to denote that the string $w \in \Sigma^*$ can be derived from a non-terminal $A$ by some sequence of applications of the production rules from $P$. The \textit{language} of a grammar $G = (N,\Sigma,P)$ with respect to a start non-terminal $S \in N$ is defined by $L(G_S) = \{w \in \Sigma^*~|~S \xrightarrow{*} w\}$.

For a given graph $D = (V, E)$ and a context-free grammar $G = (N, \Sigma, P)$, we define \textit{context-free relations} $R_A \subseteq V \times V$, for every $A \in N$, such that $R_A = \{(n,m)~|~\exists n \pi m~(l(\pi) \in L(G_A))\}$.

We define a binary operation on arbitrary subsets $N_1 , N_2$ of $N$ with respect to a context-free grammar $G = (N, \Sigma, P)$ as $N_1 \cdot N_2 = \{A~|~\exists B \in N_1, \exists C \in N_2 \text{ such that }(A \rightarrow B C) \in P\}.$

Using this binary operation as a multiplication on arbitrary subsets of $N$ and union of sets as an addition, we can define a \textit{matrix multiplication}, $a \cdot b = c$, where $a$ and $b$ are matrices of the suitable size that have subsets of $N$ as elements, as $c_{i,j} = \bigcup^{n}_{k=1}{a_{i,k} \cdot b_{k,j}}$.

According to Valiant~\cite{valiant}, we define the \textit{transitive closure} of a square matrix $a$ as $a^+ = a^{(1)}_+ \cup a^{(2)}_+ \cup \cdots$ where $a^{(i)}_+ = \bigcup^{i-1}_{j=1}{a^{(j)}_+ \cdot a^{(i-j)}_+}$, $i \ge 2$ and $a^{(1)}_+ = a$. Valiant proposes the algorithm for computing this transitive closure but only for upper triangular matrices. In the case of graphs, matrices can be arbitrary. For this reason, we introduce an algorithm for computing the transitive closure of an arbitrary square matrix.

For convenience of further reasoning, we introduce another definition of the transitive closure of a square matrix $a$ as $a^{cf} = a^{(1)} \cup a^{(2)} \cup \cdots$ where $a^{(i)} = a^{(i-1)} \cup (a^{(i-1)} \cdot a^{(i-1)})$, $i \ge 2$ and $a^{(1)} = a$.

To show the equivalence of these two definitions of the transitive closure, we introduce the partial order $\succeq$ on matrices with fixed size that have subsets of $N$ as elements. For square matrices $a, b$ of the same size we denote $a \succeq b$ iff $a_{i,j} \supseteq b_{i,j}$, for every $i, j$.

\begin{lemma}\label{lemma:cf_geq_valiant}
	Let $G =(N,\Sigma,P)$ be a grammar, let $a$ be a square matrix. Then $a^{(k)} \succeq a^{(k)}_+$, for any $k \geq 1$.
\end{lemma}
\begin{proof}(Proof by Induction)
	
	\textbf{Basis}: Since $a^{(1)} = a^{(1)}_+ = a$, then the statement of the lemma holds for $k = 1$.
	
	\textbf{Inductive step}: Assume that the statement of the lemma holds for any $k \leq (p - 1)$ and show that it also holds for $k = p$ where $p \geq 2$. Since $a^{(i)} = a^{(i-1)} \cup (a^{(i-1)} \cdot a^{(i-1)})$, then $a^{(i)} \succeq a^{(i-1)}$, for any $i \geq 2$. Hence, by the inductive hypothesis, $a^{(p-1)} \succeq a^{(i)} \succeq a^{(i)}_+$, for any $i \leq (p-1)$. Let $1 \leq j \leq (p - 1)$. Since $a^{(p-1)} \succeq a^{(j)}_+$ and $a^{(p-1)} \succeq a^{(p-j)}_+$, then $(a^{(p-1)} \cdot a^{(p-1)}) \succeq (a^{(j)}_+ \cdot a^{(p-j)}_+)$. By the definition, $a^{(p)}_+ = \bigcup^{p-1}_{j=1}{a^{(j)}_+ \cdot a^{(p-j)}_+}$ and from this it follows that $(a^{(p-1)} \cdot a^{(p-1)}) \succeq a^{(p)}_+$. Since $a^{(p)} = a^{(p-1)} \cup (a^{(p-1)} \cdot a^{(p-1)})$, then $a^{(p)} \succeq (a^{(p-1)} \cdot a^{(p-1)}) \succeq a^{(p)}_+$ and this completes the proof of the lemma.
\end{proof}

\begin{lemma}\label{lemma:valiant_geq_cf}
	Let $G =(N,\Sigma,P)$ be a grammar, let $a$ be a square matrix. Then for any $k \geq 1$ there is $j \geq 1$, such that $(\bigcup^{j}_{i=1}{a^{(i)}_+}) \succeq a^{(k)}$.
\end{lemma}
\begin{proof}(Proof by Induction)
	
	\textbf{Basis}: For $k = 1$ there is $j = 1$, such that $a^{(1)}_+ = a^{(1)} = a$. Thus, the statement of the lemma holds for $k = 1$.
	
	\textbf{Inductive step}: Assume that the statement of the lemma holds for any $k \leq (p - 1)$ and show that it also holds for $k = p$ where $p \geq 2$. By the inductive hypothesis, there is $j \geq 1$, such that $(\bigcup^{j}_{i=1}{a^{(i)}_+}) \succeq a^{(p-1)}$. By the definition, $a^{(2j)}_+ = \bigcup^{2j-1}_{i=1}{a^{(i)}_+ \cdot a^{(2j-i)}_+}$ and from this it follows that $(\bigcup^{2j}_{i=1}{a^{(i)}_+}) \succeq (\bigcup^{j}_{i=1}{a^{(i)}_+}) \cdot (\bigcup^{j}_{i=1}{a^{(i)}_+}) \succeq (a^{(p-1)} \cdot a^{(p-1)})$. Since $(\bigcup^{2j}_{i=1}{a^{(i)}_+}) \succeq (\bigcup^{j}_{i=1}{a^{(i)}_+}) \succeq a^{(p-1)}$ and $(\bigcup^{2j}_{i=1}{a^{(i)}_+}) \succeq (a^{(p-1)} \cdot a^{(p-1)})$, then $(\bigcup^{2j}_{i=1}{a^{(i)}_+}) \succeq a^{(p)} = a^{(p-1)} \cup (a^{(p-1)} \cdot a^{(p-1)})$. Therefore there is $2j$, such that $(\bigcup^{2j}_{i=1}{a^{(i)}_+}) \succeq a^{(p)}$ and this completes the proof of the lemma.	
\end{proof}

\begin{mytheorem}\label{thm:closures}
	Let $G =(N,\Sigma,P)$ be a grammar, let $a$ be a square matrix. Then $a^+ = a^{cf}$.
\end{mytheorem}
\begin{proof}
	
	By the lemma~\ref{lemma:cf_geq_valiant}, for any $k \geq 1$, $a^{(k)} \succeq a^{(k)}_+$. Therefore $a^{cf} = a^{(1)} \cup a^{(2)} \cup \cdots \succeq a^{(1)}_+ \cup a^{(2)}_+ \cup \cdots = a^+$. By the lemma~\ref{lemma:valiant_geq_cf}, for any $k \geq 1$ there is $j \geq 1$, such that $(\bigcup^{j}_{i=1}{a^{(i)}_+}) \succeq a^{(k)}$. Hence $a^+ = (\bigcup^{\infty}_{i=1}{a^{(i)}_+}) \succeq a^{(k)}$, for any $k \geq 1$. Therefore $a^+ \succeq a^{(1)} \cup a^{(2)} \cup \cdots = a^{cf}$. Since $a^{cf} \succeq a^+$ and $a^+ \succeq a^{cf}$, then $a^+ = a^{cf}$ and this completes the proof of the theorem.
\end{proof}

Further, in this paper, we use the transitive closure $a^{cf}$ instead of $a^+$ and, by the theorem~\ref{thm:closures}, algorithm for computing $a^{cf}$ also computes Valiant's transitive closure $a^+$.
\section{Bar-Hillel Theorem Mechanization in Coq}

%TODO
%What did you do and how. And, possible, why. Problems, nontrivial solutions, stc.

In this section we describe in detail all the fundamental parts of the proof. Also in this section, we briefly describe motivation to use the chosen definitions. In addition, we discuss the advantages and disadvantages of using of third-party proofs. 

Overall goal of this section is to provide step-by-step algorithm of constructing the CNF grammar of the intersection of two languages. Final formulation of the obtained theorem can be found in the last subsection. 

All code are published on GitHub~\footnote{\url{https://github.com/YaccConstructor/YC\_in\_Coq}}.
   
\subsection{ Smolka's code generalization}

In this section, we describe the exact steps taken to use the proof of TODO:Smolka's theorem in the proof of this article's theorem.

A substantial part of this proof relies on the work of TODO:Smolka. From this work(,?) many definitions and theorems were taken. Namely, the definition of a grammar, definitions of a derivation in grammar, some auxiliary lemmas about the decidability of properties of grammar/derivation, we also use the theorem that states that there always exists the transformation from context-free grammar to grammar in Chomsky Normal Form (CNF).

However, this proof had one major flaw that we needed to fix. One could define a terminal symbol as in inductive type over natural numbers[TODO].

\begin{listing}[h]
	\begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Inductive ter : Type := | T : nat -> ter.
	\end{pyglist}
	\caption{TODO}
	\label{lst:verbments1}
\end{listing}

That is how it was done in TODO:Smolka. However for purposes of our proof, we need to consider nonterminals over the alphabet of triples. Therefore, it was decided to add polymorphism over the target alphabet. Namely, let $Tt$ and $Vt$ be types with decidable relation of equality, then we can define the types of terminal and nonterminal over alphabets $Tt$ and $Vt$ respectively as follows (???):

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Inductive ter : Type := | T : Tt -> ter.
  Inductive var : Type := | V : Vt -> var.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

The proof of Smolka has a clear structure, therefore only part of the proof where the use of natural numbers was essential has become incorrect. One of the grammar transformations (namely deletion of long rules) requires the creation of many new non-terminals. In the original proof for this purpose, the maximum over non-terminals included in the grammar was used. However, it is impossible for an arbitrary type.

To tackle this problem we introduce an additional assumption on alphabet types for terminals and nonterminals. We require an existence of the bijection between natural numbers and alphabet of terminals as well as nonterminals.

Another difficulty is that the original work defines grammar as a list of rules (without a distinct starting nonterminal). Thus, in order to define the language that is defined by a  grammar, one needs to specify the grammar and a starting terminal. This leads to the fact that the theorem about the equivalence of a CF grammar and the corresponding CNF grammar isn't formulated in the most general way, namely it guarantees equivalence only for non-empty words. 

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Lemma language_normal_form 
      (G:grammar) (A: var) (u: word):
    u <> [] -> 
    (language G A u <-> 
       language (normalize G) A u).
    \end{pyglist}
    \caption{TODO, CHECK}
    \label{lst:verbments1}
\end{listing}

Changes in the definition of grammar or language would lead to significant code corrections. However, the question of whether the empty word is derivable is decidable for both the CF grammar and the DFA. Therefore, it is possible to simply consider two cases (1) when the empty word is derivable in the grammar and (2) when the empty word is not derivable.

\subsection{Part ..: derivation and so on}

In this section, we introduce the basic definitions used in the article.

We define a symbol is either a terminal or a nonterminal.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Inductive symbol : Type :=
    | Ts : ter -> symbol
    | Vs : var -> symbol.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

Next we define a word and a phrase as lists of terminals and symbols respectively. 

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Definition word := list ter.
  Definition phrase := list symbol.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

The notion of nonterminal doesn't make sense for DFA, but in order to construct derivation in grammar we need to use nonterminal in intermediate states. For phrases, we introduce a predicate that defines whenever a phrase consists of only terminals. And if so, the phrase it can be safely converted to the corresponding word.

We inheriting the definition of CFG from [Smplka] paper. Rule is defined as a pair of a nonterminal and a list of symbols. Grammar is a list of rules. 

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Inductive rule : Type :=
  | R : var -> phrase -> rule.
        
  Definition grammar := list rule.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

An important step towards the definition of a language (?) governed (formed?)(?!) by a grammar is the definition of derivability. Having $der(G, A, p)$ --- means that phrase $p$ is derivable in grammar $G$ starting from(?) nonterminal $A$.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Inductive der (G : grammar) 
        (A : var) : phrase -> Prop :=
  | vDer : der G A [Vs A]
  | rDer l : (R A l) el G -> der G A l
  | replN B u w v : 
      der G A (u ++ [Vs B] ++ w) -> 
      der G B v -> der G A (u ++ v ++ w).
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

Proof of TODO requires grammar to be in CNF. We used statement that every grammar in convertible into CNF from TODO:Smolka work.

... ... ... ... 

\subsection{General scheme of the proof}

General scheme of our proof is based on constructive proof presented by ~\cite{!!!}. In the following subsections the main steps of the proof are presented. Overall, we will adhere to the following plan. 

\begin{enumerate}
    \item First we consider trivial case, when DFA has no state (TODO: del this?)
    \item Every CF language can be converted to CNF
    \item Every DFA can be presented as an union of DFAs with single final state
    \item Intersecting grammar in CNF with DFA with one final state
    \item Proving than union of CF languages is CF language
\end{enumerate}

\subsection{Part one: trivial case}

% TODO: нужно написать, что мы всё таки используем конечный тип для состояний автомата. 
% Сперва мы рассматриваем случай, когда у автомата нет ни одного состояния, то есть, число состояний == 0. В этом случае мы можем сразу вывести противоречие, так как по определению, у автомата есть начальное состояние. Что значит, что есть по крайней мере одно состояние, что противоречит тому, что n = 0.

(TODO: del?)

\subsection{Part two: regular language and automata}

In this section we describe definitions of DFA and DFA with exactly one final state, we also present function that converts any DFA to a set of DFA with one final state and lemma that states this split is well-defined(?).

We assume that regular language by definition is described by DFA. As the definition of an DFA, we have chosen a general definition, which does not impose any restrictions on the type of input symbols and the number of states. Thus, in our case, the DFA is a 5-tuple, (1) a state type, (2) a type of input symbols, (3) a start state, (4) a transition function, and (5) a list of final states.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Context {State T: Type}.
  Record dfa: Type :=
    mkDfa {
      start: State;
      final: list State;
      next: State -> (@ter T) -> State;
    }.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

Next we define a function that would evaluate the final state of the automaton if it starts from state $s$ and receives a word $w$. 

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Fixpoint final_state 
             (next_d: dfa_rule) 
             (s: State) 
             (w: word): State :=
    match w with
    | nil => s 
    | h :: t => final_state next_d 
                            (next_d s h)
                            t 
    end.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

We say that the automaton accepts a word $w$ being in state $s$ if the function $[final\_state \_ s w]$ ends in one of the final states. Finally, we say that an automaton accepts a word $w$, if the DFA starts from the initial state and ends in one of the final states.

%CODE
%Definition accepts (d : dfa) (s: State) (w: word) : Prop :=
%In (final_state (next d) s w) (final d). 

%CODE
%Definition dfa_language (d : dfa) := (accepts d (start d)).

In order to define the DFA with exactly one final state, it is necessary to replace the list of final states by one final state in the definition of an(?) ordinary DFA. The definitions of "accepts" and "dfa\_language" vary slightly.

%Alternative: In the proof we need a subset (subtype?) of all automata. Namely, automata with one finite state. We can define them as follows. We say that dfa is a single-final-state-automata, if and only if the predicate "is final state?" can be represented as "is equal to the state fin?"

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Record s_dfa : Type :=
    s_mkDfa {
      s_start: State;
      s_final: State;
      s_next: State -> (@ter T) -> State;
  }.      
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}
  
Similarly, we can define functions $s\_accepts$ and $s\_dfa\_language$ for sDFA. Since in this case, there is only one final state, to define function $s\_accepts$ it is enough to check the state in which the automaton stopped with the finite state. The function $s\_dfa\_language$ repeats the function $dfa\_language$, except that the function must use $s\_accepts$ instead of accepts.

%CODE
%Definition s_accepts (d : s_dfa) (s: State) (w: word) : Prop :=
%(final_state (s_next d) s w) = (s_final d).

%CODE
%Definition s_dfa_language (d : s_dfa) := (s_accepts d (s_start d)).

Now we canto define a function that converts an ordinary DFA into a set of DFAs with exactly one final state.
Let d be a dfa. Then the list of its final states is known. For each such state, one can construct a copy of the original dfa, but with one current final state.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Fixpoint split_dfa_list 
      (st_d : State) 
      (next_d : dfa_rule) 
      (f_list : list State): list (s_dfa) :=
    match f_list with
    | nil => nil
    | h :: t => (s_mkDfa st_d h next_d) 
                :: split_dfa_list st_d next_d t
    end.    
 
 Definition split_dfa (d: dfa) := 
   split_dfa_list (start d) (next d) (final d).
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}


% CODE
% Definition single_final_state_dfa (d: dfa)(fin: dfa_state) := dfa_fin dfa = pred1 fin.


% d DFA accepts word iff after transitions is comes to one of ist final states

% CODE
%Fixpoint dfa\_final x w :=
%match w with
%| [::] => x
%| a::w => dfa\_final (dfa\_step A x a) w
%end.

%Definition dfa\_accept x w := dfa\_fin (dfa\_final st word).

%It is easy to see that if our automaton is an automata with one final state fin, then dfa\_accept x w  is equivalent to dfa\_final x w = fin

%Regular language is a set words accepted by DFA.

%Definition dfa\_language (d : dfa):= fun word =>accepts d start word.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Lemma correct_split:
    forall dfa w,
      dfa_language dfa w <->
      exists sdfa, 
         In sdfa (split_dfa dfa) /\ 
         s_dfa_language sdfa w.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

We prove theorem that the function of splitting preserves the language.

\begin{theorem}
  Let $dfa$ be an arbitrary dfa and $w$ be a word. Then the fact that $dfa$ accepts $w$ implies that there exists a single-state dfa $s\_dfa$, such that $s_dfa \in split\_dfa(dfa)$. And vice versa, For any $s\_dfa \in split\_dfa(dfa)$ the fact that $s\_dfa$ accepts a word $w$ implies that $dfa$ also accepts $w$.
\end{theorem}

\textbf{Proof.}
Let us divide the proof into two parts.
(1) Suppose $dfa$ accepts $w$. Then we prove that there exists a single-state dfa $s\_dfa$, such that $s\_dfa \in split\_dfa(dfa)$. 
Let $finals$ be the set of final states of $dfa$. We carry out the proof by induction on $finals$. 
\textit{\underline{Base step}}: $finals = [::]$. Trivial by contradiction (DFA with no final state cannot accept a word). \textit{\underline{Induction step}}: $finals = a::old\_finals$ and the statement holds for $old\_finals$. Since $dfa$ accepts $w$, it either ends up in $a$, or in one of the state from $old\_finals$.
If $dfa$ is ends up in $a$, then we simply choose an automaton with the final state that is equal to $a$. Such an automaton exists, since now the list of final states also contains $a$. On the other hand, if $dfa$ is ends up in one of the state from $old\_finals$, then we can apply induction hypothesis. \\
(2) Similarly for the opposite direction. Assume that there exists an automaton with exactly one final state from \textit{split\_dfa(dfa)} that accepts $w$. Then we prove that \textit{dfa} also accepts $w$. 
Let $finals$ be the set of final states of $dfa$. We carry out the proof by induction on $finals$. 
\textit{\underline{Base step}}: $finals = [::]$. Trivial by contradiction. \textit{\underline{Induction step}}: $finals = a::old\_finals$ and the statement holds for $old\_finals$. We know that one of the DFAs form $split\_dfa(dfa)$ accepts $w$, its final state either is equal to $a$, or lies in $old\_finals$.
If the final state is equal to $a$, then $dfa$ also ends up in state $a$.  On the other hand, if final state lies in $old\_finals$, then we can apply induction hypothesis.


\subsection{Part ..: Chomsky induction}

In this section, we introduce the notion of Chomsky induction.

Naturally many statements about properties of language's words can be proved by induction over derivation structure. Unfortunately, grammar can derive phrase us an intermediate step, but DFA supposed to work only with words, so we can’t simply apply induction over derivation structure. To tackle this problem we create custom induction principle for grammars in CNF.

As one might notice, TODO
%TODO
% Понятно, что для доказательства этой теоремы, нам нужно было сделать шаг "назад" по выводу, что, однако, невозможно с текущим определением вывода. 

% Поэтому, пришлось добавить следующую гипотезу. Basically is says that 

%Definition syntactic_analysis_is_possible :=
%  forall {T V: Type} (G: @grammar T V) (A: var) (l: phrase),
%  der G A l ->
%  (R A l el G) \/ (exists rhs, R A rhs el G /\ derf G rhs l).


The main point is that if we have a grammar in CNF, we can always divide the word into two parts, each of which is derived only from one nonterminal. Note that if we naively take a step back, we can get nonterminal in the middle of the word. Such a situation will not make any sense for DFA.

With induction we always work with subtrees that describes some part of word. Here is a picture of subtree describing intuition behind the Chomsky induction. \\
TODO: add picture\\ 
TODO: add Lemma derivability\_backward\_step.


(TODO: lemma)
More formally: 
Let $G$ be a grammar in CNF. Consider an arbitrary nonterminal $N \in G$ and phrase which consists only on terminals $w$. 
If $w$ is derivable from $N$ and $|w| \ge 2$, then there exist(TODO:s) two nonterminals $N_1, N_2$ and subphrases of $w$ --- $w_1, w_2$ such that: $N \to N_1 N_2 \in G$, $der(N_1, w_1)$, $der(N_2, w_2)$, $|w_1| \ge 1$, $|w_2| \ge 1$ and $w_1 ++ w_2 = w$.

(TODO: fix)
\textbf{Proof.}
The proof heavily uses the fact that grammar $G$ is in Chomsky Normal Form.
We apply the hypothesis "syntactic analysis is possible ". After application, we get the fact that word $w$ is either an RHS of a rule of grammar $G$, or there is a phrase $phr$, such that (1) word $w$ is derivable from phrase $phr$ and (2) there exists a non-terminal $N$ such that $N -> prh in G$.
The first case we finish with the proof by contradiction since the grammar is in CNF and there might be only a single terminal in an RHS (by assumption we have |w| >= 2).
On the other hand, if there is an intermediate phrase that was obtained by applying a rule, then the phrase has form $N_1 N_2$, since it also derived by rule in normal form.
Finally, now we need to prove that both of this nonterminals has a non-empty contribution to word w. This is also true since it is impossible to derive empty word in CNF grammar (see ...).

(TODO: lemma)
Let $G$ be a grammar in CNF. And $P$ be a predicate on nonterminals and phrases (i.e. $P: var \to phrase \to Prop$).
Let's also assume that the following two hypotheses are satisfied:
(1) for every terminal production (i.e. in the form $N \to a$) of grammar $G$, $P(r, [Ts r])$ holds and (2) for every $N, N_1, N_2 \in G$ and two phrases that consist only of terminals $w_1, w_2$, if $P(N_1, w_1)$, $P(N_2, w_2)$, $der(G, N_1, w_1)$ and $der(G, N_2, w_2)$ then $P(N, w_1 ++ w_2)$.
Then for any nonterminal $N$ and any phrase consisting only of terminals $w$, the fact that $w$ is derivable from $N$ implies $P(N,w)$.

(TODO: fix)
\textbf{Proof.} 
Let $n$ be an upper bound of the length of word $w$. We carry out the proof by induction on $n$. 
Base case: $ n = 0 $. Proof by contradiction. $|w| \le 0$ implies that $w$ is empty. But an empty word cannot be derived in CNF grammar (see ...).
Induction step: $|w| \le n+1$. This fact is equivalent to the following:  $|w| = n+1$ or $|w| < n$. 
In case of $|w| < n$ we use the induction hypothesis.
Next we consider two new cases, either $|w| = 1 $, or $1 < |w| = n + 1$.
In the first case, it is clear that this is possible only if there is a production $N -> w$, which means you can apply assumption (1).
If the word is longer than 1, then we apply the previous lemma, after that we can conclude that $\exists w1 w2, w = w1 ++ w2$. After that,
one need to apply assumption (2). We subgoals that are guaranteed by the lemma .... And for shorter words, we apply the induction hypothesis.

%CODE
%Hypothesis inductive_step_1:
%  forall (r : _) (t : ter),
%  R r [Ts t] el G ->
%  P r [Ts t].


%CODE
%Hypothesis inductive_step_2:
%  forall (r r1 r2: _) (w1 w2 : phrase),
%  R r [Vs r1; Vs r2] el G ->
%  P r1 w1 ->
%  P r2 w2 ->
%  terminal w1 ->
%  terminal w2 ->
%  der G r1 w1 ->
%  der G r2 w2 ->
%  P r (w1 ++ w2).


%CODE
%Lemma chomsky_derivability_induction:
%  forall (r : _) (w : _),
%  @der T V G r w ->
%  terminal w ->
%  P r w.


TODO: add some text



\subsection{Part ..: intersection}

Since we already have lemmas about the transformation of a grammar to CNF and the transformation a DFA to a DFA with exactly one state, further we assume that we have (1) DFA with exactly one final state --- $dfa$ and (2) grammar in CNF --- $G$. In this section, we describe the proof of the lemma that states that for any grammar in CNF and any automaton with exactly one state there is the intersection grammar.

\subsubsection{Function }

Next we present adaptation of the algorithm given in $[ ]$. 

Let $G_{INT}$ be the grammar of intersection. In $G_{INT}$ nonterminals presented as triples $(from \times var \times to) $ where $from$ and $to$ are states of $dfa$, and $var$ is a nonterminal of(in?) $G$.

Since $G$ is a grammar in CNF, it has only two type of productions: $(1)\ N \to a $ and $(2) \ N \to N_{1} N_{2}$, where $N, N_1, N_2$ are nonterminals and $a$ is a terminal.

For every production $N \to N_1 N_2$ in $G$ we generate a set of productions of the form $(from, N, to) \to (from, N_1,  m) (m, N_2, to)$ where: $from$, $m$, $to$ --- goes through all $dfa$ states.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Definition convert_nonterm_rule_2 
    (r r1 r2: _) 
    (state1 state2 : _) :=
    map (fun s3 => R (V (s1, r, s3)) 
                     [Vs (V (s1, r1, s2)); 
                      Vs (V (s2, r2, s3))])
      list_of_states.

  Definition convert_nonterm_rule_1  
               (r r1 r2: _) 
               (s1 : _) :=
    flat_map (convert_nonterm_rule_2 r r1 r2 s1) 
             list_of_states.

  Definition convert_nonterm_rule (r r1 r2: _) :=
    flat_map (convert_nonterm_rule_1 r r1 r2) 
             list_of_states.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

For every production of the form $N \to a$ we add a set of productions $(from, N, (dfa\_step(from, a))) \to a$ where: $from$ --- goes through all $dfa$ states and $dfa\_step (from, a)$ is the state in which the $dfa$ appears after receiving terminal $a$ in state $from$.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Definition convert_terminal_rule 
              (next: _) 
              (r: _) 
              (t: _): list TripleRule :=
    map (fun s1 => R (V (s1, r, next s1 t)) 
	               [Ts t]) 
        list_of_states.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

Next we join the functions above to get a generic function that works for both types of productions. Note that since the grammar is in CNF,(?) the third alternative can never be the case.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Definition convert_rule (next: _) (r: _ ) :=
    match r with
    | R r [Vs r1; Vs r2] => 
        convert_nonterm_rule r r1 r2
    | R r [Ts t] => 
        convert_terminal_rule next r t 
    | _  => []   (* Never called *)
    end.
        
  Definition convert_rules 
    (rules: list rule) (next: _): list rule :=
    flat_map (convert_rule next) rules.
    
  (* Maps grammar and s_dfa to grammar over triples *)
  Definition convert_grammar grammar s_dfa :=
    convert_rules grammar (s_next s_dfa). 
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

Note that at this point we do not have any manipulations with starting rules. Nevertheless(?), the hypothesis of the uniqueness of the final state of the DFA, will help us unambiguously introduce the starting nonterminal of the grammar of intersection.

\subsubsection{Correctness}

In this subsection we present a high-level description of the proof about correctness of the intersection function.

In the interest of clarity of exposition, we skip some auxiliary lemmas, such as (TODO:fix) "we can get the initial grammar from the grammar of intersection by projecting the triples back to terminals/nonterminals ". Also note that the grammar after the conversion remains in CFN. Since the transformation of rules does not change the structure of the rules, but only replaces one(??!!) terminals and nonterminals with others.


% NOTE: skipped
% Во-первых, мы доказываем, что функция ведёт себя так, как задумано
% то есть, сперва все, что мы хотим оказывается там где надо. 
% И наоборот, функция возвращает только то, что нам нужно

% forward_terminal_rule_inclusion
% forward_nonterminal_rule_inclusion
% backward_rule_inclusion
% backward_terminal_rule_inclusion
% backward_nonterminal_rule_inclusion
% remains_chomsky:
% consistensy_of_triple_nonterm_rules
% consistensy_of_triple_term_rules



% ADD
% The starting nonterminal for the intersection grammar is the following nonterminal: (start, S, final). Where: start -- the start state of DFA, S -- the start symbol of initial grammar, and final -- the final state of DFA. 



% CHECK a/the
Next we prove the two main lemmas. Namely, the derivability in the initial grammar and the $s\_dfa$ implies the derivability in the grammar of intersection. And the other way around, the derivability in the grammar of intersection implies the derivability in the initial grammar and the $s\_dfa$.

% CHECK
Let $G$ be a grammar in CNF. In order to use Chomsky Induction we also assume that syntactic analysis is possible. 

% ADD?: der_in_initial_grammar_and_dfa_implies_der_in_triple_grammar
% Theorem der_in_initial_grammar_and_dfa_implies_der_in_triple_grammar:
%   forall (next: dfa_rule) (r: var) (from to: DfaState) (word: _),
%     der G r (to_phrase word) ->
%     final_state next from word = to ->
%     der (convert_rules G next) (V (from, r, to)) (to_phrase word).
\begin{theorem}
    Let $s\_dfa$ be an arbitrary DFA, let r be a nonterminal of grammar G, let from and to be two states of the DFA. We also pick an arbitrary word --- w. If in grammar G it is possible to derive w out of r and starting from the state from when w is received, the s\_dfa ends up in state to, then word w is also derivable in grammar (convert\_rules G next) from the nonterminal (V (from, r, to)).
\end{theorem}
% Если в грамматике из нетерминала r можно вывести слово word и стартуя из состояния from при принятии слова word автомат оказывается в состоянии to, тогда слово word также выводится и в грамматике (convert_rules G next) из нетерминала (V (from, r, to)). 

\textbf{Proof.} TODO.
In another case, it would be logical to use induction on the derivation structure in $G$. But as it was discussed earlier, this is not the case, otherwise we will get a phrase (list of terminals and nonterminals) instead of a word. 
Let's apply chomsky induction principle with 
\begin{align*}
  P := fun r phr => \forall (next : dfa\_rule) (from to : DfaState), \\
           final\_state next from (to_word phr) = to -> \\
            der (convert\_rules G next) (V (from, r, to)) phr.
\end{align*}
We will get the bla-bla, bla-bla, bla-bla-bla         



% ADD: main_forward
Since a language is just a bla-bla-bla, we use the lemma above to prove bla-bla-bla



% ADD: der_in_triple_grammar_implies_dfa_accepts
% ADD: der_in_triple_gr_implies_der_in_initial_gr

% ADD: main_backward


%5.4 Intersecting DFA with one final state with grammar in CNF:
%Now we providing construction for intersection grammar in CNF with DFA. Further we name G_0 - original grammar. G_n - grammar for intersection. In G_n nonterminals presented as triples (from * n * to) where ‘from’ and ‘to’ are states of DFA, and n - is nonterminal in G_0.

%Algorithm
%Grammar in CNF has only two type of rules:
%N -> a
%N -> N_1 N_2

%For which we have simple procedures of conversion.
%For every rule S -> a
%we add rules (from  S  (dfa_step from a)) -> a where: ‘from’ - goes through all DFA states, and (dfa_step from a) - is the state in which the DFA appears after receiving terminal a
%For every rule N -> N_1 N_2
%we add rules (from  N  to) -> (from  N_1  m) (m  N_2 * to) where: from, m, to - goes through all DFA states

%The starting nonterminal for the intersection grammar is the following nonterminal: (start, S, final). Where: start -- the start state of DFA, S -- the start symbol of initial grammar, and final -- the final state of DFA. 


%Lemma der_in_triple_grammar_implies_dfa_accepts':
%forall (r : var) (w : word),
%der (convert_rules G next) (V (from, r, to)) (to_phrase w) ->     
%final_state next (fst3 (from, r, to)) w = thi3 (from, r, to).
%Proof
%We proving this statement using Chomsky induction:

%For rule (from, r, to) := t by construction we have only rules where to = next from t
%For rule (from, r, to) := (from, n1, m) (m, n2, to)  -  word divided into two parts w = w1 ++ w2. Word w1 transits DFA from ‘from’ to ‘m’. Word w2 transits DFA from ‘m‘ to ‘to’. So w transits DFA from ‘from’ to ’to’.


%Lemma der_in_triple_gr_implies_der_in_initial_gr':
%forall (r: var) (w: word),
%der (convert_rules G next) r (to_phrase w) ->
%der G (snd3 (unVar r)) (to_phrase w). 
%Proof
%We proving this statement using Chomsky induction:
%For rule (from, r, to) := [t] by construction we have rule r := t in primary grammar 

%For rule (from, r, to) := (from, n1, m) (m, n2, to)  -  by construction we have rule r := n1 n2 in primary grammar 

%Theorem der_in_initial_grammar_and_dfa_implies_der_in_triple_grammar:
%forall (next: dfa_rule) (r: var) (from to: State) (w: word),
%der G r (to_phrase w) ->
%final_state next from w = to ->
%der (convert_rules G next) (V (from, r, to)) (to_phrase w).
%Proof
%We proving this statement using Chomsky derivability induction:
%For rule (frr, to) := [t] by construction we have only rules where (to = next from t)
%For rule (from, r, to) := (from, n1, m) (m, n2, to)  - our word divided into two parts w = w1 ++ w2. Word w1 transits DFA from ‘from’ to ‘m’. Word w2 transits DFA from ‘m‘ to ‘to’. So w transits DFA from ‘from’ to ’to’.


\subsection{Part ..: union}

After the previous step, we have a list of grammars of CF languages, in this section, we provide a function by which we construct a grammar of the union of languages.

For this, we need nonterminals from every language to be from different nonintersecting sets. To achieve this we add labels to nonterminals. Thus, each grammar of the union would have its own unique ID number, all nonterminals within one grammar will have the same ID which coincides with the ID of a grammar. In addition, it is necessary to introduce a new starting nonterminal of the union.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Inductive labeled_Vt : Type :=
  | start : labeled_Vt
  | lV : nat -> Vt -> labeled_Vt.
  
  Definition label_var (label: nat) 
                       (v: @var Vt): @var 
                       labeled_Vt :=
    V (lV label v).  
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

Construction of new grammar is quite simple. The function that constructs the union grammar takes a list of grammars, then, it (1) splits the list into head [$h$] and tail [$tl$], (2) labels [$length \ tl$] to $h$, (3) adds a new rule from the start nonterminal of the union to the start nonterminal of the grammar [$h$], finally (4) the function is recursively called on the tail [$tl$] of the list.

\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Definition label_grammar label grammar := ...

  Definition label_grammar_and_add_start_rule 
               label 
               grammar :=
    let '(st, gr) := grammar in 
    (R (V start) [Vs (V (lV label st))]) 
       :: label_grammar label gr.        

  Fixpoint grammar_union 
     (grammars : seq (@var Vt * (@grammar Tt Vt)))
       : @grammar 
     Tt 
     labeled_Vt :=
    match grammars with
    |  [] => []
    |  (g::t) => 
         label_grammar_and_add_start_rule 
           (length t) 
           g ++ (grammar_union t)
    end.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

%Definition label_symbol (label: nat) (s: @symbol Tt Vt): @symbol Tt labeled_Vt :=
%match s with
%| Ts t => Ts t
%| Vs v => Vs (V (lV label v))
%end.
%
%Definition label_phrase (label: nat) (p: @phrase Tt Vt): @phrase Tt labeled_Vt :=
%map (label_symbol label) p.
%
%Definition label_rule (label: nat) (r : @rule Tt Vt): @rule Tt labeled_Vt :=
%let '(R v p) := r in R (V (lV label v)) (label_phrase label p).
%
%Definition label_grammar (label: nat) (g: @grammar Tt Vt): @grammar Tt labeled_Vt:=
%map (label_rule label) g.

%Definition label_grammar_and_add_start_rule (label: nat) (g : @var Vt * (@grammar Tt Vt)):
%@grammar Tt labeled_Vt :=
%let '(st, gr) := g in (R (V start) [Vs (V (lV label st))]) :: label_grammar label gr.        

%Fixpoint label_list_of_grammars (grammars : seq (@var Vt * (@grammar Tt Vt))):
%@grammar Tt labeled_Vt :=
%match grammars with
%|  [] => []
%|  ((_,gr)::t) => label_grammar (length t) gr ++ (label_list_of_grammars t)
%end.

%Fixpoint grammar_union (grammars : seq (@var Vt * (@grammar Tt Vt))): @grammar Tt labeled_Vt :=
%match grammars with
%|  [] => []
%|  (g::t) => label_grammar_and_add_start_rule (length t) g ++ (grammar_union t)
%end.

\subsubsection{Equivalence proof}

In this section, we prove that function $grammar\_union$ constructs a correct grammar of union language indeed. Namely, we prove the following theorem.

% ALT
%\begin{theorem}
%   Let $grammars$ be a sequence of pairs of starting nonterminals and grammars. Then for any word $w$, the fact that $w$ belongs to language of union (i.e. [$grammar\_union \ grammars$] +  [$V (start Vt)$]) is equivalent to the fact that there exists a $grammar \in grammars$ such that $w$ belongs to language generated by $grammar$.
%\end{theorem}

\begin{theorem}\label{theorem-correct-union}
    Let $grammars$ be a sequence of pairs of starting nonterminals and grammars. Then for any word $w$, the fact that $w$ belongs to language of union is equivalent to the fact that there exists a grammar $(st,gr) \in grammars$ such that $w$ belongs to language generated by $(st,gr)$.
\end{theorem}

% TODO 
\begin{listing}[h]
    \begin{pyglist}[language=coq, numbers=none, numbersep=5pt]
  Variable grammars: seq (var * grammar).

  Theorem correct_union:
    forall word, 
      language (grammar_union grammars) 
        (V (start Vt)) (to_phrase word) <->
      exists s_l, 
        language (snd s_l) (fst s_l) 
          (to_phrase word) /\ 
        In s_l grammars.
    \end{pyglist}
    \caption{TODO}
    \label{lst:verbments1}
\end{listing}

% TODO: 
% (1: Это нужно описать отдельно)
% ... ... ... ... 

\textbf{Proof of theorem ~\ref{theorem-correct-union}.} Since the statement is formulated as an equivalence, we divide the proof into two parts:\\
1. If $w$ belongs to the union language, then $w$ belongs to one of the initial language. \\
% Cсхема примерно такая: 
% Поднимает предположение в контекст. 
% (1: Это нужно описать отдельной леммой): Из леммы знаем, что либо фраза равна стартовому нетерминалу, либо грамматика из grammars такая, что в грамматике объединения это слово выводится из нетерминала (V (lV (length grammars2) var)). Список грамматик мы можем разделить на (1) начало списка, (2) ту самую грамматику и (3)конец списка. 
% Докажем, что это и есть интересующая нас грамматика. 
% Так как мы рассматриваем слово, стартовым нетерминалом оно быть не может. Значит второй случай.
% (2: Это нужно описать отдельной леммой) По другой лемме, если рассматривается вывод _не_ из стартового нетерминала, тогда все правила с использованием стартового нетерминала можно выкинуть. 
% После этого, заменяем grammars на то равенство.
% (3: Это нужно описать отдельной леммой) Есть лемма, которая говорит, что в случае вывода из labeled нетерминала, все правила с другими метками можно выкинуть. Остались правила только с одной (интересующей нас) меткой. 
% Нам нужно доказать, что в грамматике ... выводится ... 
% Это просто, так как у нас есть лемма, что мы можем про-label-ить грамматику и ничего не изменится. Теперь посылка совпадает с предположением.
% terminal (to_phrase word). Тоже просто. 
% И In (a, g) (u ++ (a, g) :: v) тоже очевидно.
2. If $w$ belongs to one of the initial language, then $w$ belongs to the union language. \\
The fact that $(st,grammar) \in grammars$ implies that there exist $gr1$ and $gr2$ such that: $gr1 ++ (st, grammar) :: gr2 = grammars$. 
%bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla bla-bla-bla 

%Lemma same_union_fwd : forall (l : list (grammar * Vt)) (w : word),
%language_list_union (map grammar_to_language l) w ->
%grammar_to_language (grammar_union l, start Vt) w.
Proof.
This proved through induction over l.
assume l = h :: t, then either word accepted by h or tail.
If word accepted by h
%grammar_to_language h w  
If word accepted by l. We just proving that adding one more language to union preserves
word derivability. 
%grammar_to_language (grammar_union l, start Vt) w ->
%grammar_to_language (grammar_union h :: l, start Vt) w
Which is equivalent to proving that adding new rules to grammar preserves
word derivability

2. If we have derivation for some word in new grammar lanager we can provide derivate in for some language from union.

%Lemma same_union_bkw : forall (l : list (grammar * Vt)) (w : word),
%grammar_to_language (grammar_union l, start Vt) w ->
%language_list_union (map grammar_to_language l) w.
Proof.
Here we converting derivability procedure for language union into derivability procedure of one of language.
%First we have to search though derivability structure and find rule of form start := s_i that was applied after this we can find for which language we build derivation.
Then we proving that in derivation we can use rules from only one language at time.
Finally we converting derivation by simple relabelling back all nonterminals.





\subsection{ Part N: taking all parts together}

TODO: add some text


\begin{theorem}
    For any two decidable types Terminal and Nonterminal for type of terminals and nonterminals correspondingly. If there exists bijection from Nonterminal to $\mathbb{N}$ and syntactic analysis in the sense of definition TODO is possible, then for any DFA dfa which accepts Terminal and any grammar $G$, there exists the grammar of intersection $L(DFA)$ and $G$.
\end{theorem}   

Proof. 


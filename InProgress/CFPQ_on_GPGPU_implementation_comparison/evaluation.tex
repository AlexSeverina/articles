\section{Evaluation}

We evaluate all described implementattions on all data and queries from presented dataset.
Also we provide results for implementation provided in~\cite{Azimov:2018:CPQ:3210259.3210264} for comparison.
Our goal is to comare CFPQ evaluation algorithms, so we exclude time requred for load data from files.
Time requred for data transferring is included.

For evaluation we use PC with Ubuntu 18.04 installed.
It has Intel core i7 8700k 3,7HGz CPU, Ddr4 32Gb RAM, and Geforce 1080Ti GPGPU with 11Gb RAM.

Results of evaluation are presented in tables below.
Time is mesured in seconds.
Result for each algorithm is an averege time of 10 runs.

First is a \textbf{[RDF]} dataset.
Results are presented in a table~\ref{tbl:tableRDF}.

{\setlength{\tabcolsep}{0.4em}
\begin{table*}
\caption{RDFs querying results}
\label{tbl:tableRDF}
\begin{tabular}{| p{1.25cm} | c | c |c | c | c | c | c | c | c | c | c | c | c | c |}
    \hline
    \multicolumn{3}{|c|}{RDF}        & \multicolumn{6}{|c|}{Query 1}                               & \multicolumn{6}{|c|}{Query 2} \\
    %\cline{2-13}
    \hline
    Name                                & \#V & \#E  & Scipy & M4RI  & GPU4R & GPU\_N & GPU\_Py & CuSprs & Scipy & M4RI & GPU4R & GPU\_N & GPU\_Py & CuSprs \\
    \hline
    \hline
    \small{atom-primitive}              & 291 & 685  & 0.003 & 0.002 & 0.002 & 0.001  & 0.005   & !!!    & 0.001 & \ltz & 0.001 & \ltz   & 0.002   & !!!    \\
    \small{biomed.-mesure-primitive}    & 341 & 711  & 0.003 & 0.005 & 0.002 & 0.001  & 0.005   & !!!    & 0.004 & \ltz & 0.001 & \ltz   & 0.005   & !!!    \\
    \small{foaf}                        & 256 & 815  & 0.002 & 0.009 & 0.002 & \ltz   & 0.005   & !!!    & 0.001 & \ltz & 0.001 & \ltz   & 0.002   & !!!    \\
    \small{funding}                     & 778 & 1480 & 0.004 & 0.007 & 0.004 & 0.001  & 0.005   & !!!    & 0.002 & \ltz & 0.003 & \ltz   & 0.004   & !!!    \\
    \small{generations}                 & 129 & 351  & 0.003 & 0.003 & 0.002 & \ltz   & 0.005   & !!!    & 0.001 & \ltz & 0.001 & \ltz   & 0.002   & !!!    \\
    \small{people\_pets}                & 337 & 834  & 0.003 & 0.003 & 0.003 & 0.001  & 0.007   & !!!    & 0.001 & \ltz & 0.001 & \ltz   & 0.003   & !!!    \\
    \small{pizza}                       & 671 & 2604 & 0.006 & 0.008 & 0.003 & 0.001  & 0.006   & !!!    & 0.002 & \ltz & 0.002 & \ltz   & 0.005   & !!!    \\
    \small{skos}                        & 144 & 323  & 0.002 & 0.004 & 0.002 & \ltz   & 0.005   & !!!    & \ltz  & \ltz & 0.001 & \ltz   & 0.002   & !!!    \\
    \small{travel}                      & 131 & 397  & 0.003 & 0.005 & 0.002 & \ltz   & 0.006   & !!!    & 0.001 & \ltz & 0.001 & \ltz   & 0.003   & !!!    \\
    \small{univ-bench}                  & 179 & 413  & 0.002 & 0.004 & 0.002 & \ltz   & 0.005   & !!!    & 0.001 & \ltz & 0.001 & \ltz   & 0.003   & !!!    \\
    \small{wine}                        & 733 & 2450 & 0.007 & 0.006 & 0.004 & 0.001  & 0.007   & !!!    & 0.001 & \ltz & 0.003 & \ltz   & 0.003   & !!!    \\
    \hline
  \end{tabular}
\end{table*}
}

We can see, that in this case running time for all our implementations smaller than time for reference implementattion, and that \textbf{[GPU\_N]} is faster than other implementations while other implementations demonsrtate similar performance.
Also it is obvious that performance improvement in comarison with first implementations is huge and it is necessary to select new significantly biggest RDF files.
                                                                                                     
Results of theoretical worst case (\textbf{[Worst]} datatset) is presented in table~\ref{tbl:tableWorst}.
                                                                                                     
{\setlength{\tabcolsep}{0.4em}
\begin{table}[H]
\caption{Worst case evaluation results}
\label{tbl:tableWorst}
\begin{tabular}{| l | c | c | c | c | c | c | }
    \hline
    \#V  & Scipy    & M4RI    & GPU4R  & GPU\_N  & GPU\_Py & CuSprs  \\
    \hline
    \hline
    16   & 0.032    & \ltz    & 0.008  & 0.002   & !!!     & !!!     \\
    32   & 0.118    & 0.001   & 0.034  & 0.008   & !!!     & !!!     \\
    64   & 0.476    & 0.041   & 0.133  & 0.032   & !!!     & !!!     \\
    128  & 2.194    & 0.226   & 0.562  & 0.129   & 2.751   & !!!     \\
    256  & 15.299   & 1.994   & 3.088  & 0.544   & 11.883  & !!!     \\
    512  & 121.287  & 23.204  & 13.685 & 2.499   & 43.563  & !!!     \\
    1024 & 1593.284 & 528.521 & 88.064 & 19.357  & 217.326 & !!!     \\
    2048 & -        & -       & -      & 325.174 & -       & !!!     \\
    \hline
  \end{tabular}
\end{table}
}

This case is really hard to process: even for graph with 1024 vertices query evaluation time grather than 10 seconds even for most performant implementation.
Also we can see, that time grows fast with grows of vertices number.

Next is a \textbf{[Sparse]} datatset.
Results are presented in table~\ref{tbl:tableSparse}.

{\setlength{\tabcolsep}{0.4em}
\begin{table}[H]
\caption{Sparse graphs querying results}
\label{tbl:tableSparse}
\begin{tabular}{| l | c | c | c | c | c | c | }
    \hline
    Graph              & Scipy   & M4RI     & GPU4R  & GPU\_N & GPU\_Py & CuSprs  \\
    \hline
    \hline
    \small{G5k-0.001}  & 10.352  & 0.647    & 0.113  & 0.041  & 0.216   & !!!     \\
    \small{G10k-0.001} & 37.286  & 2.395    & 0.435  & 0.215  & !!!     & !!!     \\
    \small{G10k-0.01}  & 97.607  & 1.455    & 0.273  & 0.138  & 0.763   & !!!     \\
    \small{G10k-0.1}   & !!!     & 1.050    & 0.223  & 0.114  & 0.859   & !!!     \\
    \small{G20k-0.001} & 150.774 & 11.025   & 1.842  & 1.274  & 6.180   & !!!     \\
    \small{G40k-0.001} & -       & 97.841   & 11.663 & 8.393  & 37.821  & !!!     \\
    \small{G80k-0.001} & -       & 1142.959 & 88.366 & 65.886 & -       & !!!     \\
    \hline
  \end{tabular}
\end{table}  
}


For such type of graphs !!!!
Note that we estimate only query execution time, so it is hard to compare our results with results presented in~\cite{fan2018scaling}.
But it would be interesting to do such comaprison in future because running time of our \textbf{[GPU\_N]} implementation is significantly smaller than provided in~\cite{fan2018scaling}.

The last dataset is a \textbf{[Full]}, and results a shown in table~\ref{tbl:tableFull}


\begin{table*}
\caption{Full querying results}
\label{tbl:tableFull}
\begin{tabular}{| l | c | c | c | c | c | c | c | c | c | c | c | c |}
    \hline
    \multirow{2}{*}{\#V} & \multicolumn{6}{|c|}{Query 1}                               & \multicolumn{6}{|c|}{Query 2} \\
    \cline{2-13}
                         & Scipy   & M4RI    & GPU4R   & GPU\_N  & GPU\_Py & CuSprs & Scipy  & M4RI     & GPU4R   & GPU\_N  & GPU\_Py & CuSprs \\
    \hline
    \hline
%    10                   & 0.001   & \ltz    & \ltz    & \ltz    & 0.002   & !!!    & 0.002  & !!!     & 0.001   & 0.001   & 0.004   & !!!    \\
%    50                   & 0.002   & \ltz    & 0.001   & \ltz    & 0.003   & !!!    & 0.005  & !!!     & 0.002   & 0.001   & !!!     & !!!    \\
    100                  & 0.007   & 0.002    & 0.002   & \ltz    & 0.003   & !!!    & 0.023  & !!!     & 0.005   & 0.001   & 0.007   & !!!    \\
    200                  & 0.040   & 0.003    & 0.002   & 0.001   & 0.004   & !!!    & 0.105  & !!!     & 0.004   & 0.001   & 0.007   & !!!    \\
    500                  & 0.480   & 0.003    & 0.003   & 0.001   & 0.004   & !!!    & 1.636  & !!!     & 0.007   & 0.001   & 0.010   & !!!    \\
    1000                 & 3.741   & 0.007    & 0.005   & 0.001   & 0.006   & !!!    & 13.071 & !!!     & 0.009   & 0.001   & 0.009   & !!!    \\
    2000                 & 40.309  & !!!      & 0.019   & 0.003   & 0.017   & !!!    & 93.676 & !!!     & 0.030   & 0.005   & 0.026   & !!!    \\
    5000                 & 651.343 & 0.366    & 0.125   & 0.038   & 0.150   & !!!    & !!!    & 0.851   & 0.195   & 0.075   & 0.239   & !!!    \\
    10000                & -       & 1.932    & 0.552   & 0.315   & 0.840   & !!!    & !!!    & 4.690   & 1.055   & 0.648   & 1.838   & !!!    \\
    25000                & -       & 33.236   & 7.252   & 5.314   & 15.521  & !!!    & -      & 70.823  & 15.240  & 10.961  & 36.495  & !!!    \\
    50000                & -       & 360.035  & 58.751  & 44.611  & 129.641 & !!!    & -      & 775.765 & 130.203 & 91.579  & !!!     & !!!    \\
    80000                & -       & 1292.817 & 256.579 & 190.343 & 641.260 & !!!    & -      & -       & 531.694 & 376.691 & !!!     & !!!    \\

    \hline
  \end{tabular}
\end{table*}


Finally, we can cocnlude that
\begin{itemize}
\item On GPU utilization
\item On Existinng libraries
\item On Low-level programming
\item On sparse matrices
\end{itemize}

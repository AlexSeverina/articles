\section{Implementation}

We implement matrix-based algorithm fo CFPQ by using a number of different programming languages and tools.
Our goal is to investigate effects of the next features of implmentation.
\begin{itemize}
\item \textbf{GPGPU utilization.} 
It is mell-known thet GPGPUs are sutable for matrices operations, but performance of whole solution depends on task details: overhead on data transferring may negate effect of parallel computations. 
Moreover, it is believed that GPGPUs is not sutable boolean calculations~\cite{!!!}. 
Can GPGPUs utilization for CFPQ improve performance in comparison with CPU version?

\item \textbf{Existing libraries utilization} is a good practice in software engeneering.
Is it possible to achaive highe performance by using existing libraries for matrices operations or we need to create own solution to get more control?

\item \textbf{Low-level programming}. 
GPGPU programming is traditionally low-level programming by using C-based languages (CUDA C, OpenCL C). 
On the other hand, there are number of approaches to create GPGPU-based solution by ysing such high-level languages as a Python. 
Can we get high-performance solution by using such approaches?

\item \textbf{Sparce} Real graphs often are sparse. 

\end{itemize}
We provide next implementations to compare different approaces to algorithms implementation.

\begin{itemize}
  \item CPU-based solutions 
  \begin{itemize}
    \item Python + Scipy~\cite{scipy} (sparse matrices)
    \item C + m4ri~\cite{M4RI} (4 russian method)
  \end{itemize}
  \item GPGPU-based solutions
  \begin{itemize}
    \item CUDA C, manual implemenattion of 4 russian metod.
    \item CUDA C, manual implementation of naive boolean matrix multiplication
    \item Pyton + numba\footnote{Numba is a JIT compiler which supports GPGPU for subset of Python programming. Offical page: \url{http://numba.pydata.org/}. Access date: 03.05.2019} manual implementation of naive boolean matrix multiplication
  \end{itemize}
\end{itemize}


Brief overview of approaches.

Generic notes on optimizations.
Notes on data transferring.
On matrix changes tracking (we should multiply pair of matrices only if one of them changed in last iteration)

\subsection{m4ri}

Descriprion of impl 1~\cite{M4RI}

\subsection{Pyton sparse CPU}

Descriprion of impl 2

\subsection{CUDA naive}

Descriprion of impl 3

\subsection{CUDA 4 russian method}

Descriprion of impl 4

\subsection{Python + CUDA}

Descriprion of impl 5

\subsection{Smth else?}

Descriprion of impl n

\section{Implementation}

We implement the matrix-based algorithm for CFPQ by using a number of different programming languages and tools.
Our goal is to investigate the effects of the following features of an implementation.
\begin{itemize}
\item \textbf{GPGPU utilization.}
It is well-known that GPGPUs are suitable for matrices operations, but the performance of the whole solution depends on the implementation details. For example, overhead on data transferring may negate the effect of parallel computations.
Can GPGPUs utilization for CFPQ improve performance in comparison with the CPU version?

\item \textbf{Existing libraries utilization} is a good practice in software engineering.
Is it possible to achieve higher performance by means of existing libraries for matrices operations or do we need to create our own solution to get more control?

\item \textbf{Low-level programming}.
GPGPU programming traditionally involves low-level programming in C-based languages (CUDA C, OpenCL C).
But can we achieve a high-performance solution solution with high-level languages such as Python?

\item \textbf{Sparce matrices.} Real graphs are often sparse.
Can we gain more performance improvement by using sparse matrix representation for CFPQ?

\end{itemize}

We provide the following implementations for investigation.

\begin{itemize}
  \item CPU-based solutions
%  \begin{itemize}

    \textbf{[Scipy]} Sparse matrices multiplication by using Scipy~\cite{scipy} in Python programming language.

    \textbf{[M4RI]} Dense matrices multiplication by using m4ri\footnote{Actually we use pull request which is not merged yet: \url{https://bitbucket.org/malb/m4ri/pull-requests/9/extended-m4ri-to-multiplication-over-the/diff}. The original library implements operations over $GF(2)$, and this pull request contains operations over boolean semiring}~\cite{M4RI} library which implements the Method of Four Russians~\cite{arlazarov1970economical} in C language.
    This library is choosen because it is one of performant implementations of the Method of Four Russians~\cite{albrechtefficient}.
  %\end{itemize}
  \item GPGPU-based solutions

    \textbf{[GPU4R]} Our own implementation of the Method of Four Russians in CUDA C.

    \textbf{[GPU\_N]} Our own implementation of the na\"ive boolean matrix multiplication in CUDA C with boolean values treated as bits and packed into \texttt{uint\_32}.

    \textbf{[GPU\_Py]} Manual implementation of na\"ive boolean matrix multiplication in Python by using numba compiler\footnote{Numba is a JIT compiler which supports GPGPU for a subset of Python programming. Official page: \url{http://numba.pydata.org/}. Access date: 03.05.2019}.
    Boolean values are packed into \texttt{uint\_32}.

\end{itemize}

As far as a set of matrices and its size can be calculated at the start of computations, all GPGPU based implementations allocate all required memory on the GPGPU once, at the start of computations.
This way, it is possible to significantly reduce overhead on data transferring: all input data loads to GPGPU at the start, and the result loads from GPGPU to the host at the end.
As a result, there is no active data transferring and memory allocating during query computation.

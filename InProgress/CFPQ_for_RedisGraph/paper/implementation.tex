\section{Implementation}

We showed that CFPQ can be naturally reduced to linear algebra.
Linear algebra for graph problems is an actively developed area.
One of the most important results is a GraphBLAS API which provides a way to operate over matrices and vectors over user-defined semirings.

Previous works show~\cite{Mishin:2019:ECP:3327964.3328503, Azimov:2018:CPQ:3210259.3210264} that existing linear algebra libraries utilization is the right way to achieve high-performance CFPQ implementation with minimal effort.
But neither of these works provide an evaluation with data storage: algorithm execution time has been measured in isolation.

We provide a number of implementations of the matrix-based CFPQ algorithm.
We use RedisGraph as storage and implement CFPQ as an extension by using the mechanism provided.
Note that currently, we do not provide complete integration with the querying mechanism: one cannot use Cypher~--- a query language used in RedisGraph.
Instead, a query should be provided explicitly as a file with grammar in Chomsky normal form.
This is enough to evaluate querying algorithms and we plan to improve integration in the future to make our solution easier to use. 

\textbf{CPU-based implementation (RG\_CPU)} uses SuteSparse implementation of GraphBLAS, which is also used in RedisGraph, and a predefined boolean semiring.
Thus we avoid data format issues: we use native RedisGraph representation of the adjacency matrix in our algorithm.

\textbf{GPGPU-based implementation} has four versions.
The first one ($\textbf{RG\_M4RI}_{rel}$) uses the Method of the Four Russians implemented in~\cite{Mishin:2019:ECP:3327964.3328503}, the second one ($\textbf{RG\_CUSP}_{rel}$) utilizes a CUSP~\cite{Cusp} library for matrix operations, the third one ($\textbf{RG\_SPARSE}_{rel}$) is our implementation based on the idea from this paper~\cite{NsparsePaper} and the fourth one ($\textbf{RG\_SPARSE}_{path}$) is our implementation of single-path semantics.
First two implementations require matrix format conversion but the last two does not.

The first ($\textbf{RG\_M4RI}_{rel}$) implementation works with dense matrices so it cannot be applicable to huge graphs. Therefore, we choose the CUSP library as base solution that uses sparse matrices. CUSP is a C++ templated library which allows us to multiply boolean matrices (that solve relational path semantic problem). But in fact, performing CFPQ with relational paths semantics on the largest graph using CUSP does not fit in GPU memory and this fact led us to develop an algorithm that would be more memory efficient.

The third ($\textbf{RG\_SPARSE}_{rel}$) implementation utilizes low-latency on-chip shared memory for hash table of each row of the result matrix. For more details of algorithm see the original paper~\cite{NsparsePaper}. An original solution designed for single and double precision SpGEMM. Since we have a boolean matrix in CSR format, we can discard the array of values and optimize usage of shared memory. But boolean matrix multiplication is only one part of the algorithm, since we must effectively combine two boolean sparse matrices. We use merge path~\cite{GpuMergePathPaper} algorithm to merge corresponding rows of the result matrix.

The fourth ($\textbf{RG\_SPARSE}_{path}$) algorithm must perform SpGEMM on \textit{PathIndex}. It is more complex tasks than boolean SpGEMM because domain of operation changed and it is no way to perform atomically $\oplus$ defined for PathIndexes. But for every element of the matrix with indexes $i,j$ it either $PathIndex = (i,j,\_,\_,\_)$ or $\bot$. Also note that \textit{length} information does not matter in the algorithm and can be restored later, so only two elements are really important: \textit{middle} and \textit{height}. We can store two 4 bytes value into one 8 byte value and perform an atomic operation. In high four bytes we store the \textit{height} and in the low four bytes we store the \textit{middle}. For the value of $\bot$ we use maximum unsigned integer value of 8 bytes in size. Now we can use \textit{atomicMin} as $\oplus$. As a result the algorithm consist of two steps. On the first step we evaluate the $\textbf{RG\_SPARSE}_{rel}$ algorithm to determinate final structure of \textit{proper matrix}. On the second step we fill matrices with $\bot$ or edges and start multiplication.

\chapter{Алгоритм на матричных операциях}
\section{Описание}
\label{Matrix-CFPQ}
В главе~\ref{graph:CYK}~был изложен алгоритм для графов на основе CYK. Заметим, что обход матрицы напоминает матричное умножение:

\begin{gather*}
M_1 \times M_2 = M_3 \\
M_3[i,j] = \sum_{k=1}^{n} M[i,k] * M[k,j]
\end{gather*}
, где
\begin{gather*}
\sum_{k=1}^{n} = \bigcup_{k=1}^{n} \\
S_1 * S_2 = \{N_1^0 ... N_1^m\} * \{N_2^0 ... N_2^l\} = \{N_3~|~(N_3 \rightarrow N_1^i N_2^j) \in P\}
\end{gather*}

Для линейного входа существует алгоритм Валианта~\cite{Valiant:1975:GCR:1739932.1740048}, но он не обобщается на графы с сохранением асимптотики~\cite{Yannakakis}, поэтому рассмотрим идею, изложенную в статье Рустама Азимова~\cite{Azimov:2018:CPQ:3210259.3210264}.

Пусть $\mathcal{G} = (V, E)$ --- входной граф и $G = (N,\Sigma,P)$ --- входная грамматика.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\caption{Context---free recognizer for graphs}
\label{alg:graphParse}
\Function{contextFreePathQuerying}{$\mathcal{G}$, G}
    
    \State{$n \gets$ количество узлов в $\mathcal{G}$}
    \State{$E \gets$ направленные ребра в $\mathcal{G}$}
    \State{$P \gets$ набор продукций из $G$}
    \State{$T \gets$ матрица $n \times n$, в которой каждый элемент $\varnothing$}
    \ForAll{$(i,x,j) \in E$}
    \Comment{Инициализация матрицы}
        \State{$T_{i,j} \gets T_{i,j} \cup \{A~|~(A \rightarrow x) \in P \}$}
    \EndFor    
    \While{матрица $T$ меняется}
       
        \State{$T \gets T \cup (T \times T)$}
        \Comment{Вычисление транзитивного замыкания} 
    \EndWhile
\State \Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}


\begin{example}[Пример работы]

Пусть есть граф $\mathcal{G}$:
\begin{center}
    \begin{tikzpicture}[shorten >=1pt,on grid,auto]
    \node[state] (q_0)   {$1$};
    \node[state] (q_1) [above right=of q_0] {$2$};
    \node[state] (q_2) [right=of q_0] {$0$};
    \node[state] (q_3) [right=of q_2] {$3$};
    \path[->]
    (q_0) edge  node {a} (q_1)
    (q_1) edge  node {a} (q_2)
    (q_2) edge  node {a} (q_0)
    (q_2) edge[bend left, above]  node {b} (q_3)
    (q_3) edge[bend left, below]  node {b} (q_2);
    \end{tikzpicture}
    
\end{center}

и грамматика $G$:
\begin{align*}
S   &\to A B \\ 
S  &\to A S_1 \\ 
S_1 &\to S B \\
A  &\to a \\ 
B   &\to b
\end{align*}

Тогда $T_0$, полученная напрямую из графа, выглядит так:


\[
T_0 = \begin{pmatrix}
    \varnothing & \{A\}       & \varnothing & \{B\}       \\
    \varnothing & \varnothing & \{A\}       & \varnothing \\
    \{A\}       & \varnothing & \varnothing & \varnothing \\
    \{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

Пусть $T_i$ --- матрица, полученная из $T$ после применения цикла на строках \textbf{8-9} алгоритма~\ref{alg:graphParse} $i$ раз. Далее показано получение матрицы $T_1$.


\[
T_0 \times T_0 = \begin{pmatrix}
    \varnothing & \varnothing & \varnothing & \varnothing \\
    \varnothing & \varnothing & \varnothing & \varnothing \\
    \varnothing & \varnothing & \varnothing & \{S\}       \\
    \varnothing & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

\[
T_1 = T_0 \cup (T_0 \times T_0) = \begin{pmatrix}
    \varnothing & \{A\}       & \varnothing & \{B\}       \\
    \varnothing & \varnothing & \{A\}       & \varnothing \\
    \{A\}       & \varnothing & \varnothing & \{\pmb{S}\}       \\
    \{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

Когда алгоритм находит новые пути в графе $\mathcal{G}$, он добавляет соответствующие нетерминалы в матрицу $T$. Например, после первого цикла нетерминал $S$ добавляется к матрице $T$. Этот нетерминал добавляется в ячейку $[2,3]$. Это означает, что существует такой путь $\pi$ из вершины 2 в вершину 3, что $S \xrightarrow{*} \omega(\pi)$. В данном примере путь состоит из двух ребер с именами $a$ и $b$, так что $S \xrightarrow{*} ab$.

Вычисление транзитивного замыкания заканчивается через $k$ итераций, когда достигается фиксированная точка: $T_{k-1} = T_k$. Для данного примера $k = 13$, так как $T_{13} = T_{12}$. Процесс вычисления транзитивного замыкания показан ниже (на каждой итерации новые элементы выделены жирным).

{\footnotesize
\begin{alignat*}{7}
& &&T_2 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\varnothing & \varnothing & \{A\}       & \varnothing \\
\{A, \pmb{S_1}\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_3 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\{\pmb{S}\}       & \varnothing & \{A\}       & \varnothing \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_4 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\{S\}       & \varnothing & \{A\}       & \{\pmb{S_1}\}     \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}  \ \ \ \ &&T_5 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B, \pmb{S}\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_6 &&= \begin{pmatrix}
\{\pmb{S_1}\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_7 &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1, \pmb{S}\}  & \varnothing & \varnothing & \{S\}    \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}  \\
& &&T_8 &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, \pmb{S_1}\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_9 &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1, \pmb{S}\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_{10} &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S, \pmb{S_1}\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}  \ \ \ \  &&T_{11} &&= \begin{pmatrix}
\{S_1, \pmb{S}\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S, S_1\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_{12} &&= \begin{pmatrix}
\{S_1, S\}     & \{A\}       & \varnothing & \{B, S, \pmb{S_1}\}    \\
\{S, S_1\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_{13} &&= \begin{pmatrix}
\{S_1, S\}     & \{A\}       & \varnothing & \{B, S, S_1\}    \\
\{S, S_1\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\end{alignat*}
}

Таким образом, результат алгоритма~\ref{alg:graphParse} для нашего примера --- это матрица $T_{13} = T_{12}$. 

\end{example}


\subsection{Матричный алгоритм для конъюнктивных грамматик}

Матричный алгоритм для конъюнктивных грамматик отличается от алгоритма~\ref{alg:graphParse} для контекстно-свободных грамматик только операцией умножения матриц, в остальном алгоритм остается без изменений. Определим операцию умножения матриц.
\begin{definition}
    Пусть $M_1$ и $M_2$ матрицы размера $n$. Определим операцию $\circ$. $M_1 \circ M_2 = M_3$, где $M_3 [i,j] = \{A \mid \exists (A \rightarrow B_1 C_1 \& \ldots \& B_m C_m) \in P, (B_k , C_k) \in d[i,j] \forall k = 1,\ldots,m\}$, где $d[i,j] = \bigcup_{k = 1}^{n} M_1 [i,k] \times M_2 [k,j]$.
\end{definition}

Важно заметить, что алгоритм для конъюнктивных грамматик, в отличие от алгоритма для контекстно-свободных грамматик, дает лишь верхнюю оценку. То есть все нетерминалы, которые должны быть в ячейках матрицы результата, содержатся там, но вместе с ними содержатся и лишние нетерминалы. Рассмотрим пример, иллюстрирующий появление лишних нетерминалов.

\begin{example}
    Грамматика $G$:
    \begin{align*}
    S &\to AB \& DC \\ 
    A &\to a \\
    B &\to BC \mid b \\
    C &\to c \\
    D &\to DC \mid b \\
    \end{align*}
    Очевидно, что грамматика $G$ задает язык из одного слова $L(G) = \{abc\} = \{abc^*\} \cap \{a^* bc\}$.
    
    Пусть есть граф $\mathcal{G}$:
    \begin{center}
        \begin{tikzpicture}[node distance=2.5cm, shorten >=1pt,on grid,auto]
        \node[state] (q_0)   {$0$};
        \node[state] (q_1) [right=of q_0] {$1$};
        \node[state] (q_2) [right=of q_1] {$2$};
        \node[state] (q_6) [below=of q_2] {$6$};
        \node[state] (q_3) [right=of q_2] {$3$};
        \node[state] (q_5) [right=of q_6] {$5$};
        \node[state] (q_4) [right=of q_3] {$4$};
        \path[->]
        (q_0) edge  node {a} (q_1)
        (q_1) edge  node {b} (q_2)
        (q_1) edge  node {a} (q_6)
        (q_2) edge  node {c} (q_3)
        (q_3) edge  node {c} (q_4)
        (q_6) edge  node {b} (q_5)
        (q_5) edge  node {c} (q_4);
        \end{tikzpicture}
    \end{center}
    Применяя алгоритм, получим, что существует путь из вершины 0 в вершину 4 из нетерминала $S$. Очевидно, что такого пути нет. Это происходит из-за того, что существует путь ``abcc'', соответствующий $L(AB) = \{abc^*\}$ и путь ``aabc'', соответствующий $L(DC) = \{a^{*}bc\}$, но они различны и проверить их в общем случае нельзя. Поэтому для классической семантики результат работы алгоритма является оценкой сверху.
    
    Существует альтернативная семантика, когда мы трактуем конъюнкцию как в Datalog. Подробнее о Datalog в параграфе~\ref{Subsection Datalog}. Т.е если есть правило $S \to AB \& DC$, то должен быть путь принадлежащий языку $L(AB)$ и путь принадлежащий языку $L(DC)$. В альтернативной семантике алгоритм дает точный ответ.
\end{example}

Подробнее алгоритм описан в статье Рустама Азимова и Семена Григорьева~\cite{565CECD7E8F5C6063935B41DB41797AA37D53B04}.

В общем случае для булевых грамматик подобного алгоритма не существует.

\section{Особенности реализации матричного алгоритма}

Матричные алгоритмы удобны тем, что их удобно вычислять на GPU и для них можно создать модификацию, которая будет работать параллельно на нескольких вычислителях~\cite{Mishin:2019:ECP:3327964.3328503}.

Так как множество нетерминалов и правил конечно, то мы можем свести алгоритм к булевым матрицам: для каждого нетерминала заводим матрицу, такую что в ячейке стоит 1 тогда и только тогда, когда в исходной матрице в соответствующей ячейке был этот нетерминал.
Тогда перемножение пары таких матриц --- это применение правила.


\begin{example}
Представим в таком виде следующую матрицу:
\[
T_0 = \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\varnothing & \varnothing & \{A\}       & \varnothing \\
\{A\}       & \varnothing & \varnothing & \varnothing \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

Тогда:
\begin{alignat*}{7}
& &&T_{0\_A} &&= \begin{pmatrix}
0 & 1       & 0 & 0       \\
0 & 0 & 1       & 0 \\
1  & 0 & 0 & 0       \\
0       & 0 & 0 & 0 \\
\end{pmatrix} \ \ \ \ &&T_{0\_B} &&= \begin{pmatrix}
0 & 0       & 0 & 1       \\
0       & 0 & 0       & 0 \\
0  & 0 & 0 & 0       \\
1       & 0 & 0 & 0 \\
\end{pmatrix}
\end{alignat*}
Тогда при наличии правила $S \to A B$ получим $T_{1\_S} =T_{0\_A} \times T_{0\_B}$~:
\[
T_{1\_S} = \begin{pmatrix}
0 & 0       & 0 & 0       \\
0       & 0 & 0       & 0 \\
0  & 0 & 0 & 1       \\
0       & 0 & 0 & 0 \\
\end{pmatrix}
\]
\end{example}

\medskip

С другой стороны, для небольших запросов практически может быть выгодно представлять множества нетерминалов в виде битового вектора.
Нумеруем все нетерминалы с нуля, в векторе стоит 1 на i позиции, если в множестве есть нетерминал с номером i.
Таким образом, в каждой ячейке хранится битовый вектор длины $|N|$.
Тогда операцию умножения надо определить следующим образом:
$$v_1 \times v_2 = \{v \mid \exists (v,v_3) \in P, \textit{append}(v_1, v_2) \& v_3 = v_3\},$$ где $\&$ --- побитовое \texttt{``и''}.
Чтобы это было возможно, правила надо кодировать соответственно: продукция это пара, где первый элемент --- битовый вектор длины $N$ с единственной единицей в позиции, соответствующей нетерминалу в правой части, а второй элемент --- вектор длины $2|N|$, с двумя единицами кодирующими первый и второй нетерминалы, соответственно.

\begin{example}
Пусть $N = \{S, A, B\}$ и есть продукция $S \to A B$. Тогда занумеруем нетерминалы $ S \to 0, A \to 1, B \to 2$ и продукция примет вид $[1, 0, 0] \to [0, 1, 0, 0, 0, 1]$. Матрица $T_0$ примет вид(в нашей нотации $.$ означает, что в ячейке стоит $[0,0,0]$):
\[
T_0 = \begin{pmatrix}
. & [0,1,0]       & . & [0,0,1]       \\
. & . & [0,1,0]       & . \\
[0,1,0]       & . & . & . \\
[0,0,1]      & . & . & . \\
\end{pmatrix}
\]

После выполнения умножения получим $T_1 = T_0 \times T_0$:
\[
T_1 = \begin{pmatrix}
. & [0,1,0]       & . & [0,0,1]       \\
. & . & [0,1,0]       & . \\
[0,1,0]       & . & . & [1,0,0] \\
[0,0,1]      & . & . & . \\
\end{pmatrix}
\]
\end{example}


На практике в роли векторов могут выступать беззнаковые целые. 
Например, 32 бита под ячейки в матрице и 64 бита под правила (или 8 и 16, если запросы совсем маленькие, или 16 и 32).
Тогда умножение выражается через битовые операции и сравнение.



Это может оказаться быстрее --- в данном случае скорость зависит от деталей реализации.

При таких представлениях данные часто оказываются разреженны --- возникает вопрос, как представлять матрицу. Среди способов --- разреженные матрицы, GraphBLAS\footnote{GraphBLAS --- открытый стандарт для графовых алгоритмов --- \url{https://github.com/gunrock/graphblast} }, GPGPU, CUTLASS\footnote{Репозиторий библиотеки CUTLASS: \url{https://github.com/NVIDIA/cutlass}}.
Quad Tree~\cite{quadtree}.

Для вычислений лучше всего, когда все нужные для вычисления матрицы помещаются на одну карту. Хуже --- если только одна пара матриц. Хуже всего, когда не помещается даже пара матриц. Поэтому хороши распределенные решения, например через GraphBLAS.

\section{Обзор}
\begin{itemize}
    \item Lee. О конвертации парсеров КС-грамматик в перемножение булевых матриц~\cite{Lee:2002:FCG:505241.505242}
    \item OpenCypher~\cite{Kuijpers:2019:ESC:3335783.3335791}
    \item J.Hellings. CFPQ~\cite{hellingsRelational,hellings2015querying,Hellings2015PathRF}
    \item Zhang. CFPQ on rdf graphs~\cite{10.1007/978-3-319-46523-4_38}
    \item Bradford~\cite{bradford2007quickest,ward2008distributed,bradford2016fast,Bradford:2008:LCG:1373936.1373946}
\end{itemize}

Асимптотически приведенные алгоритмы имеют большую сложность, например \\ $O(n^2 |N|^2|P|~ (MM(n))$, где $MM(n)$ --- сложность перемножения матриц $n \times n$, $|P|$ --- мощность множества продукций, $|N|$ --- мощность множества нетерминалов. Однако такая большая сложность компенсируется возможностью их распараллеливания, в результате чего они работают быстрее однопоточных алгоритов с лучшей сложностью.

Брэдфорт получил субкубическую сложность для частного случая --- языка Дика с одним типом скобок~\cite{8249039}.

\section{Вопросы и задачи}
\begin{enumerate}
    \item Находить кратчайшие пути в графах, используя идеи из секции~\ref{Matrix-CFPQ}.
    \item Превратить граф, использующийся для CFPQ, в дерево.
    \item Реализовать предложенные идеи на различных архитектурах.
    \item Замерить производительность и расходы памяти по сравнению с существующими реализациями.
\end{enumerate}

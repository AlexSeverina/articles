\section{Алгоритм на матричных операциях}
\subsection{Описание}
Попробуем применить идею CYK(построить транзитивное замыкание) в случае нелинейного графа.

Рассмотрим граф
\begin{center}
	\begin{tikzpicture}[shorten >=1pt,on grid,auto]
	\node[state] (q_0)   {$1$};
	\node[state] (q_1) [above right=of q_0] {$2$};
	\node[state] (q_2) [right=of q_0] {$0$};
	\node[state] (q_3) [right=of q_2] {$3$};
	\path[->]
	(q_0) edge  node {a} (q_1)
	(q_1) edge  node {a} (q_2)
	(q_2) edge  node {a} (q_0)
	(q_2) edge[bend left, above]  node {b} (q_3)
	(q_3) edge[bend left, below]  node {b} (q_2);
	\end{tikzpicture}
	
\end{center}

и грамматику
\begin{align*}
S   &\to A B \\ 
S  &\to A S_1 \\ 
S_1 &\to S B \\
A  &\to a \\ 
B   &\to b
\end{align*}

Очевидно, что в данном случае матрица достижимости уже не будет треугольной: 
\begin{center}
	\begin{tabular}{c||cc|cc}
		& $0$ & $1$ & $2$ & $3$ \\ \hline \hline 
		$0$ & \o & $\{A\}$ & \o & $\{B\}$ \\ 
		$1$ & \o  & \o & $\{A\}$ & \o \\ 
		$2$ &  $\{A\}$ &  \o & \o & \o \\ \hline
		$3$ & $\{B\}$  & \o  & \o  & \o \\ 
	\end{tabular}
\end{center}

Для построения транзитивного замыкания попробуем применить алгоритм Флойда---Уоршелла

\begin{algorithm}[H]
	\begin{algorithmic}[1]
		\caption{Алгоритм Флойда---Уоршелла построения транзитивного замыкания}
		\label{alg:Floyd}
		\Function{Floyd–Warshall }{M, P}
		
		\For{$k \in [0..n]$}
		\For{$i \in [0..n]$}
		\For{$j \in [0..n]$}
		\For{$N_1 \in M[i,k]$}
		\For{$N_2 \in M[k,j]$}
		\State{$M[i,j] \mathrel{+}=  \{N_3~|~(N_3 \rightarrow N_1 N_2) \in P \}$}
		\EndFor   
		\EndFor 
		\EndFor 
		\EndFor 
		\EndFor  
		\Return $M$
		\EndFunction
	\end{algorithmic}
\end{algorithm}

Заметим, однако, что после запуска алгоритма мы не имеем всех возможных путей. Так, у нас отсутствует путь из вершины 1 в вершину 0($AABB$), хотя этот путь выводим в грамматике:

\begin{center}
	\begin{tabular}{c||cc|cc}
		& $0$ & $1$ & $2$ & $3$ \\ \hline \hline 
		$0$ & \o & $\{A\}$ & \o & $\{B\}$ \\ 
		$1$ & \o  & \o & $\{A\}$ & \o \\ 
		$2$ &  $\{A, S_1\}$ &  \o & \o & $\{S\}$ \\ \hline
		$3$ & $\{B\}$  & \o  & \o  & \o \\ 
	\end{tabular}
\end{center}

Таким образом, алгоритм надо запускать до тех пор, пока матрица будет меняться.

\smallskip

Заметим также, что обход матрицы напоминает матричное умножение:

\begin{gather*}
M_1 \times M_2 = M_3 \\
M_3[i,j] = \sum_{k=1}^{n} M[i,k] * M[k,j]
\end{gather*}
, где
\begin{gather*}
\sum_{k=1}^{n} = \bigcup_{k=1}^{n} \\
S_1 * S_2 = \{N_1^0 ... N_1^m\} * \{N_2^0 ... N_2^l\} = \{N_3~|~(N_3 \rightarrow N_1^i N_2^j) \in P\}
\end{gather*}

Для линейного входа существует алгоритм Валианта~\cite{Valiant:1975:GCR:1739932.1740048}, но он не обобщается на графы с сохранением асимптотики, поэтому рассмотрим идею, изложенную в статье Рустама Азимова~\cite{Azimov:2018:CPQ:3210259.3210264}.

Пусть $D = (V, E)$ --- входной граф и $G = (N,\Sigma,P)$ --- входная грамматика.

\begin{algorithm}[H]
\begin{algorithmic}[1]
\caption{Context---free recognizer for graphs}
\label{alg:graphParse}
\Function{contextFreePathQuerying}{D, G}
    
    \State{$n \gets$ количество узлов в $D$}
    \State{$E \gets$ направленные ребра в $D$}
    \State{$P \gets$ набор продукций из $G$}
    \State{$T \gets$ матрица $n \times n$, в которой каждый элемент $\varnothing$}
    \ForAll{$(i,x,j) \in E$}
    \Comment{Инициализация матрицы}
        \State{$T_{i,j} \gets T_{i,j} \cup \{A~|~(A \rightarrow x) \in P \}$}
    \EndFor    
    \While{матрица $T$ меняется}
       
        \State{$T \gets T \cup (T \times T)$}
        \Comment{Вычисление транзитивного замыкания $T^{cf}$ } 
    \EndWhile
\State \Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}


\begin{example}[Пример работы]

Пусть есть граф $D$:
\begin{center}
	\begin{tikzpicture}[shorten >=1pt,on grid,auto]
	\node[state] (q_0)   {$1$};
	\node[state] (q_1) [above right=of q_0] {$2$};
	\node[state] (q_2) [right=of q_0] {$0$};
	\node[state] (q_3) [right=of q_2] {$3$};
	\path[->]
	(q_0) edge  node {a} (q_1)
	(q_1) edge  node {a} (q_2)
	(q_2) edge  node {a} (q_0)
	(q_2) edge[bend left, above]  node {b} (q_3)
	(q_3) edge[bend left, below]  node {b} (q_2);
	\end{tikzpicture}
	
\end{center}

и грамматика $G$:
\begin{align*}
S   &\to A B \\ 
S  &\to A S_1 \\ 
S_1 &\to S B \\
A  &\to a \\ 
B   &\to b
\end{align*}

Тогда $T_0$, полученная напрямую из графа, выглядит так:


\[
T_0 = \begin{pmatrix}
    \varnothing & \{A\}       & \varnothing & \{B\}       \\
    \varnothing & \varnothing & \{A\}       & \varnothing \\
    \{A\}       & \varnothing & \varnothing & \varnothing \\
    \{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

Пусть $T_i$ - матрица, полученная из $T$ после применения цикла на строчках \textbf{8-9} алгоритма~\ref{alg:graphParse} $i$ раз. Снизу показано получение матрицы $T_1$.


\[
T_0 \times T_0 = \begin{pmatrix}
    \varnothing & \varnothing & \varnothing & \varnothing \\
    \varnothing & \varnothing & \varnothing & \varnothing \\
    \varnothing & \varnothing & \varnothing & \{S\}       \\
    \varnothing & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

\[
T_1 = T_0 \cup (T_0 \times T_0) = \begin{pmatrix}
    \varnothing & \{A\}       & \varnothing & \{B\}       \\
    \varnothing & \varnothing & \{A\}       & \varnothing \\
    \{A\}       & \varnothing & \varnothing & \{\pmb{S}\}       \\
    \{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

Когда алгоритм находит новые пути в графе $D$, он добавляет соответствующие нетерминалы в матрицу $T$. Например, после первого цикла нетерминал $S$ добавляется к матрице $T$. Этот нетерминал добавляется в ячейку $[2,3]$. Это означает, что существует такой путь $\pi$ из вершины 2 в вершину 3, что $S \xrightarrow{*} l(\pi)$. В данном примере путь состоит из двух ребер с именами $a$ и $b$, так что $S \xrightarrow{*} a \ b$.

Вычисление транзитивного замыкания заканчивается через $k$ итераций, когда достигается фиксированная точка: $T_{k-1} = T_k$. Для данного примера $k = 13$, так как $T_{13} = T_{12}$. Процесс вычисления транзитивного замыкания показан ниже (на каждой итерации новые элементы выделены жирным).


\begin{alignat*}{7}
& &&T_2 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\varnothing & \varnothing & \{A\}       & \varnothing \\
\{A, \pmb{S_1}\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_3 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\{\pmb{S}\}       & \varnothing & \{A\}       & \varnothing \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_4 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\{S\}       & \varnothing & \{A\}       & \{\pmb{S_1}\}     \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}  \ \ \ \ &&T_5 &&= \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B, \pmb{S}\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_6 &&= \begin{pmatrix}
\{\pmb{S_1}\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1\}  & \varnothing & \varnothing & \{S\}       \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_7 &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1, \pmb{S}\}  & \varnothing & \varnothing & \{S\}    \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}  \\
& &&T_8 &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, \pmb{S_1}\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_9 &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S\}       & \varnothing & \{A\}       & \{S_1, \pmb{S}\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_{10} &&= \begin{pmatrix}
\{S_1\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S, \pmb{S_1}\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}  \ \ \ \  &&T_{11} &&= \begin{pmatrix}
\{S_1, \pmb{S}\}     & \{A\}       & \varnothing & \{B, S\}    \\
\{S, S_1\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \\ & &&T_{12} &&= \begin{pmatrix}
\{S_1, S\}     & \{A\}       & \varnothing & \{B, S, \pmb{S_1}\}    \\
\{S, S_1\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_{13} &&= \begin{pmatrix}
\{S_1, S\}     & \{A\}       & \varnothing & \{B, S, S_1\}    \\
\{S, S_1\}       & \varnothing & \{A\}       & \{S_1, S\}     \\
\{A, S_1, S\}  & \varnothing & \varnothing & \{S, S_1\} \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\end{alignat*}

Таким образом, результат алгоритма~\ref{alg:graphParse} для нашего примера - это матрица $T_{13} = T_{12}$. 

\end{example}

\subsubsection{Вопросы и задачи}
\begin{enumerate}
	\item Находить кратчайшие пути
	\item Превратить граф в дерево
\end{enumerate}
\subsection{Конъюнктивные и булевы граммтики}

\subsubsection{Определения}

Охотин~\cite{Okhotin:2003:BG:1758089.1758123,f60a33d409364914be560cac0e54b12c,Okhotin:2014:PMM:2565359.2565379}.
\begin{example}[Пример конъюктивной грамматики]
	Следующая конъюктивная грамматика порождает язык $ \{a^nb^nc^n~|~n \geq 0\}$:
	\begin{align*}
	S   &\to A B \& D C \\ 
	A  &\to a A \mid \epsilon \\ 
	B &\to b B c \mid \epsilon \\
	C   &\to c C \mid \epsilon \\ 
	D   &\to aDb \mid \epsilon
	\end{align*}
	
	Грамматика основывается на представлении языка, как пересечения двух КС---языков: $\{a^nb^nc^n~|~n \geq 0\}=\{a^ib^jc^k~|~j = k\} \cap \{a^ib^jc^k~|~i = j\}$. В этой грамматике строка $abc$ может быть получена следующим образом:
\end{example}
\subsubsection{Для графов}


Классическая семантика --- работает для конъюнктивных для любых графов.
Для Булевых и конъюнктивных только для графов без циклов.

Альтернативная семантика (DataLog).
Трактуем конъюнкцию как в даталоге. Тогда всё хорошо.
Это похоже на даталог через линейную алгебру~\cite{!!!}
\subsection{Особенности реализации матричного алгоритма}

Матричные алгоритмы удобны тем, что их удобно вычислять на GPU и их можно распараллелить~\cite{Mishin:2019:ECP:3327964.3328503}

Так как множество нетерминалов и правил конечно, то мы можем свести алгоритм к булевым матрицам: для каждого нетерминала заводим матрицу, такую что в ячейке стоит true тогда и только тогда, когда в исходной матрице в соответствующе ячейке был этот нетерминал.
Тогда перемножение пары таких матриц --- это применеие правила.


\begin{example}
Представим в таком виде следующую матрицу:
\[
T_0 = \begin{pmatrix}
\varnothing & \{A\}       & \varnothing & \{B\}       \\
\varnothing & \varnothing & \{A\}       & \varnothing \\
\{A\}       & \varnothing & \varnothing & \varnothing \\
\{B\}       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

Тогда:
\begin{alignat*}{7}
& &&T_{0\_A} &&= \begin{pmatrix}
\varnothing & 1       & \varnothing & \varnothing       \\
\varnothing & \varnothing & 1       & \varnothing \\
1  & \varnothing & \varnothing & \varnothing       \\
\varnothing       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix} \ \ \ \ &&T_{0\_B} &&= \begin{pmatrix}
\varnothing & \varnothing       & \varnothing & 1       \\
\varnothing       & \varnothing & \varnothing       & \varnothing \\
\varnothing  & \varnothing & \varnothing & \varnothing       \\
1       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\end{alignat*}
Тогда при наличии правила $S \to A B$ получим $T_{1\_S} =T_{0\_A} \times T_{0\_B}$~:
\[
T_{1\_S} = \begin{pmatrix}
\varnothing & \varnothing       & \varnothing & \varnothing       \\
\varnothing       & \varnothing & \varnothing       & \varnothing \\
\varnothing  & \varnothing & \varnothing & 1       \\
\varnothing       & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]
\end{example}

\medskip

С другой стороны, для небольших запросов практически может быть выгодно представлять множества нетерминалов в виде битового вектора.
Нумеруем все нетерминалы с нуля, в векторе стит 1 на i позиции если в множетве есть нетерминал с номером i.
Таким образом, в каждой ячейке хранится битовый вектор длины $|N|$.
Тогда операцию умножения надо определить следующим образом:
$$v_1 \times v_2 = \{v \mid \exists (v,v_3) \in P, \textit{append}(v_1, v_2) \& v_3 = v_3\},$$ где $\&$ --- побитовое \texttt{``и''}.
Для этого правила надо кодировать соответственно: продукция это пара, где первый элемент --- битовый вектор длины $N$ с единственной единицей в позиции, соответствующей нетерминалу в правой части, а второй элемент --- векто длины $2|N|$, с двумя единицами кодирующими первый и второй нетерминалы, соответственно.

\begin{example}
Пусть $N = \{S, A, B\}$ и есть продукция $S \to A B$. Тогда занумеруем нетерминалы $ S \to 0, A \to 1, B \to 2$ и продукция примет вид $[1, 0, 0] \to [0, 1, 0, 0, 0, 1]$. Матрица $T_0$ примет вид(в нашей нотации $\varnothing$ означает, что в ячейке стоит $[0,0,0]$):
\[
T_0 = \begin{pmatrix}
\varnothing & [0,1,0]       & \varnothing & [0,0,1]       \\
\varnothing & \varnothing & [0,1,0]       & \varnothing \\
[0,1,0]       & \varnothing & \varnothing & \varnothing \\
[0,0,1]      & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]

После выполнения умножения получим $T_1 = T_0 \times T_0$:
\[
T_1 = \begin{pmatrix}
\varnothing & [0,1,0]       & \varnothing & [0,0,1]       \\
\varnothing & \varnothing & [0,1,0]       & \varnothing \\
[0,1,0]       & \varnothing & \varnothing & [1,0,0] \\
[0,0,1]      & \varnothing & \varnothing & \varnothing \\
\end{pmatrix}
\]
\end{example}


На практике в роли векторов могут выступать беззнаковые целые. 
Например, 32 бита под ячейки в матрице и 64 бита под правила (или 8 и 16, если запросы совсем маленькие, или 16 и 32).
Тогда умножение выражается через битовые операции и сравнение.



Это может оказаться быстрее --- в данном случае скорость зависит от деталей реализации.

При таких представлениях данные часто оказываются разреженны --- возникает вопрос, как представлять матрицу. Среди способов - разреженные матрицы, GraphBLAS\footnote{GraphBLAS --- открытый стандарт для графовых алгоритмов --- \url{https://github.com/gunrock/graphblast} }, GPGPU, CUTLASS\footnote{Репозиторий библиотеки CUTLASS: \url{https://github.com/NVIDIA/cutlass}}.
Quad Tree~\cite{quadtree}.

Для вычислений лучше всего, когда все нужные для вычисления матрицы помещаются на одну карту. Хуже --- если только одна пара матриц. Хуже всего, когда не помещается даже пара матриц. Поэтому хороши распределенные решения, например через GraphBLAS.

\subsection{Обзор}
\begin{itemize}
	\item Improving the Performance of the Sparse Matrix Vector Product with GPUs~\cite{sparseperformance}
	\item Lee. Быстрый CFPQ требует быстрого умножения булевых матриц~\cite{Lee:2002:FCG:505241.505242}
	\item OpenCypher~\cite{Kuijpers:2019:ESC:3335783.3335791}
	\item J.Hellings. CFPQ~\cite{hellingsRelational,hellings2015querying,Hellings2015PathRF}
	\item Zhang. CFPQ on rdf graphs~\cite{10.1007/978-3-319-46523-4_38}
	\item Bradford~\cite{bradford2007quickest,ward2008distributed,bradford2016fast,Bradford:2008:LCG:1373936.1373946}
\end{itemize}

Асимптотически приведенные алгоритмы имеют большую сложность, например \\ $O(n^2 |N|^2|P|~ (MM(n))$, где $MM(n)$ --- сложность перемножения матриц $n \times n$, $|P|$ --- мощность множества продукций, $|N|$ --- мощность множества нетерминалов. Однако такая большая сложность компенсируется возможностью их распараллеливания, в результате чего они работают быстрее однопоточных алгоритов с лучшей сложностью.

Брэдфорт получил субкубическую сложность для частного случая --- языка Дика~\cite{8249039}.

\subsection{Вопросы и задачи}
\begin{enumerate}
  \item Реализовать предложенные идеи на различных архитектурах.
  \item Замерить производительность и расходы памяти по сравнению с существующими реализациями.
\end{enumerate}

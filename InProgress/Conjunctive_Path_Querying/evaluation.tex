\section{Evaluation} \label{section_evaluation}
To show that the proposed algorithm allows us to effectively apply GPGPU computing techniques, we implement the Algorithm~\ref{alg:graphParse_conj} on a CPU and on a GPU. Also, we apply these implementations to some classical conjunctive grammars~\cite{okhotin2001conjunctive} and synthetic graphs.

Algorithm~\ref{alg:graphParse_conj} is implemented in F\# programming language~\cite{fsharp} and is available on GitHub\footnote{GitHub repository of the YaccConstructor project: \url{https://github.com/YaccConstructor/YaccConstructor}.}. We denote our implementations of the Algorithm~\ref{alg:graphParse_conj} as follows:
\begin{itemize}
	\item onCPU --- an implementation using CSR format for sparse matrix representation and a CPU for matrix operations calculation. For sparse matrix representation in CSR format, we use the Math.Net Numerics package.
	\item onGPU --- an implementation using the CSR format for sparse matrix representation and a GPU for matrix operations calculation. For calculations of the matrix operations on a GPU, where matrices represented in a CSR format, we use a wrapper for the CUSPARSE library from the managedCuda library.
\end{itemize}

Comparison of the performance of this implementations allows us to determine the efficiency of the GPU acceleration of the Algorithm~\ref{alg:graphParse_conj}.

All tests were run on a PC with the following characteristics:
\begin{itemize}
	\item OS: Microsoft Windows 10 Pro
	\item System Type: x64-based PC
	\item CPU: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz, 3601 Mhz, 4 Core(s), 4 Logical Processor(s)
	\item RAM: 16 GB
	\item GPU: NVIDIA GeForce GTX 1070
	\begin{itemize}
		\item CUDA Cores:		1920 
		\item Core clock:		1556 MHz 
		\item Memory data rate:	8008 MHz
		\item Memory interface:	256-bit 
		\item Memory bandwidth:	256.26 GB/s
		\item Dedicated video memory:	8192 MB GDDR5
	\end{itemize}
\end{itemize}

We evaluate two queries which correspond to two classical conjunctive grammars.

\textbf{Query 1} is based on the grammar $G^1_S$, which generates the language $\{a^n b^n c^n | n > 0\}$, where:
\begin{itemize}
	\item The grammar $G^1 = (N^1, \Sigma^1, P^1)$.
	\item The set of non-terminals $N^1 = \{S, A, B, C, D\}$.
	\item The set of terminals $\Sigma^1 = \{a, b, c\}.$
	\item The set of production rules $P^1$ is presented in Figure~\ref{ProductionRulesQuery1}.
\end{itemize}

\begin{figure}[h]
	\[
	\begin{array}{rccl}
	0: & S & \rightarrow & AB ~\& ~DC \\ 
	1: & A & \rightarrow & AA ~|~ a \\ 
	2: & B & \rightarrow & bBc ~|~ bc \\ 
	3: & C & \rightarrow & CC ~|~ c \\ 
	4: & D & \rightarrow & aDb ~|~ ab \\ 
	\end{array}
	\]
	\caption{Production rules for the query 1 conjunctive grammar.}
	\label{ProductionRulesQuery1}
\end{figure}

\begin{table*}[ht]
	\centering
	\caption{Evaluation results for conjunctive Query 1 (time in ms)}
	\label{tbl1}
	
	\begin{tabular}{ | c | c | c | c | c |}
		\hline
		|V| & |E| & \#results & onCPU(in ms) & onGPU(in ms) \\
		\hline 
		\hline
		100 & 25 & 0 & 2 & 7\\
		100 & 75 & 0 & 10 & 20\\
		100 & 200 & 79 & 101 & 213\\
		1000  & 250 & 1 & 265 & 25\\
		1000 & 750 & 13 & 2781 & 102\\
		1000 & 2000 & 731 & 12050 & 347\\
		10000 & 2500 & 4 & 26595 & 41\\
		10000 & 7500 & 136 & 241087 & 213\\
		10000 & 20000 & 4388 & 1305177 & 1316\\
		\hline
	\end{tabular}
	
\end{table*}

\begin{table*}[h]
	\centering
	\caption{Evaluation results for conjunctive Query 2 (time in ms)}
	\label{tbl2}
	
	\begin{tabular}{ | c | c | c | c | c |}
		\hline
		|V| & |E| & \#results & onCPU(in ms) & onGPU(in ms) \\
		\hline 
		\hline
		100 & 25 & 9 & 14 & 67\\
		100 & 75 & 29 & 114 & 129\\
		100 & 100 & 47 & 254 & 483\\
		1000  & 250 & 82 & 2566 & 127\\
		1000 & 750 & 279 & 21394 & 530\\
		1000 & 1000 & 438 & 64725 & 1951\\
		10000 & 2500 & 829 & 268843 & 257\\
		10000 & 7500 & 2796 & 3380046 & 1675\\
		10000 & 10000 & 27668 & --- & 3017\\
		\hline
	\end{tabular}
	
\end{table*}


The grammar $G^1$ is transformed into an equivalent grammar in normal form, which is necessary for the Algorithm~\ref{alg:graphParse_conj}. Let $R'_S$ be an over-approximation of the conjunctive relation for a start non-terminal in the transformed grammar, which is computed by the Algorithm~\ref{alg:graphParse_conj}.

The result of query 1 evaluation is presented in Table~\ref{tbl1}, where $|V|$ is a number of nodes in the graph, $|E|$ is a number of edges, and \#results is a number of pairs $(n,m)$ in the approximation $R'_S$ of the conjunctive relation $R_S$. The implementation which uses a CPU demonstrates a better performance only on some small graphs. We can conclude that acceleration from the $GPU$ increases with the graph size growth.

\textbf{Query 2} is based on the grammar $G^2_S$, which generates the language $\{wcw | w \in \{a,b\}^*\}$, where:
\begin{itemize}
	\item The grammar $G^2 = (N^2, \Sigma^2, P^2)$.
	\item The set of non-terminals $N^2 = \{S, A, B, C, D, E\}$.
	\item The set of terminals $\Sigma^2 = \{a, b, c\}.$
	\item The set of production rules $P^2$ is presented in Figure~\ref{ProductionRulesQuery2}.
\end{itemize}

\begin{figure}[h]
	\[
	\begin{array}{rccl}
	0: & S & \rightarrow & C ~\& ~ D \\ 
	1: & C & \rightarrow & aCa~|~aCb~|~bCa~|~bCb~|~c\\ 
	2: & D & \rightarrow & aA ~\& ~aD~|~bB ~\& ~bD~|~cE \\ 
	3: & A & \rightarrow & aAa~|~aAb~|~bAa~|~bAb~|~cEa\\ 
	4: & B & \rightarrow & aBa~|~aBb~|~bBa~|~bBb~|~cEb \\
	5: & E & \rightarrow & aE~|~bE~|~\varepsilon \\ 
	\end{array}
	\]
	\caption{Production rules for the query 2 conjunctive grammar.}
	\label{ProductionRulesQuery2}
\end{figure}

The grammar $G^2$ is transformed into an equivalent grammar in normal form. The result of the query 2 evaluation is presented in Table~\ref{tbl2}. On almost all graphs $onGPU$ implementation demonstrates a better performance than $onCPU$ implementation and we also can conclude that acceleration from the GPU increases with the graph size growth.

As a result, we conclude that the Algorithm~\ref{alg:graphParse_conj} allows us to speed up computations by means of GPGPU. We can also use other optimizations for matrix operations to increase the performance of the proposed algorithm.

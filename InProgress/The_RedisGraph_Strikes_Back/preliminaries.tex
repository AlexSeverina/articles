\section{Preliminaries}

In this section we introduce common definitions in graph theory and formal language theory which will be used in this paper. 
Also, we provide brief description of Azimov's algorithm which is used as a base of our solution.

\subsection{Basic definitions of Graph Theory}

In this work we use labeled directed graph as a data model and define it as follows.
\begin{definition} \emph{Labeled directed graph} is a tuple of six elements $D = (V, E, \Sigma_V, \Sigma_E, \lambda_V, \lambda_E)$, where
\begin{itemize}
    \item $\Sigma_V$ and $\Sigma_E$ is a set of labels of vertices and edges respectively, such that $\Sigma_V \cap \Sigma_E = \varnothing$.
    \item $V$ is a set of vertices. For simplicity, we assume that the vertices are natural numbers from $0$ to $|V|-1$.
    \item $E \subseteq V \times V$ is a set of edges.
    \item $\lambda_V : V \xrightarrow{} 2^{\Sigma_V}$ is a function that maps a vertex to a set of its labels, which can be empty.
    \item $\lambda_E : E \xrightarrow{} 2^{\Sigma_E} \setminus \{\varnothing\}$ is a function that maps a edge to a not empty set of its labels, so each edge must have at least one label.
\end{itemize} \qed
\end{definition}

Labeled graph is a part of widely-used \textit{property graph} data model~\cite{Angles2018ThePG} and allows one to use in navigation queries not only edge labels but also vertex labels.

An example of the labeled directed graph $D_1$ is presented in figure~\ref{fig:example_input_graph}. Here the sets of labels $\Sigma_V = \{x, y\}$ and $\Sigma_E = \{a, b, c, d\}$. 
We omit vertex labels set if it is empty.

\begin{figure}[h]
    \centering        
    \begin{tikzpicture}[shorten >=1pt,auto]
       \node[elliptic state] (q_0)                        {$0:\{x, y\}$};
       \node[state] (q_1) [right=of q_0]         {$1$};
       \node[elliptic state] (q_2) [below left=of q_1]    {$2: \{x\}$};
       \node[state] (q_3) [below left=of q_2]    {$3$};
       \node[elliptic state] (q_4) [below right=of q_2]   {$4: \{y\}$};
       \node[state] (q_5) [below right=of q_1]   {$5$};
       \path[->]
        (q_0) edge  node {$\{a\}$} (q_1)
        (q_1) edge  node {$\{b\}$} (q_5)
        (q_1) edge  node {$\{a, b\}$} (q_2)
        (q_3) edge[above]  node {$\{c\}$} (q_2)
        (q_4) edge  node {$\{c\}$} (q_3)
        (q_2) edge[above]  node {$\{c\}$} (q_4)
        (q_5) edge[bend left, below]  node {$\{d\}$} (q_4)
        (q_4) edge[bend left, above]  node {$\{d\}$} (q_5);
    \end{tikzpicture}
    \caption{The example of input graph $D_1$}
    \label{fig:example_input_graph}
\end{figure}

\begin{definition}
Path $\pi$ in the graph $D=(V, E, \Sigma_V, \Sigma_E, \lambda_V, \lambda_E)$ is a finite sequence of vertices and edges $(v_0, e_0, v_1, e_1, ..., e_{n-1}, v_{n})$, where $\forall i \mid 0 \leq n ~ v_i \in V$, $\forall j \mid 1 \leq j \leq n ~ e_j=(v_j, v_{j+1}) \in E$.

We denote the set of all possible paths in the graph $D$ as $\pi(D)$. \qed 
\end{definition}

\begin{definition}
An \emph{adjacency matrix} $M$ of the graph $D$ is a square $|V|\times|V|$ matrix, such that 
\begin{equation*}
M[i,j] =
 \begin{cases}
   \lambda_E((i, j)), & (i, j) \in E\\
   \varnothing, & else
 \end{cases}
\end{equation*} \qed
\end{definition}

Adjacency matrix $M$ of the graph $D_1$~(fig.~\ref{fig:example_input_graph}) is

$$
    M =
    \begin{pmatrix}
    \varnothing     & \{a\} &   \varnothing      &   \varnothing   &   \varnothing   &   \varnothing   \\
    \varnothing     &   \varnothing   & \{a, b\} &   \varnothing   &       & \{b\} \\
    \varnothing     &   \varnothing   &   \varnothing      &   \varnothing   & \{d\} &   \varnothing   \\
    \varnothing     &   \varnothing   & \{c\}    &   \varnothing   &   \varnothing   &   \varnothing   \\
    \varnothing     &   \varnothing   &   \varnothing      & \{c\} &   \varnothing   & \{d\} \\
    \varnothing     & \varnothing     &   \varnothing      &   \varnothing   & \{d\} &   \varnothing
    \end{pmatrix}.
$$

\begin{definition}
Let $M$ be an adjacency matrix of the graph $D$. Then the \emph{adjacency matrix of label} $l \in \Sigma_E$ of graph $D$ is a $|V| \times |V|$ matrix $\mathcal{E}^l$, such that
\begin{equation*}
\mathcal{E}^l[i,j] =
 \begin{cases}
   1, & l \in M[i,j]\\
   0, & else
 \end{cases}
\end{equation*} \qed
\end{definition}

\begin{definition}
\emph{Boolean decomposition of adjacency matrix} $M$ of the graph $D$ is a set of Boolean matrices $$\mathcal{E} = \{\mathcal{E}^l \mid l \in \Sigma\},$$
where $\mathcal{E}^l$ is the adjacency matrix of label $l$. \qed
\end{definition}

For example, adjacency matrix $M$ of the example graph $D_1$ can be represented as a set of four Boolean matrices $\mathcal{E}^a$, $\mathcal{E}^b$, $\mathcal{E}^c$ and $\mathcal{E}^d$ such that 
\begin{align*}
\mathcal{E}^a =
\begin{pmatrix}
    . & . & . & . & . & . \\
    1 & . & . & . & . & . \\
    . & 1 & . & . & . & . \\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & . \\ 
    . & . & . & . & . & .
\end{pmatrix},~  
\mathcal{E}^b =
\begin{pmatrix}
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & 1 & . & . & . & . \\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & . \\ 
    . & 1 & . & . & . & .
\end{pmatrix},\\
\mathcal{E}^c =
\begin{pmatrix}
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & . & 1 & . & . \\
    . & . & . & . & 1 & . \\ 
    . & . & 1 & . & . & . \\ 
    . & . & . & . & . & .
\end{pmatrix},~ 
\mathcal{E}^d =
\begin{pmatrix}
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & 1 \\ 
    . & . & . & . & 1 & .
\end{pmatrix}.
\end{align*}

\begin{definition}

An \emph{vertices label matrix} $H$ of the graph $D$ is a square $|V|\times|V|$ matrix, such that 
\begin{equation*}
H[i,j] = 
  \begin{cases}
    \lambda_V (i), & i = j \\
    \varnothing,     & else
  \end{cases}
\end{equation*} \qed
\end{definition}

The vertices label matrix $H$ of the example graph $D_1$ is
$$
    H =
    \begin{pmatrix}
    \{x, y\}        & \varnothing     &   \varnothing      &   \varnothing   &   \varnothing   &    \varnothing  \\
    \varnothing     &   \varnothing   & \varnothing        &   \varnothing   & \varnothing     & \varnothing     \\
    \varnothing     &   \varnothing   &   \{x\}            &   \varnothing   & \varnothing     &   \varnothing   \\
    \varnothing     &   \varnothing   & \varnothing        &   \varnothing   &   \varnothing   &   \varnothing   \\
    \varnothing     &   \varnothing   &   \varnothing      &    \varnothing  &   \{y\}         & \varnothing     \\
    \varnothing     & \varnothing     &   \varnothing      &   \varnothing   & \varnothing     &   \varnothing
    \end{pmatrix}.
$$


\begin{definition}
Let $H$ be a vertices label matrix of graph $D$. Then the \emph{vertices matrix of label} $l$ is a square $|V|\times|V|$ matrix $\mathcal{V}^l$, such that
\begin{equation*}
\mathcal{V}^l[i,j] = 
  \begin{cases}
    1,  & l \in H[i, j] \\
    0,  & else
  \end{cases}
\end{equation*}
\end{definition}

\begin{definition}
Boolean decomposition of vertices label matrix $H$ of the graph $D$ is the set of Boolean matrices
$$\mathcal{V} = \{V^l \mid l \in \Sigma\},$$
where $\mathcal{V}^l$ is a vertices matrix of label $l$.
\end{definition}

Vertices label matrix $H$ of the graph $D_1$ can be decomposed into a set of the following Boolean matrices:

\begin{align*}
\mathcal{V}^x =
\begin{pmatrix}
    1 & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & 1 & . & . & . \\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & . \\ 
    . & . & . & . & . & .
\end{pmatrix},~ 
\mathcal{V}^y =
\begin{pmatrix}
    1 & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\ 
    . & . & . & . & 1 & . \\ 
    . & . & . & . & . & .
\end{pmatrix}.
\end{align*}


\subsection{Basic Definitions of Formal Languages}
We use context-free grammars as paths constraints. Thus we should define context-free languages and grammars.

%\begin{definition}
%Let $\Sigma$ be an alphabet, $A, B$ $\subset \Sigma^*$. Then concatenation of $A$ and $B$ is the following:

%$$A \cdot B = \{a b \mid a \in A, b \in B\} \subset \Sigma^*$$ \qed
%\end{definition}

In other worlds concatenation of two sets contains all concatenations of elements from the first set with all elements from the second one.

\begin{definition}\emph{Context-free grammar} is a tuple $G=(N, \Sigma, P, S)$, where 
\begin{itemize}
    \item $N$ is a finite set of nonterminals
    \item $\Sigma$ is a finite set of terminals
    \item $P$ is a finite set of productions of the following forms: $A \to \alpha, ~A \in N,~ \alpha \in (N \cup \Sigma)^*$
    \item $S$ is a start nonterminal
\end{itemize} \qed
\end{definition}

\begin{definition} \emph{Context-free language} is a language generated by a context-free grammar $G$:
\begin{align*}
     L(G) = \{w \in \Sigma^* \mid S \xLongrightarrow[G]{*} w \} 
\end{align*}
Where $S \xLongrightarrow[G]{*} w$  denotes that a string $w$ can be generated from a starting non-terminal $S$ using some sequence of production rules from $P$. \qed
\end{definition}

\begin{definition} Context-free grammar $G = (N, \Sigma, P, S)$ is said to be in \emph{Chomsky normal form} if all productions in $P$ are in one of the following forms:
    \begin{itemize}
        \item $A \rightarrow BC,~A \in N,~B,~C \in N \setminus S$
        \item  $A \rightarrow a,~A \in N,~a \in \Sigma$
        \item $S \rightarrow \varepsilon, where \varepsilon$ is an identity element of $\Sigma^*$, or an empty string.
    \end{itemize}\qed
\end{definition}

\begin{definition} Context-free grammar $G = (N, \Sigma, P, S)$ is said to be in \emph{weak Chomsky normal form} if all productions in $P$ are in one of the following forms:
    \begin{itemize}
        \item $A \rightarrow BC,~A,~B,~C \in N$
        \item  $A \rightarrow a,~A \in N,~a \in \Sigma$
        \item $A \rightarrow \varepsilon,~A \in N$
    \end{itemize} \qed
\end{definition}

In other words, weak Chomsky normal form differs from Chomsky normal form in the following:
\begin{itemize}
    \item $\varepsilon$ can be derived from any non-terminal;
    \item $S$ can be at a right part of productions.
\end{itemize}

Since matrix-based CFPQ algorithms processes grammars only in weak Chomsky normal form, it should be noted that every context-free grammar can be transformed into an equivalent one in this form. 

Consider the following example of the context-free grammar $G_1=(N, \Sigma, P, S), where ~N=\{S\},~\Sigma=\{c, d, y\}$, and $P$ contains two rules: 
\begin{align}
\label{eqn:g1_example}
S \rightarrow c \ S \ d \nonumber\\
S \rightarrow c \ y \ d
\end{align}

This grammar generates the context-free language $$L(G_1) = \{c^nyd^n, n \in \mathbb{N}\}.$$
One can get the following grammar as a result of the transformation of the $G_1$ to weak Chomsky normal form:

\begin{align*}
S& \to C \ E   & C& \to c   \\
S& \to C \ S_1 & Y& \to y   \\
E& \to Y \ D   & D& \to d   \\ 
S_1& \to S \ D &&
\end{align*}


\subsection{Context-Free Path Querying}

\begin{definition}
Let $D = (V, E, \Sigma_V, \Sigma_E, \lambda_V, \lambda_E)$ be a labeled graph, $G = (N, \Sigma_V \cup \Sigma_E, P, S)$ be a context free grammar. Then a \emph{context free relation} with grammar $G$ on the labeled graph $D$ is the following relation $R_{G, D} \subseteq V \times V$:

\begin{equation*} \label{eq1}
\begin{split}
R_{G, D} = \{&(v, to) \in V \times V \mid \exists \pi = (v_1, e_1, v_2, e_2, \ldots, e_n, v_n) \in \pi(D): \\
      &v_1 = v, v_n = to,~l(\pi) \cap L(G) \neq \varnothing \},
\end{split}
\end{equation*}
where $l(\pi) \subset (\Sigma_V \cup \Sigma_E)^*$ is the set of possible labels along the path $\pi$:
$$l(\pi) = \lambda_V(v_1)^* \cdot \lambda_E(e_1) \cdot \lambda_V(v_2)^* \cdot \lambda_E(e_2) \cdot \ldots \cdot \lambda_E(e_n) \cdot \lambda_V(v_n)^*$$
\qed
\end{definition}


For example, in the labeled graph presented in figure~\ref{fig:example_input_graph} there is the path $$\pi=3 \xrightarrow{\{c\}} 5:\{y\} \xrightarrow{\{d\}} 6$$ from the vertex 3 to vertex 6.
Labels along this path form the sequence $cyd$.
It can be observed that this sequence satisfies context-free constraints of the above grammar $G_1$:
    \begin{align*}
         S \Rightarrow CE \Rightarrow cE \Rightarrow cYD \Rightarrow cyD \Rightarrow cyd
    \end{align*}
Hence $l(\pi) \cap L(G_1) \neq \varnothing$ and the pair $(3,6) \in R_{G_1, D}$.

Note that the proposed definition, namely zero or more repetition of each vertex label allows one freely omit labels or use them in arbitrary order in case when there are more then one label for vertex. 
On the other hand, it makes valid queries that use one label more than ones. 
In some cases such behavior may looks strange, but it depends on semantics on query language, so we argue that it is necessary to formalize semantics of graph query language first, which is task for the future.  

Finally, we are can define context-free path querying problem as follows. 
\begin{definition}
    \emph{Context-free path querying problem} is the problem of finding context-free relation $R_{G, D}$ for a given directed labeled graph $D$ and a given context-free grammar $G$. \qed
\end{definition} 

In other words, the result of context-free path query evaluation is a set of vertex pairs such that there is a path between them and this path forms a word from the given language.
    
For graph $D_1$ and context-free free grammar $G_1$ the relation $$R_{G_1, D_1} = \{(2, 4), (2, 5), (3, 4), (3, 5), (4, 4), (4, 5)\}.$$ 
Note that any relation $R_{G, D}$ can be represented as a Boolean matrix: $$T[i,j] = 1 \iff (i,j) \in R_{G, D}.$$
In our example, $R_{G_1, D_1}$ can be represented as follows:
\begin{align*}
T =
\begin{pmatrix}
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & . & . & 1 & 1 \\
    . & . & . & . & 1 & 1 \\ 
    . & . & . & . & 1 & 1 \\ 
    . & . & . & . & . & .
\end{pmatrix}.
\end{align*}

In case when one restricts a set of start vertices we can say about \textit{multiple-source context-free path querying}.

\begin{definition}
    Suppose $Src$ is a given set of start vertices, then \textit{multiple-source context-free path querying problem} for the given $Src$ is the problem of finding context-free relation $$R_{G, D}^{Src} \subseteq Src\times V \subseteq R_{G,D}$$ for a given directed labeled graph $D$ and a given context-free grammar $G$. Namely, we restrict start vertices of the paths of interest to be a vertices from the given set\qed
\end{definition}

As a partial case, one can get a single-source version of CFPQ by restrict $Src$ to be a set of one element. 
If in the previous example we set $Src=\{2\}$, then the result is $$R_{G_1, D_1}^{\{2\}} = \{(2, 4), (2, 5)\}.$$ 
For unification we can represent the $R_{G_1, D_1}^{\{2\}}$ as a Boolean matrix:

\begin{align*}
T =
\begin{pmatrix}
    . & . & . & . & . & . \\
    . & . & . & . & . & . \\
    . & . & . & . & 1 & 1 \\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & . \\ 
    . & . & . & . & . & .
\end{pmatrix}.
\end{align*}
 
\subsection{Matrix-Based Algorithm}
Our algorithm is based on the Azimov's CFPQ algorithm~\cite{Azimov:2018:CPQ:3210259.3210264} which is based on matrix operations.
This algorithm allows one to use high-performance linear algebra libraries and utilize modern parallel hardware for CFPQ.

Let $G = (N, \Sigma, P, S)$ be the input grammar, the input edge-labeled graph $D = (V, E, \Sigma_V, \Sigma_E, \lambda_V, \lambda_E)$ and language $L$ over alphabet $\Sigma$.
The matrix-based algorithm for CFPQ can be expressed in terms of operations over Boolean matrices as showed in listing~\ref{alg:algo0}. 
This fact simplifies implementation of the algorithm.

{\footnotesize
\begin{algorithm}
\begin{algorithmic}[1]
\caption{Context-free path querying algorithm}
\label{alg:algo0}
\Function{evalCFPQ}{$D=(V,E, \Sigma_V, \Sigma_E, \lambda_V, \lambda_E), G=(N,\Sigma,P,S)$}
    \State{$n \gets$ |V|}
    \State{$T \gets \{T^{A_i} \mid A_i \in N, T^{A_i}$ is a matrix $n \times n$, $T^{A_i}_{k,l} \gets$ \texttt{false}\} }
    \ForAll{$(i,j) \in E$, $A_k \mid \lambda_E(i,j) = x, A_k \to x \in P$}
        %\Comment{Matrices initialization}
        %\For{$A_k \mid A_k \to x \in P$}
          {$T^{A_k}_{i,j} \gets \texttt{true}$}
        %\EndFor
    \EndFor
    \ForAll{$A_k \mid A_k \to \varepsilon \in P$}
        \ForAll{$i \in \{0,\ldots ,n-1\}$}
            {$T^{A_k}_{i,i} \gets \texttt{true}$}
        \EndFor
    \EndFor

    \While{any matrix in $T$ is changing}
        %\Comment{Transitive c	losure calculation}
        \For{$A_i \to A_j A_k \in P$}
          { $T^{A_i} \gets T^{A_i} + (T^{A_j} \times T^{A_k})$ } 
        \EndFor
    \EndWhile
\State \Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}
}

Note, that the provided algorithm returns not only context-free relation $R_{G,D}$ but a set of context-free relations $R_{A,D} \subseteq V \times V$ for every $A \in N$, thus it provides information about paths which worm words derivable from any nonterminal in the given grammar.
Also, this algorithm handles only edge labels.

As was shown by Nikita Mishin et al.~\cite{Mishin:2019:ECP:3327964.3328503} and Arseniy Terekhov et al.~\cite{ 10.1145/3398682.3399163}, this algorithm can be implemented using various high-performance programming techniques (including GPGPU utilization), and it is applicable for real-world graph analysis.
But this algorithm solves \textit{all-pairs} version of CFPQ: it finds all pairs of vertices in the given graph, such that there exist a paths between them which forms a word in the given language.
Thus it is impractical in cases when we need only paths which start from specific set of vertices, especially if this set is relatively small. 
Moreover, Azimov's algorithm operates over adjacency matrices of full graphs, as a result it requires a huge amount of memory, which may be a problem for real-world graph database.
\section{Preliminaries}

In this section we introduce common definitions in graph theory and formal language theory which will be used in this paper. 
Also, we provide brief description of Azimov's algorithm which is used as a base of our solution.

\subsection{basic Definitions of Graph Theory}

In this work we use labeled directed graph as a data model and define it as follows.
\begin{definition} \emph{Labeled directed graph} is a tuple of six elements $D = (V, E, \Sigma_V, \Sigma_E, \lambda_V, \lambda_E)$, where
\begin{itemize}
    \item $\Sigma_V$ and $\Sigma_E$ is a set of labels of vertices and edges respectively, such that $\Sigma_V \cap \Sigma_E = \varnothing$.
    \item $V$ is a set of vertices. For simplicity, we assume that the vertices are natural numbers from $1$ to $|V|$.
    \item $E \subseteq V \times V$ is a set of edges.
    \item $\lambda_V : V \xrightarrow{} 2^{\Sigma_V}$ is a function that maps a vertex to a set of its labels, which can be empty.
    \item $\lambda_E : E \xrightarrow{} 2^{\Sigma_E} \setminus \{\varnothing\}$ is a function that maps a edge to a not empty set of its labels, so each edge must have at least one label.
\end{itemize}
\end{definition}

An example of the labeled directed graph $\mathcal{D}$ is presented in figure~\ref{fig:example_input_graph}. Here the set of labels $\Sigma_V = \{x, y\}$ and $\Sigma_E = \{a, b, c, d\}$.

\begin{figure}[h]
    \centering        
    \begin{tikzpicture}[shorten >=1pt,auto]
       \node[state] (q_0)                        {$1:\{x, y\}$};
       \node[state] (q_1) [right=of q_0]         {$2$};
       \node[state] (q_2) [below left=of q_1]    {$3: \{x\}$};
       \node[state] (q_3) [below left=of q_2]    {$4$};
       \node[state] (q_4) [below right=of q_2]   {$5: \{y\}$};
       \node[state] (q_5) [below right=of q_1]   {$6$};
       \path[->]
        (q_0) edge  node {$\{a\}$} (q_1)
        (q_1) edge  node {$\{b\}$} (q_5)
        (q_1) edge  node {$\{a, b\}$} (q_2)
        (q_3) edge[above]  node {$\{c\}$} (q_2)
        (q_4) edge  node {$\{c\}$} (q_3)
        (q_2) edge[above]  node {$\{c\}$} (q_4)
        (q_5) edge[bend left, below]  node {$\{d\}$} (q_4)
        (q_4) edge[bend left, above]  node {$\{d\}$} (q_5);
    \end{tikzpicture}
    \caption{The example of input graph $\mathcal{D}$}
    \label{fig:example_input_graph}
\end{figure}

% We use adjacency matrix decomposed to a set of a boolean matrix as a representation of the graph. 

Let's denote $D$ as a labeled directed graph $(V, E, \Sigma_V, \sigma_E, \lambda_E, \lambda_V)$ for the following definitions. Also we identify a Boolean $|V| \times |V|$ matrix $A$ and binary relation $R \in V \times V$ in the following way:
$$A \equiv R \iff R = \{(i, j) \mid A[i, j] = 1\}$$.

\begin{definition}
Path $\pi$ in the graph $D$ is a tuple of arbitrary $2n +1$ length $(v_1, e_1, v_2, e_2, ..., e_n, v_{n+1})$, where $\forall i \mid 1 \leq n+1 ~ v_i \in V$, $\forall j \mid 1 \leq j \leq n ~ e_j=(v_j, v_{j+1}) \in E$.

We denote the set of all possible paths in the graph $D$ as $\pi(D)$. 
\end{definition}

\begin{definition}
An \emph{adjacency matrix} $M$ of the graph $D$ is a square $|V|\times|V|$ matrix, such that 
\begin{equation*}
M[i,j] =
 \begin{cases}
   \lambda_E((i, j)), & (i, j) \in E\\
   \varnothing, & else
 \end{cases}
\end{equation*}
\end{definition}

For example adjacency matrix $M$ of the example graph $\mathcal{D}$ is

$$
    M =
    \begin{pmatrix}
    \varnothing     & \{a\} &   \varnothing      &   \varnothing   &   \varnothing   &   \varnothing   \\
    \varnothing     &   \varnothing   & \{a, b\} &   \varnothing   &       & \{b\} \\
    \varnothing     &   \varnothing   &   \varnothing      &   \varnothing   & \{d\} &   \varnothing   \\
    \varnothing     &   \varnothing   & \{c\}    &   \varnothing   &   \varnothing   &   \varnothing   \\
    \varnothing     &   \varnothing   &   \varnothing      & \{c\} &   \varnothing   & \{d\} \\
    \varnothing     & \varnothing     &   \varnothing      &   \varnothing   & \{d\} &   \varnothing
    \end{pmatrix}.
$$

\begin{definition}
Let M be an adjacency matrix of the graph $D$. Then the \emph{adjacency matrix of label} $l \in \Sigma_E$ of graph $D$ is a $|V| \times |V|$ matrix $\mathcal{E}^l$, such that
\begin{equation*}
\mathcal{E}^l[i,j] =
 \begin{cases}
   1, & l \in M[i,j]\\
   0, & else
 \end{cases}
\end{equation*}
\end{definition}

\begin{definition}
\emph{Boolean decomposition of adjacency matrix} $M$ of the graph $D$ is a set of Boolean matrices $$\mathcal{E} = \{\mathcal{E}^l \mid l \in \Sigma\},$$
where $\mathcal{E}^l$ is the adjacency matrix of label $l$.
\end{definition}

For example, adjacency matrix $M$ of the example graph $\mathcal{D}$ can be represented as a set of four Boolean matrices $\mathcal{E}^a$, $\mathcal{E}^b$, $\mathcal{E}^c$ and $\mathcal{E}^d$ such that 
\begin{align*}
\mathcal{E}^a =
\begin{pmatrix}
    . & . & . & . & . & .   \\
    1 & . & . & . & . & . \\
    . & 1 & . & . & . & .\\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & . \\ 
    . & . & . & . & . & .
\end{pmatrix},~  
\mathcal{E}^b =
\begin{pmatrix}
    . & . & . & . & . & .   \\
    . & . & . & . & . & . \\
    . & 1 & . & . & . & .\\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & . \\ 
    . & 1 & . & . & . & .
\end{pmatrix},\\
\mathcal{E}^c =
\begin{pmatrix}
    . & . & . & . & . & .   \\
    . & . & . & . & . & . \\
    . & . & . & 1 & . & .\\
    . & . & . & . & 1 & . \\ 
    . & . & 1 & . & . & . \\ 
    . & . & . & . & . & .
\end{pmatrix},~ 
\mathcal{E}^d =
\begin{pmatrix}
    . & . & . & . & . & .   \\
    . & . & . & . & . & . \\
    . & . & . & . & . & .\\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & 1 \\ 
    . & . & . & . & 1 & .
\end{pmatrix}.
\label{eq:boolean_decomposition_of_graph}
\end{align*}

\begin{definition}

An \emph{vertex label matrix} $H$ of the graph $D$ is a square $|V|\times|V|$ matrix, such that 
\begin{equation*}
H[i,j] = 
  \begin{cases}
    \lambda_V (i), & i = j \\
    \varnothing,     & else
  \end{cases}
\end{equation*}

For example, the vertex label matrix $H$ of the example graph $\mathcal{D}$ is the following:
$$
    H =
    \begin{pmatrix}
    \{x, y\}        & \varnothing     &   \varnothing      &   \varnothing   &   \varnothing   &    \varnothing  \\
    \varnothing     &   \varnothing   & \varnothing        &   \varnothing   & \varnothing     & \varnothing     \\
    \varnothing     &   \varnothing   &   \{x\}            &   \varnothing   & \varnothing     &   \varnothing   \\
    \varnothing     &   \varnothing   & \varnothing        &   \varnothing   &   \varnothing   &   \varnothing   \\
    \varnothing     &   \varnothing   &   \varnothing      &    \varnothing  &   \{y\}         & \varnothing     \\
    \varnothing     & \varnothing     &   \varnothing      &   \varnothing   & \varnothing     &   \varnothing
    \end{pmatrix}.
$$
\end{definition}

\begin{definition}
Let $H$ be a vertex label matrix of graph $D$. Then the \emph{vertex matrix of label} $l$ is a square $|V|\times|V|$ matrix $\mathcal{V}^l$, such that
\begin{equation*}
\mathcal{V}^l[i,j] = 
  \begin{cases}
    1,  & l \in H[i, j] \\
    0,  & else
  \end{cases}
\end{equation*}
\end{definition}

\begin{definition}
Boolean decomposition of vertex label matrix $H$ of the graph $D$ is the set of Boolean matrices
$$\mathcal{V} = \{V^l \mid l \in \Sigma\},$$
where $\mathcal{V}^l$ is a vertex matrix of label $l$.
\end{definition}

For example, vertex label matrix $H$ of the example graph $\mathcal{D}$ can be decomposed into a set of the following boolean matrices:

\begin{align*}
\mathcal{V}^x =
\begin{pmatrix}
    1 & . & . & . & . & .   \\
    . & . & . & . & . & . \\
    . & . & 1 & . & . & .\\
    . & . & . & . & . & . \\ 
    . & . & . & . & . & . \\ 
    . & . & . & . & . & .
\end{pmatrix},~ 
\mathcal{V}^y =
\begin{pmatrix}
    . & . & . & . & . & .   \\
    . & . & . & . & . & . \\
    . & . & . & . & . & .\\
    . & . & . & . & . & . \\ 
    . & . & . & . & 1 & . \\ 
    . & . & . & . & . & .
\end{pmatrix},  \label{eq:boolean_decomposition_of_graph}
\end{align*}

\subsection{Basic Definitions of Formal Languages}
We formulate constraints in terms of context-free languages, for this reason there are following definitions.

\begin{definition}
Let $\Sigma$ be a alphabet, $A, B$ $\subset \Sigma^*$. Then concatenation of $A$ and $B$ is the following:

$$A \cdot B = \{a b \mid a \in A, b \in B\} \subset \Sigma^*$$

In other worlds concatenation of two sets contains all concatenations of elements from the first set with all elements from the second one.

\end{definition}

\begin{definition}\emph{Context-free grammar} is a 4-tuple $G=(N, \Sigma, P, S)$, where 
\begin{itemize}
    \item $N$ is a finite set of nonterminals
    \item $\Sigma$ is a finite set of terminals
    \item $P$ is a finite set of productions of the following forms: $A \to \alpha, ~A \in N,~ \alpha \in (N \cup \Sigma)^*$
    \item $S$ is a starting nonterminal
\end{itemize}
\end{definition}

\begin{definition} \emph{Context-free language} is a language generated by a context-free grammar $G$:
\begin{align*}
     L(G) = \{w \in \Sigma^* \mid S \xLongrightarrow[G]{*} w \} 
\end{align*}
Where $S \xLongrightarrow[G]{*} w$  denotes that a string $w$ can be generated from a starting non-terminal $S$ using some sequence of production rules from $P$.
\end{definition}
\begin{definition} Context-free grammar $G = (N, \Sigma, P, S)$ is said to be in \emph{Chomsky normal form} if all productions in $P$ are in one of the following forms:
    \begin{itemize}
        \item $A \rightarrow BC,~A \in N,~B,~C \in N \setminus S$
        \item  $A \rightarrow a,~A \in N,~a \in \Sigma$
        \item $S \rightarrow \varepsilon,~\varepsilon$ is an identity element of $\Sigma^*$ that correspondes to empty string
    \end{itemize}
\end{definition}
 Since matrix-based CFPQ algorithms processes grammars only in Chomsky normal form, it should be noted that every context-free grammar can be transformed into an equivalent one in this form. 
\begin{definition} Context-free grammar $G = (N, \Sigma, P, S)$ is said to be in \emph{weak Chomsky normal form} if all productions in $P$ are in one of the following forms:
    \begin{itemize}
        \item $A \rightarrow BC,~A,~B,~C \in N$
        \item  $A \rightarrow a,~A \in N,~a \in \Sigma$
        \item $A \rightarrow \varepsilon,~A \in N$
    \end{itemize}
\end{definition}
In other words, weak Chomsky normal form differs from Chomsky normal form in the following:
\begin{itemize}
    \item $\varepsilon$ can be derived from any non-terminal
    \item $S$ can be at a right part of productions
\end{itemize}

We use a context-free grammar in the weak Chomsky normal form without a starting non-terminal, which will be specified in the path queries for the graph. Also we omit the rules of the form $A \rightarrow \varepsilon$ for the reason that they correspond to trivial paths, which are more convenient to consider separately.

\subsection{Context-Free Path Querying}


\begin{definition}
Let $D = (V, E, \Sigma_V, \Sigma_E, \lambda_V, \lambda_E)$ be a labeled graph, $G = (N, \Sigma_V \cup \Sigma_E, P, S)$ be a context free grammar. Then a \emph{context free relation} with grammar $G$ on the labeled graph $D$ is the following relation $R_A \subseteq V \times V$:

\begin{equation*} \label{eq1}
\begin{split}
R_A = \{&(v, to) \in V \times V \mid \exists \pi = (v_1, e_1, v_2, e_2, ..., e_n, v_n) \in \pi(D): \\
      &v_1 = v, v_n = to,~l(\pi) \cap L(G) \neq \varnothing \},
\end{split}
\end{equation*}
where $l(\pi) \subset (\Sigma_V \cup \Sigma_E)^*$ is the set of possible labels along the path $\pi$:
$$l(\pi) = \lambda_V(v_1)^* \cdot \lambda_E(e_1) \cdot \lambda_V(v_2)^* \cdot \lambda_E(e_2) \cdot ... \cdot \lambda_E(e_n) \cdot \lambda_V(v_n)^*$$

For example, for the graph presented in figure~\ref{fig:example_input_graph} let's consider a query, formulated as a context-free grammar, which generates the language $L(G) = \{c^nyd^n, n \in \mathbb{N}\}$:
$G=(N, \Sigma, P, S), ~N=\{S\},~\Sigma=\{c, d, y\}$ and productions: 
\begin{align*}
S \rightarrow cSd\\
S \rightarrow cyd
\end{align*}
After transformation to weak Chomsky normal form the resulting grammar:
\begin{gather*}
S \rightarrow CE \quad E \rightarrow YD  \quad S \rightarrow CS_1 \quad S_1 \rightarrow SD \\
C \rightarrow c \quad D \rightarrow d \quad Y \rightarrow y
\end{gather*}

These productions itself are the grammar that has the same result as original grammar.

In this example, considering the vertex 3 as the starting vertex, we can see that, there are following relations and strings, formed with edge and vertex labels (note that there is also empty string at each vertex label):
\begin{itemize}
    \item $(3,6),~l(\pi) = cyd$ 
    \item $(3,5),~l(\pi) = ccccydddd$,  etc
\end{itemize}

\end{definition}

Finally, in these notations context-free path querying problem is the problem of finding context-free relations in which the language is specified by a context-free grammar, in other words, the result of context-free path query evaluation is a set of vertex pairs such that there is a path between them and its labels form a word from the language.
 
\subsection{Matrix-Based Algorithm}
Let $G = (N, \Sigma, P)$ be the input grammar, $D = (V, E)$ be the input edge-labeled graph and language $L$ over alphabet $\Sigma$. For the context-free path query evaluation, we need to provide context-free relations \mbox{$R_A \subseteq V \times V$} for every \mbox{$A \in N$}.
The matrix-based algorithm for CFPQ can be expressed in terms of operations over Boolean matrices (see listing~\ref{alg:algo0}) which is an advantage for implementation.
{\footnotesize
\begin{algorithm}
\begin{algorithmic}[1]
\caption{Context-free path querying algorithm}
\label{alg:algo0}
\Function{evalCFPQ}{$D=(V,E), G=(N,\Sigma,P)$}
    \State{$n \gets$ |V|}
    \State{$T \gets \{T^{A_i} \mid A_i \in N, T^{A_i}$ is a matrix $n \times n$, $T^{A_i}_{k,l} \gets$ \texttt{false}\} }
    \ForAll{$(i,x,j) \in E$, $A_k \mid A_k \to x \in P$}
        %\Comment{Matrices initialization}
        %\For{$A_k \mid A_k \to x \in P$}
          {$T^{A_k}_{i,j} \gets \texttt{true}$}
        %\EndFor
    \EndFor
    \ForAll{$A_k \mid A_k \to \varepsilon \in P$}
        \ForAll{$i \in \{0,\ldots ,n-1\}$}
            {$T^{A_k}_{i,i} \gets \texttt{true}$}
        \EndFor
    \EndFor

    \While{any matrix in $T$ is changing}
        %\Comment{Transitive c	losure calculation}
        \For{$A_i \to A_j A_k \in P$}
          { $T^{A_i} \gets T^{A_i} + (T^{A_j} \times T^{A_k})$ } 
        \EndFor
    \EndWhile
\State \Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}
}

This CFPQ algorithm allows efficiently apply GPGPU techniques, but it solves all-pairs problem and takes unreasonable amount of memory in scenarios in which we want to find paths from a relatively small set of vertices, since it calculates a lot of redundant information.  
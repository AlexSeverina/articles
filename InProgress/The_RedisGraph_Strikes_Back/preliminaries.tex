\section{Preliminaries}

In this section we introduce common definitions in graph theory and formal language theory which will be used in this paper. 
Also, we provide brief description of Azimov's algorithm which is used as a base of our solution.

\subsection{Graphs}

In this work we use labelled digraph as a data model and define it as follows.
\begin{definition} \emph{Labeled directed graph} is a triple $D = (V, E, \lambda)$, where
\begin{itemize}
    \item $V$ is a set of vertices. For simplicity, we assume that the vertices are natural numbers.
    \item $E \subseteq V \times V$ is a set of edges
    \item $\lambda : (E\cup V) \xrightarrow{} 2^\Sigma$ is a function that maps edges and vertices to their labels from the label set $\Sigma$.
\end{itemize}
\end{definition}

An example of the graph is presented in figure~\ref{fig:example_input_graph}. Here the set of labels $\Sigma = \{A, B, C, D\}$ and the set of vertices $V = \{v_0, v_1, v_2, v_3, v_4, v_5\}$.

\begin{figure}[h]
    \centering        
    \begin{tikzpicture}[shorten >=1pt,auto]
       \node[state] (q_0)                        {$1$};
       \node[state] (q_1) [right=of q_0]         {$2$};
       \node[state] (q_2) [below left=of q_1]    {$3$};
       \node[state] (q_3) [below left=of q_2]    {$4$};
       \node[state] (q_4) [below right=of q_2]   {$5$};
       \node[state] (q_5) [below right=of q_1]   {$6$};
        \path[->]
        (q_0) edge  node {$A$} (q_1)
        (q_1) edge  node {$B$} (q_5)
        (q_1) edge  node {$B$} (q_2)
        (q_3) edge[above]  node {$C$} (q_2)
        (q_4) edge  node {$C$} (q_3)
        (q_2) edge[above]  node {$C$} (q_4)
        (q_5) edge[bend left, below]  node {$D$} (q_4)
        (q_4) edge[bend left, above]  node {$D$} (q_5);
    \end{tikzpicture}
    \caption{The example of input graph $\mathcal{G}$}
    \label{fig:example_input_graph}
\end{figure}

We use adjacency matrix decomposed to a set of a boolean matrix as a representation of the graph.
\begin{definition}
An adjacency matrix $M$ of the labelled graph $\mathcal{G}=(V, E, \lambda)$ is a square $|V|\times|V|$ matrix, such that $M[i,j] = \lambda((i, j))$.
\end{definition}

Adjacency matrix $M$ of the graph $\mathcal{G}$ is

$$
    M =
    \begin{pmatrix}
    .     & \{A\} &   .   &   .   &   .   &   .   \\
    .     &   .   & \{B\} &   .   &       & \{B\} \\
    .     &   .   &   .   &   .   & \{C\} &   .   \\
    .     &   .   & \{C\} &   .   &   .   &   .   \\
    .     &   .   &   .   & \{C\} &   .   & \{D\} \\
    .     & .     &   .   &   .   & \{D\} &   .
    \end{pmatrix}.
$$

\begin{definition}

Boolean decomposition of adjacency matrix $M$ of graph $\mathcal{G}=(V, E, \lambda)$ is set of Boolean matrix $$\mathcal{M} = \{M^l \mid l \in \Sigma, M^l[i,j]=1 \iff l \in M[i,j]\}.$$

\end{definition}

Matrix $M$ can be represented as a set of two Boolean matrices $M^a$ and $M^b$ where
\begin{align}
& M^{A} =    
\begin{pmatrix}
    .     &   1   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .
\end{pmatrix}, 
M^{B} =
\begin{pmatrix}
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   1   &   .   &   .   &   1   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .
\end{pmatrix} \\
& M^{C} =
\begin{pmatrix}
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   1   &   .   \\
    .     &   .   &   1   &   .   &   .   &   .   \\
    .     &   .   &   .   &   1   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .
\end{pmatrix},
M^{D} =
\begin{pmatrix}
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   .   \\
    .     &   .   &   .   &   .   &   .   &   1   \\
    .     &   .   &   .   &   .   &   1   &   .
\end{pmatrix}.
\label{eq:boolean_decomposition_of_graph}
\end{align}

\begin{definition}

An vertex label matrix $N$ of the labelled graph $\mathcal(G)=(V, E, \lambda)$ is a square $|V|\times|V|$ matrix, such that $N[i,i] = \lambda (i)$ and $N[i,j] = \emptyset$ for $i \neq j$.

\end{definition}

\begin{definition}

Boolean decomposition of vertex label matrix $N$ of graph $\mathcal{G}=(V, E, \lambda)$ is set of Boolean matrix $$\mathcal{N} = \{N^l \mid l \in \Sigma, N^l[i,j]=1 \iff l \in N[i,j]\}.$$

\end{definition}

\subsection{Languages}
\begin{definition}\emph{Context-free grammar} is a 4-tuple $G=(N, \Sigma, R, S)$, where 
\begin{itemize}
    \item $N$ is a set of nonterminals
    \item $\Sigma$ is a set of terminals
    \item $R$ is a finite set of productions of the followings form: $A \to \alpha$, $A \in N,~ \alpha \in (N \cup \Sigma)^*$
    \item $S$ - a starting nonterminal
\end{itemize}
\end{definition}
\begin{definition} Context-free grammar $G = (N, \Sigma, R, S)$ is said to be in \emph{Chomsky normal form} if all productions in $R$ are of the form: $A \rightarrow BC$, $A \rightarrow a$, or $S \rightarrow \varepsilon$, where $A, B, C \in N, a \in \Sigma, \varepsilon$ is an empty string.
\end{definition}

For example, we have the following context-free grammar:
\begin{align*}
S \rightarrow AB \mid a \\
B \rightarrow b 
\end{align*}
After transformation to Chomsky Normal Form the resulting grammar:
\begin{align*}
S \rightarrow a
\end{align*}

This production itself is a grammar that has the same result, which is ${a}$, as original grammar.

We use a context-free grammar in Chomsky Normal Form that does not include a starting non-terminal, which will be specified in the path queries for the graph. Note that every context-free grammar can be transformed into an equivalent one in Chomsky Normal Form. Since only the empty paths correspond to empty string omitting the rules of the form \mbox{$A \rightarrow \varepsilon$} does not restrict the applicability of the algorithms.


\subsection{Matrix-Based Algorithm}

Let $D = (V, E)$ be the input graph and $G = (N, \Sigma, P, S)$ be the input grammar. For a given graph and a context-free grammar, we define \emph{context-free relations} \mbox{$R_A \subseteq V \times V$} for every \mbox{$A \in N$}, such that $R_A = \{(n,m)~|~\exists n \pi m~(l(\pi) \in L(G_A))\}$. For the context-free path query evaluation, we must provide such a path for each node pair from $R_A$.

The matrix-based algorithm for CFPQ can be expressed in terms of operations over Boolean matrices (see listing~\ref{alg:algo0}) which is an advantage for implementation.
{\footnotesize
\begin{algorithm}
\begin{algorithmic}[1]
\caption{Context-free path querying algorithm}
\label{alg:algo0}
\Function{evalCFPQ}{$D=(V,E), G=(N,\Sigma,P)$}
    \State{$n \gets$ |V|}
    \State{$T \gets \{T^{A_i} \mid A_i \in N, T^{A_i}$ is a matrix $n \times n$, $T^{A_i}_{k,l} \gets$ \texttt{false}\} }
    \ForAll{$(i,x,j) \in E$, $A_k \mid A_k \to x \in P$}
        %\Comment{Matrices initialization}
        %\For{$A_k \mid A_k \to x \in P$}
          {$T^{A_k}_{i,j} \gets \texttt{true}$}
        %\EndFor
    \EndFor
    \ForAll{$A_k \mid A_k \to \varepsilon \in P$}
        \ForAll{$i \in \{0,\ldots ,n-1\}$}
            {$T^{A_k}_{i,i} \gets \texttt{true}$}
        \EndFor
    \EndFor

    \While{any matrix in $T$ is changing}
        %\Comment{Transitive c	losure calculation}
        \For{$A_i \to A_j A_k \in P$}
          { $T^{A_i} \gets T^{A_i} + (T^{A_j} \times T^{A_k})$ } 
        \EndFor
    \EndWhile
\State \Return $T$
\EndFunction
\end{algorithmic}
\end{algorithm}
}

This CFPQ algorithm allows efficiently apply GPGPU techniques, but it solves all-pairs problem and takes unreasonable amount of memory in scenarios in which we want to find paths from a relatively small set of vertices, since it calculates a lot of redundant information. 
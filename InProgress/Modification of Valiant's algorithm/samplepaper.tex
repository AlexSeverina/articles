% This is samplepaper.tex, a sample chapter demonstrating the
% LLNCS macro package for Springer Computer Science proceedings;
% Version 2.20 of 2017/10/04
%
\documentclass[runningheads]{llncs}
%
\usepackage{graphicx}


% Package to generate and customize Algorithm as per ACM style
\usepackage[ruled, linesnumbered]{algorithm2e}
\renewcommand{\algorithmcfname}{Algorithm}
\SetAlFnt{\small}
\SetAlCapFnt{\small}
\SetAlCapNameFnt{\small}
\SetAlCapHSkip{0pt}
\IncMargin{-\parindent}
% Used for displaying a sample figure. If possible, figure files should
% be included in EPS format.
%
% If you use the hyperref package, please uncomment the following line
% to display URLs in blue roman font according to Springer's eBook style:
% \renewcommand\UrlFont{\color{blue}\rmfamily}

\begin{document}
%
\title{Parsing by matrix multiplication for the string-matching problem\thanks{Supported by organization x.}}
%
%\titlerunning{Abbreviated paper title}
% If the paper title is too long for the running head, you can set
% an abbreviated paper title here
%
\author{First Author\inst{1}\orcidID{0000-1111-2222-3333} \and
Second Author\inst{2,3}\orcidID{1111-2222-3333-4444} \and
Third Author\inst{3}\orcidID{2222--3333-4444-5555}}
%
\authorrunning{F. Author et al.}
% First names are abbreviated in the running head.
% If there are more than two authors, 'et al.' is used.
%
\institute{Princeton University, Princeton NJ 08544, USA \and
Springer Heidelberg, Tiergartenstr. 17, 69121 Heidelberg, Germany
\email{lncs@springer.com}\\
\url{http://www.springer.com/gp/computer-science/lncs} \and
ABC Institute, Rupert-Karls-University Heidelberg, Heidelberg, Germany\\
\email{\{abc,lncs\}@uni-heidelberg.de}}
%
\maketitle              % typeset the header of the contribution
%
\begin{abstract}
The abstract should briefly summarize the contents of the paper in
15--250 words.

\keywords{Parsing  \and Matrix multiplication \and Context-free grammars \and String-matching \and Bioinformatics.}
\end{abstract}
%
%
%
\section{Introduction}

Since the theory of context-free grammars was developed by Noam Chomsky, its utility has been extensively studied. The classic application of context-free grammars is describing natural and programming  languages. Recent  research  has  shown  that the theory of formal languages and, in particular, context-free languages can be used in bioinformatics. For example, parsing is applicable to DNA and RNA processing. The secondary structure of the nucleotide sequence contains information about the organism species, therefore, it can be used in solving the recognition and classification problems. Moreover, in terms of parsing, the secondary structure can be described by some context-free grammar.

Such field of application as bioinformatics requires working with large amount of data. That is why it is important not only to develop more efficient recognition or parsing algorithms, but also to adapt the existing ones to new problems that come with the new application areas.

At this moment the asymptotically fastest parsing algorithm that can be applied to any context-free grammar was proposed by Leslie Valiant~\cite{valiant}. The algorithm computes the parsing table for a linear input, where each element of this table is responsible for deriving a particular substring. By offloading the most time-consuming computations on a Boolean matrix multiplication, Valiant has achieved an improvement in time complexity, which is O(BMM(n)log(n)) for an input string of size n, where BMM(n) is the number of operations needed to multiply two Boolean matrices of size n Ã— n. Nevertheless, this algorithm also has some drawbacks, for example, adaptation to the string-matching problems. 

This  paper  aims  to  present  a  modification  of  Valiant's  algorithm partially dealing with the problem described above. We divide the parsing table into successively computed layers of disjoint submatrices of the same size through the reorganization of the matrix multiplication order. Thus, we can suspend the modification execution as soon as the layer we need was computed. Moreover, all submatrices in layer can be processed independently and further it allow to use GPGPU (General-Purpose computing on Graphics Processing Units) and parallel computation.

We make the following contribution:
\begin{itemize}
    \item we introduce a  modification  of  Valiant's  algorithm;
    \item we prove the correctness of the modification, and also we prove that time complexity is the same as for the original algorithm;
    \item we show the applicability of our modification for the string-matching problem.
\end{itemize}

\section{Background}

In this section we briefly introduce the key definitions and the necessary parsing algorithm. Before descibing the Valiant's  algorithm, we would like to mention one of the basic recognition algorithms known as CYK (the Cocke-Younger-Kasami algorithm), by which we show the main Valiant's idea that made such time complexity possible.

\subsection{Preliminaries}

An alphabet $\Sigma$ is a finite nonempty set of symbols. $\Sigma^{*}$ is a set of all finite strings over $\Sigma$. 
A grammar is a quadruple $(\Sigma, N, R, S)$, where $\Sigma$ is a finite set of terminals, N is a finite set of nonterminals, R is a finite set of productions of the form $\alpha \rightarrow \gamma$, where $\alpha \in V^{*}NV^{*}$, $\gamma \in V^{*}$, $V = \Sigma \cup N$ and $S \in N$ is a start symbol. 

\subsubsection{Definition 1} Grammar $G = (\Sigma, N, R, S)$ is called context-free, if $\space\forall r \in R$ are of the form $A \rightarrow \beta$, where $A \in N, \beta \in V^{+}$. 

\subsubsection{Definition 2} Context-free grammar $G = (\Sigma, N, R, S)$ is said to be in Chomsky normal form if $\space\forall r \in R$ are of the form: 
\begin{itemize}
  \item $A \rightarrow BC$,
  \item $A \rightarrow a$,
  \item $S \rightarrow \epsilon$, 
\end{itemize}
where $A, B, C \in N, a \in \Sigma, \epsilon$ is an empty string. 

\subsubsection{Definition 3} $L_{G}(A)$ is language of grammar $G_{A} = (\Sigma, N, R, A)$, which means all the sentences that can be derived in a finite number of steps from the start symbol A.

\subsection{Parsing by matrix multiplication}
  
The main problem of parsing is to verify if the input string belongs to the language of some given grammar $L_{G}$. We will describe the Cocke-Younger-Kasami algorithm and the most asymptotically efficient parsing algorithm, which works for all context-free grammars, Valiant's parsing algorithm, based on matrix multiplication. In this paper we use the rewritten version of Valiant's algorithm proposed by Alexander Okhotin. 

The CYK algorithm is a basic parsing algorithm. Its main idea is to construct for an input string $a_{1}a_{2}...a_{n}$ a parsing table T of size $n \times n$,  where 
\begin{equation}
T_{i, j} =  \{ A |  a_{i + 1}...a_{j} \in L_{G}(A)\} \quad \forall i < j
\end{equation}
and $G = (\Sigma, N, R, S)$ is a context-free grammar in Chomsky normal form. 

The elements of T are filled successively beginning with 
\begin{equation}
T_{i - 1, i} = \{ A | A -> a_{i} \in R\}
\end{equation}
Then, 
\begin{equation}
T_{i, j} = f(P_{i, j})
\end{equation}
where 
\begin{equation}
P_{i, j} = \bigcup\limits_{k = i + 1}^{j - 1} T_{i,k} \times T_{k, j}
\end{equation}
\begin{equation}
f(P) = \{A | \exists A \rightarrow BC \in R : (B, C) \in P\}
\end{equation}

The input string $a_{1}a_{2}...a_{n}$ belongs to $L_{G}$ if and only if $S \in T_{0, n}$.

% Algorithm1
\begin{algorithm}
\SetAlgoNoLine
\KwIn{Grammar $G = (\Sigma, N, R, S), w = a_{1}...a_{n}, n \geq 1, a_{i} \in \Sigma$, where  n + 1 --- power of two}
\underline{main()}{:}{
 
 \textit{compute(0, n + 1)\;}
 accept if and only if $S \in T_{0, n}$
 \linebreak
 }
 
\underline{compute(\textit{l, m})}{:}{
 \If {$m - l \geq 4$}{
     \textit{compute(l, $\frac{l+m}{2}$)\;
     compute($\frac{l+m}{2}$, m)}}
 \textit{complete(l, $\frac{l+m}{2}$, $\frac{l+m}{2}$, m)}
 \linebreak
 }
 
\underline{complete(\textit{l, m}, $l^\prime$, $m^\prime$)}{:}{
 \If {$m - l = 4$ and $m = l^\prime$}{$T_{l, l + 1} = \{A | A \rightarrow a_{l+ 1} \in R\}$\;}
 \ElseIf{$m - l = 1$ and $m < l^\prime$}{ $T_{l, l'} = f(P_{l, l'})$\;}
 \ElseIf{$m - l > 1$}{
    $B = (l, \frac{l+m}{2}, \frac{l'+m'}{2}, m'), B' = (\frac{l+m}{2}, m, l', \frac{l'+m'}{2}),\linebreak
    C = (\frac{l+m}{2}, m, l', \frac{l'+m'}{2}), D = (l, \frac{l+m}{2}, l', \frac{l'+m'}{2}),\linebreak
    D' = (\frac{l+m}{2}, m, \frac{l'+m'}{2}, m'), E = (l, \frac{l+m}{2}, \frac{l'+m'}{2}, m')$\;
    complete(C)\;
    $P_{D} = P_{D} \cup (T_{B} \times T_{C})$\;
    complete(D)\;
    $P_{D'} = P_{D'} \cup (T_{C} \times T_{B'})$\;
    complete(D')\;
    $P_{E} = P_{E} \cup (T_{B} \times T_{D'})$\;
    $P_{E} = P_{E} \cup (T_{D} \times T_{B'})$\;
    complete(E)
    }
 }
  \textit{complete(l, $\frac{l+m}{2}$, $\frac{l+m}{2}$, m)}
 
\caption{Parsing by matrix multiplication: Valiant's Version}
\end{algorithm}

The time complexity of this algorithm is $O(n^3)$. Valiant proposed to offload the most intensive computations to the Boolean matrix multiplication. As the most time-consuming is computing $\bigcup\limits_{k = i + 1}^{j - 1} T_{i, k} \times T_{k, j}$, Valiant rearranged computation of $T_{i, j}$, in order to use multiplication of submatrices of T. 

\subsubsection{Definition 4} Let $X \in (2^N)^{m \times l}$ and $Y \in (2^N)^{l \times n}$ be two submatrices of parsing table T. Then, $X \times Y = Z$, where $Z \in (2^{N \times N})^{m \times n}$ and $Z_{i, j} = \bigcup\limits_{k = 1}^{l} X_{i, k} \times Y_{k, j}$.

In \textbf{Algorithm 1} full pseudo-code of Valiant's algorithm written in the terms proposed by Okhotin, is presented. All elements of T and P are initialized by empty sets. Then, the elements of these two table are successively filled by two recursive procedures.

The procedure $compute(l, m)$ constructs the correct values of $T_{i,j} \forall l \le i < j < m$.

The procedure $complete(l, m, l', m')$ constructs the submatrix $\forall T_{i, j}$ $l \le i < m$, $l' \le j < m'$. This procedure assumes $T_{i, j} \forall l \leq i < j < m,  l' \leq i < j < m'$ are already constructed and the current value of  $P[i, j] =  \{ (B, C) |\exists (m \le k < l'): a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$ $\forall l \leq i < m,  l' \leq j < m'$. 

Then Valiant described that product of multiplying of two submatrices of parsing table T can be provided as $|N|^2$ Boolean matrices (for each pair of nonterminals). Denote matrix corresponding to pair $(B, C) \in N \times N$ as $Z^{(B, C)}$, then $Z_{i, j}^{(B, C)} = 1$ if and only if $(B, C) \in Z_{i, j}$. It should also be noted that $Z^{(B, C)} = X^{B} \times Y^{C}$. So, matrix multiplication in \textbf{Definition 4} can be replaced by Boolean matrix multiplication, each of which can be computed independently. Following these changes, time complexity of \textbf{Algorithm 1} is $O(|G|BMM(n)log(n))$ for an input string of length n, where BMM(n) is the number of operations needed to multiply two Boolean matrices of size $n \times n$.

\section{Modification of Valiant's algorithm}
 
In this section we describe the modification of Valiant's algorithm, which has a number of advantages, such as possibility to broke it down into several subtasks that can be processed independently. Also this version can be simply applied to the string-matching problem, which often arises in text editing, DNA and RNA sequence analysis.
 
The main change of this modification is to divide the parsing table into layers of disjoint submatrices of the same size.
The division, we have made from the reorganization of the matrix multiplication order, is presented in \textbf{Figure 1}. 
The layers are computes successively from the bottom up.

Let us consider the pseudo-code of the modification, which is written in \textbf{Algorithm 2}. The procedure $main()$ computes the lowest layer ($T_{l, l+1}$), and then divide the table into layers, described earlier, and computes them through the $completeVLayer()$ call. Thus, $main()$ computes all elements of parsing table T correctly.

% Algorithm2
\begin{algorithm}
\SetAlgoNoLine
\KwIn{Grammar $G = (\Sigma, N, R, S), w = a_{1}...a_{n}, n \geq 1, a_{i} \in \Sigma$, where  n + 1 --- power of two}
\underline{main()}{:}{
 
 \For {$l \in \{1, \ldots, n \}$}{$T_{l, l + 1} = \{A | A \rightarrow a_{l + 1} \in R\}$}
 \For{$1 \le i < k $}{
 layer = $\textit{constructLayer(i)}$\;
 \textit{completeVLayer(layer)}
 }
 \BlankLine
 }
 
\underline{constructLayer(i)}{:}{
 \BlankLine
 $\{B | \exists k \geq 0 : B = (k*2^i, (k+1)*2^i, (k + 1)*2^i, (k+2)*2^i) \}$
 \BlankLine
    }
\underline{completeLayer(M)}{:}{
\BlankLine
\If {$\forall (l, m, l', m') \in M \quad (m - l = 1)$}{\For{$ (l, m, l', m') \in M$}{$T_{l, l'} = f(P_{l, l'})$\;}}
\Else{
bottomLayer =  $\{ (\frac{l+m}{2}, m, l', \frac{l'+m'}{2}) | (l, m, l', m') \in M\}$\;
\textit{completeLayer(bottomLayer)}\;
\textit{completeVLayer(M)}
}
\BlankLine
}
 
\underline{comleteVLayer(M)}{:}{
 \BlankLine
 leftSubLayer = $\{ (l, \frac{l+m}{2}, l', \frac{l'+m'}{2}) | (l, m, l', m') \in M\}$\;
 rightSubLayer = $\{ (\frac{l+m}{2}, m, \frac{l'+m'}{2}, m') | (l, m, l', m') \in M\}$\;
 topSubLayer = $\{ (l, \frac{l+m}{2}, \frac{l'+m'}{2}, m') | (l, m, l', m') \in M\}$\;
 multiplicationTask1 = $\{(l, m, l', m'), (l, m, m, 2m - l), (m, 2m - l, l', m') | (l, m, l', m') \in leftSubLayer\} \cup \linebreak  \{(l, m, l', m'), (l, m, 2l' - m', l'), (2l' - m', l', l', m') | (l, m, l', m') \in rightSubLayer\}$\;
 \BlankLine
 multiplicationTask2 = $\{(l, m, l', m'), (l, m, m, 2m - l'), (m, 2m - l, l', m') | (l, m, l', m') \in topSubLayer\}$\;
 \BlankLine 
 multiplicationTask3 = $\{(l, m, l', m'), (l, m, 2l' - m', l'), (2l' - m', l', l', m') | (l, m, l', m') \in topSubLayer\}$\;
 \BlankLine
 \textit{performMultiplications(multiplicationTask1)}\;
 \textit{completeLayer(leftSubLayer $\cup$ rightSubLayer)}\;
 \textit{performMultiplications(multiplicationTask2)}\;
 \textit{performMultiplications(multiplicationTask3)}\;
 \textit{completeLayer(topSubLayer)}
 
 }

\caption{Parsing by matrix multiplication:  Modified Version}
\end{algorithm}
 
\newpage
Denote some subsidiary functions for matrix $m$:
 \begin{itemize}
  \item $bottom(m) = (\frac{l+m}{2}, m, l', \frac{l'+m'}{2})$,
  \item $left(m) = (l, \frac{l+m}{2}, l', \frac{l'+m'}{2})$,
  \item $right(m) = (\frac{l+m}{2}, m, \frac{l'+m'}{2}, m')$, 
  \item $top(m) = (l, \frac{l+m}{2}, \frac{l'+m'}{2}, m')$.
\end{itemize}
 
The procedure $completeVLayer(M)$ takes an array of disjoint submatrices M. For each $m = (l, m, l', m') \in M$ this procedure computes $left(m)$, $right(m)$, $top(m)$. The procedure assumes that the elements of $bottom(m)$ and all $T_{i, j} \forall l \leq i < j < m,  l' \leq i < j < m'$ are already constructed. Also it is assumed that the current value of  $P[i, j] =  \{ (B, C) |\exists (m \le k < l'): a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$ $\forall l \leq i < m,  l' \leq j < m'$.
 
The procedure $completeLayer(M)$ also takes an array of disjoint submatrices M, but unlike the previous one, it computes $T_{i, j} \forall (i, j) \in m$. This procedure, just as in the previous case, assumes that  $T_{i, j} \forall l \leq i < j < m,  l' \leq i < j < m'$ are already constructed and the current value of  $P[i, j] =  \{ (B, C) |\exists (m \le k < l'): a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$ $\forall l \leq i < m,  l' \leq j < m'$.
 
\textbf{Algorithm 3} describes how the procedure $performMultiplication(task)$, where $task$ is an array of a triple of submatrices, works. It is worth mentioning that, as distinct from the original algorithm, $|tasks| \ge 1$ and all these multiplications can be computed independently.


 % Algorithm3
\begin{algorithm}[h!]
\SetAlgoNoLine
\underline{performMultiplication(task)}{:}{\\
\For{$ (m, m1, m2) \in M$}{$P_{m} = P_{m} \cup (T_{m1} \times T_{m2})$\;}
}
\caption{}
\end{algorithm}

\section{Proof of correctness}

We provide the proof of correctness and time complexity for the proposed modification in this section. 

\begin{theorem}
Let M be a submatrix array. Assume that $T[i, j] =  \{ A |  a_{i + 1}...a_{j} \in L(A)\}$ $\forall l \leq i < j < m,  l' \leq i < j < m'$ and $P[i, j] =  \{ (B, C) |\exists (m \le k < l'): a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$ $\forall l \leq i < m,  l' \leq j < m'$ $\forall (l, m, l', m') \in M$.

Then the procedure $\textit{completeLayer(M)}$, returns correctly computed sets of $T[i, j]$ $\forall l \leq i \le m,  l' \leq j \le m'$ $\forall (l, m, l', m') \in M$. 
\end{theorem}
%
% the environments 'definition', 'lemma', 'proposition', 'corollary',
% 'remark', and 'example' are defined in the LLNCS documentclass as well.
%
\begin{proof}
Induction on $\textit{m - l}$. (Hereinafter denoting (l, m, l', m') as a typical example of array M, and all the computations are implemented for all submatrices in M).

The base case: $\textit{m - l}$ = 1. There is only one element to compute, and $P[l, l'] =  \{ (B, C) |  a_{l + 1}...a_{l'} \in L(B)L(C)\}$. Further, algorithm computes $f(P[l, l'])$ = \linebreak $\{ A |  a_{l + 1}...a_{l'} \in L(A)\}$, so $T[l, l']$ computed correctly.

For the induction step, assume that (l1, m1, l2, m2) is correctly computed for $m2 - l2 = m1 - l1 > m - l$.

Let us consider complete $\textit{completeLayer(M)}$, where $\textit{m - l} >$ 1.

Firstly, consider $\textit{completeLayer(bottom = \{$(\frac{l+m}{2}, m, l', \frac{l'+m'}{2})$\})}$, as theorem conditions are fulfilled, then this call returns correct sets $T[i, j]$ $\forall (i, j) \in bottom$ (hereinafter is means $\forall (i, j) \in m$ $\forall m \in bottom$). All submatrices with size $ m1 - l1 > m - l$, all previous layers and also $\textit{bottom(M)}$ are correct, so, $\textit{completeVLayer(M)}$ can be called, and $\textit{multiplicationByTask(task1)}$ adds to each $P[i, j]$ $\forall (i, j) \in left = \{(\frac{l+m}{2}, m, l', \frac{l'+m'}{2}))\}$ all pairs $\{ (B, C) |\exists (\frac{l+m}{2} \le k < l'): a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$ and $\forall (i, j) \in right = \{(\frac{l+m}{2}, m, \frac{l'+m'}{2}, m')\}$ all pairs $\{ (B, C) |\exists (m \le k < \frac{l'+m'}{2}): a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$. Now all the theorem conditions are fulfilled so, it is possible to call $\textit{completeLayer($left \cup right$)}$, which returns correct sets $T[i, j]$ $\forall (i, j) \in ($left \cup right$)$. 

Next, \textit{multiplicationByTask(task2)} and \textit{multiplicationByTask(task3)} add to each $P[i, j]$ $\forall (i, j) \in top = \{(l, \frac{l+m}{2}, \frac{l'+m'}{2}, m'))\}$ all pairs $\{(B, C) |\exists (\frac{l+m}{2} \le k < m)$ and $(l' \le k < \frac{l'+m'}{2}) : a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$. Now all the theorem conditions are fulfilled so, it is possible to call $\textit{completeLayer(top)}$, which returns correct sets $T[i, j]$ $\forall (i, j) \in top$. 

Thus, all $T[i, j]$ $\forall (i, j) \in M$ are computed correctly.
\end{proof}

\begin{theorem}
Let M be a submatrix array. Assume that, $T[i, j] =  \{ A |  a_{i + 1}...a_{j} \in L(A)\}$ $\forall l \leq i < j < m,  l' \leq i < j < m'$ and $\forall b1 \leq i < b2$,  $b3 \leq j < b4$, where $(b1, b2, b3, b4) = (\frac{l+m}{2}, m, l', \frac{l'+m'}{2})$, also $P[i, j] =  \{ (B, C) |\exists (m \le k < l'): a_{i + 1}...a_{k} \in L(B), a_{k + 1}...a_{j} \in L(C)\}$ $\forall l \leq i < m,  l' \leq j < m'$ $\forall (l, m, l', m') \in M$.

Then, the procedure $\textit{completeVLayer(M)}$, returns correctly computed sets of $T[i, j]$ $\forall l \leq i \le m,  l' \leq j \le m'$ $\forall (l, m, l', m') \in M$. 
\end{theorem}

\begin{proof}
The proof is similar to the proof of Theorem 1.
\end{proof}

\begin{note}
Function $\textit{costructLayer(i)}$ returns $2^{k - i} - 1$ matrices of size $2^i$.
\end{note}

\begin{lemma}
\
\begin{itemize}
 \item $\forall i \in \{ 1, .., k - 1\}$  $\sum{|layer|}$ for the calls of \textit{completeVLayer(layer)} where $\forall (l, m, l', m') \in layer$ with $m - l = 2^{k - i}$  is exactly $2^{2i - 1} - 2^{i - 1}$;
 \item $\forall i \in \{ 1, .., k - 1\}$ products of submatrices of size $2^{k - i} \times 2^{k - i}$ are calculated exactly $2^{2i - 1} - 2^{i}$
\end{itemize}
\end{lemma}

\begin{proof}
The base case: i = 1. $\textit{completeVLayer(layer)}$ where $\forall (l, m, l', m') \in layer$ with $m - l = 2^{k - 1}$ is called only once in the  $\textit{main()}$ and $|layer| = 1$. So, $2^{2i - 1} - 2^{i - 1} = 2^1 - 2^0 = 1$.

For the induction step, assume that $\forall i \in \{ 1, .., j\}$ $\sum{|layer|}$ for the calls of $\textit{completeVLayer(layer)}$ where $\forall (l, m, l', m') \in layer$ with $m - l = 2^{k - i}$  which is exactly $2^{2i - 1} - 2^{i - 1}$.

Let us consider i = j + 1. 

Firstly, it is the call of \textit{completeVLayer(costructLayer(k - i))}, where \textit{costructLayer(i)} returns $2^i - 1$ matrices of size $2^i$. Secondly, \textit{completeVLayer(layer)} is called 3 times for the left, right and top submatrices of size $2^{k - (i - 1)}$. Finally, \textit{completeVLayer(layer)} is called 4 times for the bottom, left, right and top submatrices of size $2^{k - (i - 2)}$, except $2^{i - 2} - 1$ matrices which were already computed.

Then, $\sum{|layer|} = 2^{i} - 1 + 3 \times (2^{2(i - 1) - 1} - 2^{(i - 1) - 1}) + 4 \times (2^{2(i - 2) - 1} - 2^{(i - 2) - 1}) - (2^{i - 2} - 1) = 2^{2i - 1} - 2^{i - 1}$. 

To calculate the number of products of submatrices of size $2^{k - i} \times 2^{k - i}$, we consider the calls of \linebreak \textit{completeVLayer(layer)} where $\forall (l, m, l', m') \in layer$ with $m - l = 2^{k - (i - 1)}$, which is $2^{2(i - 1) - 1} - 2^{(i - 1) - 1}$. During these calls \textit{performMultiplications} run 3 times, $|multiplicationTask1| = 2 \times 2^{2(i - 1) - 1} - 2^{(i - 1) - 1}$ and \linebreak $|multiplicationTask2|$ = $|multiplicationTask3| = 2^{2(i - 1) - 1} - 2^{(i - 1) - 1}$. So, the number of products of submatrices of size $2^{k - i} \times 2^{k - i}$ is $4 \times (2^{2(i - 1) - 1} - 2^{(i - 1) - 1}) = 2^{2i - 1} - 2^{i}$.
\end{proof}

\begin{theorem}
The time complexity of the Algorithm 1 is $O(|G|BMM(n)log(n))$ for an input string of length n, where G is a context-free grammar in Chomsky normal form, BMM(n) is the number of operations needed to multiply two Boolean matrices of size $n \times n$.
\end{theorem}

\begin{proof}
The proof is almost identical with that of the theorem given by Okhotin~\cite{okhotin}, because, as shown in the last lemma, the Algorithm 1 has the same number of products of submatrices.
\end{proof}

\section{Applications}

Next we discuss the main cause of developing this modification. Our aim was adaptation of Valiant's algorithm for string-matching problem. 

So if we want to find all substrings of size s which can be derived from a start symbol for an input string of size $n = 2^k$, we need to compute layers with submatrices of size $\le 2^{l'}$, where $ 2^{l' - 2} < s \le 2^{l' - 1}$.

$l' = k - (m - 2)$, $(m - 2) = k - l'$

$ C \sum\limits_{i=m}^k 2^{2i - 1} \cdot 2^{\omega(k - i)} \cdot f(2^{k - i}) = C \cdot 2^{\omega l'}\sum\limits_{i=2}^{l'} 2^{(2 - \omega)i} \cdot 2^{2(k - l') - 1} \cdot f(2^{l' - i}) \le C \cdot 2^{\omega l'} f(2^{l'}) \cdot 2^{2(k - l') - 1} \sum\limits_{i=2}^{l'} 2^{(2 - \omega)i} = BMM(2^{l'}) \cdot 2^{2(k - l') - 1} \sum\limits_{i=2}^{l'} 2^{(2 - \omega)i}$ 

Thus, time complexity for searching all substrings is  $O(|G|BMM(2^{l'})(l' - 1))$, while time complexity for the full input string is $O(|G|BMM(2^k)(k - 1))$. In contract to the modification, Valiant's algorithm completely calculate at least 2 triangle submatrices of size $\frac{n}{2}$, as it is shown on the \textbf{Figure 2}, which mean minimum asymptotic complexity  $O(|G|BMM(2^{k - 1})(k - 2))$. Make a conclusion that the modification is asymptotically faster for substrings of size s $<<$ n  than the original algorithm. 

\section{Conclusion}

The main goal of this work was to find an effective solution for the string-matching problem that arose at the intersection of the theory of formal languages and bioinformatics. We proposed a modification of Valiant's algorithm partially dealing with this problem. Also we proved its applicability by showing the asymptotic complexity concerning substring searching. 



%
% ---- Bibliography ----
%
% BibTeX users should specify bibliography style 'splncs04'.
% References will then be sorted and formatted in the correct style.
%
% \bibliographystyle{splncs04}
% \bibliography{mybibliography}
%
\begin{thebibliography}{8}
\bibitem{valiant}
Valiant, Leslie G.: General context-free recognition in less than cubic time. Journal of computer and system sciences \textbf{10}(2), 308--315 (1975)

\bibitem{okhotin}
Okhotin, A.: Parsing by matrix multiplication generalized to Boolean grammars. Theoretical Computer Science \textbf{516}, 101--120 (2014)

\bibitem{bernardy}
Bernardy, J.P., Claessen K.: Efficient divide-and-conquer parsing of practical context-free languages. In: ACM SIGPLAN Notices, vol. 48. no. 9, pp. 111-122 ACM (2013)

\bibitem{kasami}
Kasami, T.: An efficient recognition and syntax-analysis algorithm for context-free languages. Coordinated Science Laboratory Report no. R-257 (1966)

\bibitem{younger}
Younger, D.H.: Recognition and parsing of context-free languages in time n3. Information and control \textbf{10}(2), 189--208 (1967)

\bibitem{earley}
Earley, J.: An efficient context-free parsing algorithm. Communications of the ACM \textbf{13}(2), 94--102 (1970)

\end{thebibliography}
\end{document}

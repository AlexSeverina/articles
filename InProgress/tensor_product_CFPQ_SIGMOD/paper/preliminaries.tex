\section{Preliminaries}

In this section we introduce basic notation and definitions from graph theory and formal language theory which are used in our work.

\subsection{Context-Free Path Querying Problem}

We use a directed edge-labeled graph as a data model. 
To introduce \textit{Context-Free Path Querying Problem (CFPQ)} over directed edge-labeled graphs we should introduce both graph and grammar definition.

First of all, we introduce edge-labelled diraph $\mathcal{G} = \langle V,E,L \rangle$, where $V$ is a finite set of vertices, $E \in V \times L \times V$ is a finite set of edges, $L$ is a finite set of edge labels. 
Note that one can always introduce bijection between $V$ and $Q = \{0, \ldots, |V|-1\}$, thus in our work we gues that $V = \{0, \ldots, |V|-1\}$.

The example of a graph which we will use in further examples is presented in figure~\ref{fig:example_input_graph}.

\begin{figure}[h]
    \centering        
    \begin{tikzpicture}[shorten >=1pt,auto]
       \node[state] (q_0)                      {$0$};
       \node[state] (q_1) [above right=of q_0] {$1$};
       \node[state] (q_2) [right=of q_0]       {$2$};
       \node[state] (q_3) [right=of q_2]       {$3$};
        \path[->]
        (q_0) edge  node {a} (q_1)
        (q_1) edge  node {a} (q_2)
        (q_2) edge  node {a} (q_0)
        (q_2) edge[bend left, above]  node {b} (q_3)
        (q_3) edge[bend left, below]  node {b} (q_2);
    \end{tikzpicture}
    \caption{The example of input graph $\mathcal{G}$}
    \label{fig:example_input_graph}
\end{figure}

Each edge-labeled graph can be representad as adjacency matrix $M$: square $|V|\times|V|$ matrix, such that $M[i,j] = \{l \mid e = (i,l,j) \in E\}$.
Adjacency matrix $M_2$ of the graph $\mathcal{G}$ is 

$$
    M_2 =
    \begin{pmatrix}
    . & \{a\} & . & .     \\
    . & . & \{a\} & .     \\
    \{a\} & . & . & \{b\} \\
    . & . & \{b\} & .
    \end{pmatrix}.
$$

In our work we use decomposition of the adjacency matrix to a set of Boolean matrices: 
$$
\mathcal{M} = \{M^l \mid l \in L, M^l[i,j]=1 \iff l \in M[i,j]\}.
$$

Matrix $M_2$ can be represented as a set of two Boolean matrices $M_2^a$ and $M_2^b$ where
\begin{align}
M_2^{a} =
\begin{pmatrix}
    . & 1 & . & .   \\
    . & . & 1 & .   \\
    1 & . & . & .   \\
    . & . & . & .  
\end{pmatrix}, 
M_2^{b} =
\begin{pmatrix}      
    . & . & . & .   \\
    . & . & . & .   \\
    . & . & . & 1   \\
    . & . & 1 & . 
\end{pmatrix} \label{eq:boolean_decomposition_of_graph}
\end{align}


This way we reduce operations which are necessary for our algorithm from operations over custom semiring (over edge labels) to operations over a Boolean semiring.

Also, we should define the path in the graph and word formed by the path.

\begin{definition}
Path $\pi$ in the graph $\mathcal(G) = \langle V,E,L \rangle$ is a seqence $e_0,e_1,\ldots,e_{n-1}$, where $e_i = (v_i,l_i,u_i) \in E$ and for any $e_i, e_{i+1}$ $u_i = v_{i+1}$. We denote path from $v$ to $u$ as $v\pi u$.   
\end{definition}

\begin{definition}
The word formed by a path $$\pi = (v_0,l_0,v_1),(v_1,l_1,v_2),\ldots,(v_{n-1},l_{n-1},v_n)$$ is a concatenation of labels along the path: $\omega(\pi) = l_0 l_1 \ldots l_{n-1}$.
\end{definition}

The next part is a definitions from formal language theory.
\begin{definition} 
Context-free grammar $G = \langle\Sigma, N, S, P\rangle$ where $\Sigma$ is a finite set of terminals (or terminal alphabet), $N$ is a finite set of nonterminals (or nonterminal alphabet), $S \in N$ is a start nonterminal, and $P$ is a finite set of productions (grammar rules) of form $N_i \to \alpha$ where  $N_i \in N$, $\alpha \in (\Sigma \cup N)^*$.
\end{definition}

\begin{definition}
The sequence $\omega_2 \in (\Sigma \cup N)^*$ is dervable from $\omega_1 \in (\Sigma \cup N)^*$ in one derivation step, or $\omega_1 \to \omega_2$, in the grammar $G = \langle\Sigma, N, S, P\rangle$ iff $\omega_1=\alpha N_i \beta$, $\omega_2 = \alpha \gamma \beta$, and $N_i \to \gamma \in P$.
\end{definition}

\begin{definition}
Context-free grammar $G=\langle\Sigma, N, S, P\rangle$ specifies a \textit{contex-free languege}: $\mathcal{L}(G) = \{\omega \mid S \xrightarrow{*} \omega \}$, where $(\xrightarrow{*})$ denotes zero or more derivation steps $(\to)$.    
\end{definition}

Now we are ready to introduce CFPQ problem for the given graph  $\mathcal{G} = \langle V,E,L \rangle$ and the given grammar $G=\langle\Sigma, N, S, P\rangle$ with reachability and all paths semantics (according Hellings~\cite{!!!}).

\begin{definition}
To evaluate context-free path query with reachability semantics is to construct a set of pairs of vertices $(v_i,v_j)$ such that there exists a path $v_i \pi v_j$ in $\mathcal{G}$ which forms the word from the given language:
$$
R = \{(v_i,v_j) \mid \exists \pi: v_i \pi v_j, \omega(\pi) \in L(G) \}
$$
\end{definition}

\begin{definition}
To evaluate context-free path query with all paths semantics is to construct a set of path $\pi$ in $\mathcal{G}$ which forms the word from the given language:
$$
\Pi = \{ \pi \mid \omega(\pi) \in L(G)\}
$$
\end{definition}

Note that $\Pi$ can be infinite, thus in practice, we should provide a way with reasonable complexity to enumerate such paths, instead of explicit construction of the $\Pi$.

\subsection{Finite state machine}

\begin{definition}
FSM
\end{definition}

Regular expression to deterministic FSM.

Intersection of FSM is an RPQ.
Regualr languages are clusude under intersection.

\subsection{Recursive State Machines}



Also known as recursive networks~\cite{!!!}, recursive automata~\cite{!!!}, !!!  

\begin{definition}
RSM
\end{definition}

Properties.

Grammar to RSM convertion algorithm.
Eaxmple of convertion.


Adjacency matrices $M_1$ and $M_2$ for automata $R$ and graph $\mathcal{G}$ respectively are initialized as follows:
    $$
    M_1 =
    \begin{pmatrix}
    . & . & \{a\} & .     \\
    . & . & \{S\} & \{b\} \\
    . & . & . & \{b\}     \\
    . & . & . & .
    \end{pmatrix}
    $$

Matrix $M_1$ can be represented as a set of Boolean matrices as follows:
\begin{align*}
M_1^S =
\begin{pmatrix}      
    . & . & . & .   \\
    . & . & 1 & .   \\
    . & . & . & .   \\
    . & . & . & .   
\end{pmatrix},~M_1^a =
\begin{pmatrix}       
   . & . & 1 & .   \\
   . & . & . & .   \\
   . & . & . & .   \\
   . & . & . & .   \\
\end{pmatrix}, \\ M_1^b =
\begin{pmatrix}      
    . & . & . & .   \\
    . & . & . & 1   \\
    . & . & . & 1   \\
    . & . & . & .   \\
\end{pmatrix}
\end{align*}


Boolean decomposition of adjacency matrix

\subsection{Graph Kronecker Product}

\begin{definition}
Given two edge-labelled directed graphs $\mathcal{G}_1=\langle V_1, E_1, L_1 \rangle$ and $\mathcal{G}_2=\langle V_2, E_2, L_2 \rangle$ the Kronecker product of these two graphs is a edge-labeles directed graph $\mathcal{G}=\langle V, E, L \rangle$ where 
\begin{itemize}
	\item $V = V_1 \times V_2$
	\item $E = \{((u,v),l,(p,q)) \mid (u,l,p) \in E_1 \wedge (v,l,q) \in E_2 \}$
	\item $L = L_1 \cap L_2$
\end{itemize}
 $\mathcal{G}_1 \otimes \mathcal{G}_2$ 
\end{definition}


\begin{definition}
Matrix tensor product definition.
!!!!!
\end{definition}

Tensot ptoduct of adjacency matrices. $M(G) = M(G_1) \otimes M(G_2)$


FSM intersection can be calcualeted as tensor product of FSM adjacency matrix.

Example!!!

Tensor product for FSM intersection over Boolean semiring using given definitions.

RSM and FSM intersection classical theorem proof? 

\subsection{Index Creation Algorithm}

In this section, we introduce the algorithm for context-free path querying.
The algorithm determines the existence of a path, which forms a sentence of the language defined by 
the input RSM $R$, between each pair of vertices in the directed edge-labeled graph $\mathcal{G}$.
The algorithm is based on the generalization of the FSM intersection for an RSM, 
and an input graph. Since a graph can be interpreted as a FSM, in which 
transitions correspond to the labeled edges between vertices of the graph, 
and an RSM is composed of a set of FSMs, the intersection of such machines
can be computed using the classical algorithm for FSM intersection, presented 
in~\cite{automata:theory:10.5555/1177300}. 
Such a way of generalization leads to zero-overhead algorithm for RPQ, contrary to other algorithms which require regular expression to context-free grammar transformation.

The intersection can be computed as a Kronecker product of the corresponding 
adjacency matrices for an RSM and a graph. Since we are only determining the
reachability of vertices, it is enough to represent intersection result as 
a Boolean matrix. It simplifies the algorithm implementation and allows 
one to express it in terms of basic matrix operations.

\subsubsection{Na{\"i}ve Version}
Listing~\ref{tensor:cfpq} shows main steps of the algorithm.
The algorithm accepts context-free grammar $G=(\Sigma,N,P$) and graph $\mathcal{G}=(V,E,L)$ as an input.
An RSM $R$ is created from the grammar $G$.
Note, that $R$ must have no $\varepsilon$-transitions.
$M_1$ and $M_2$ are the adjacency matrices for the machine $R$ and the graph $\mathcal{G}$ correspondingly.

Then for each vertex $i$ of the graph $\mathcal{G}$, the algorithm adds loops 
with non-terminals, which allows deriving $\varepsilon$-word.
Here the following rule is implied: each vertex of the graph is reachable 
by itself through an $\varepsilon$-transition. Since the machine $R$ does 
not have any $\varepsilon$-transitions, the $\varepsilon$-word could be 
derived only if a state $s$ in the box $B$ of the $R$ is both initial and final.
This data is queried by the $getNonterminals()$ function for each state $s$.

The algorithm terminates when the matrix $M_2$ stops changing.
Kronecker product of matrices $M_1$ and $M_2$ is evaluated for each iteration.
The result is stored in $M_3$ as a Boolean matrix.
For the given $M_3$ a $C_3$ matrix is evaluated by the $transitiveClosure()$ 
function call. The $M_3$ could be interpreted as an adjacency matrix for an 
directed graph with no labels, used to evaluate transitive closure in terms of 
classical graph definition of this operation.
Then the algorithm iterates over cells of the $C_3$.
For the pair of indices $(i,j)$, it computes $s$ and $f$ --- 
the initial and final states in the recursive automata $R$ which relate 
to the concrete $C_3[i,j]$ of the closure matrix.
If the given $s$ and $f$ belong to the same box $B$ of $R$, $s = q_B^0$, 
and $f \in F_B$, then $getNonterminals()$ returns the respective non-terminal.
If the the condition holds then the algorithm  adds the computed non-terminals 
to the respective cell of the adjacency matrix $M_2$ of the graph.

The functions $getStates$ and $getCoordinates$ (see listing~\ref{tensor:cfpq:help})
are used to map indices between Kronecker product arguments and the result matrix.
The Implementation appeals to the blocked structure of the matrix $C_3$, 
where each block corresponds to some automata and graph edge.

The algorithm returns the updated matrix $M_2$ which contains the initial 
graph $\mathcal{G}$ data as well as non-terminals from $N$.
If a cell $M_2[i,j]$ for any valid indices $i$ and $j$ contains symbol 
$S \in N$, then vertex $j$ is reachable from vertex $i$ in grammar $G$ for 
non-terminal $S$.

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{Kronecker product based CFPQ}
\label{tensor:cfpq}
\Function{contextFreePathQuerying}{G, $\mathcal{G}$}
    % Input data preparation
    \State{$R \gets$ Recursive automata for $G$}
    \State{$M_1 \gets$ Adjacency matrix for $R$}
    \State{$M_2 \gets$ Adjacency matrix for $\mathcal{G}$}
    % Eps-transition handling for graph
    \For{$s \in 0..dim(M_1)-1$}
        \For{$i \in 0..dim(M_2)-1$}
            \State{$M_2[i,i] \gets M_2[i,i] \cup \textit{getNonterminals}(R,s,s)$}
        \EndFor
    \EndFor
    \While{Matrix $M_2$ is changing}
        \State{$M_3 \gets M_1 \otimes M_2$}
        \Comment{Evaluate Kroncker product}
        \State{$C_3 \gets \textit{transitiveClosure}(M_3)$}
        \State{$n \gets$ dim($M_3)$}
        \Comment{Matrix $M_3$ size = $n \times n$}
        % Add non-terminals (possibly new)
        \For{$(i,j) \in [0..n-1] \times [0..n-1]$}
            \If{$C_3[i,j]$}
                \State{$s, f \gets \textit{getStates}(C_3,i,j)$}
                \If{$\textit{getNonterminals}(R,s,f) \neq \emptyset$}
                    \State{$x, y \gets \textit{getCoordinates}(C_3,i,j)$}
                    \State{$M_2[x,y] \gets M_2[x,y] \cup \textit{getNonterminals}(R,s,f)$}
                \EndIf
            \EndIf
        \EndFor
    \EndWhile
\State \Return $M_2$
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{Help functions for Kronecker product based CFPQ}
\label{tensor:cfpq:help}
\Function{getStates}{$C, i, j$}
    \State{$r \gets dim(M_1)$}
    \Comment{$M_1$ is adjacency matrix for automata $R$}
    \State \Return{$\left\lfloor{i / r}\right\rfloor, \left\lfloor{j / r}\right\rfloor$}
\EndFunction
\Function{getCoordinates}{$C, i, j$}
    \State{$n \gets dim(M_2)$}
    \Comment{$M_2$ is adjacency matrix for graph $\mathcal{G}$}
    \State \Return{$i \bmod n, j \bmod n$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{lemma}
    \label{lemma:algo:correctness}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = (\Sigma, N, P)$ be a grammar.
    Let $\mathcal{G}_k = (V,E_k,L \cup N)$ be graph and $M_k$ its adjacency
    matrix of the execution some iteration $k \geq 0$ of the algorithm \ref{?}.
    Then for each edge $e = (m,S,n) \in E_k$, where $S \in N$,
    the following statement holds: $\exists m\pi n: S \to_{G} l(\pi)$.
\end{lemma}

\begin{proof}{(Proof by induction)}

    \textbf{Basis:} For $k = 0$ and the statement of the lemma holds, since
    $M_0 = M$, $M$ where is adjacency matrix of the graph $G$. Non-terminals,
    which allow to derive $\varepsilon$-word, are also added at algorithm
    preprocessing step, since each vertex of the graph is reachable by itself 
    through an $\varepsilon$-transition.
    
    \textbf{Inductive step:} Assume that the statement of the lemma holds for any
    $k \leq (p - 1)$ and show that it also holds for $k = p$, where $p \geq 1$.
    
    For the algorithm iteration $p$ the Kronecker product $K_p$ and transitive
    closure $C_p$ are evaluated as described in the algorithm. By the properties
    of this operations, some edge $e = ((s,m),(f,n))$ exists in the directed
    graph, represented by adjacency matrix $C_p$, if and only if $\exists s
    \pi ^{'} f$ in the RSM graph, represented by matrix $M_r$, and 
    $\exists m \pi n$ in graph, represented by $M_{p-1}$. Concatenated symbols 
    along the path $\pi^{'}$ form some derivation string v, composed from terminals
    and non-terminals, where $v \to_G l(\pi)$  by the inductive assumption.
    
    The new edge $e = (m,S,n)$ will be added to the $E_p$ only if $s$ and $f$ 
    are initial and final states of some box $B$ of the RSM corresponding to 
    the non-terminal $S_B$. In this case, the grammar $G$ has the derivation rule
    $S_B \to_G v$, by the inductive assumption $v \to_G l(\pi)$. Therefore, 
    $S_B \to_G l(\pi)$ and this completes the proof of the lemma.
    
\end{proof}

\begin{lemma}
    \label{lemma:algo:completeness}
    Let $\mathcal{G} = (V,E,L)$ be a graph and  $G = (\Sigma, N, P)$ be a grammar. 
    Let $\mathcal{G}_k = (V,E_k,L \cup N)$ be graph and $M_k$ its adjacency
    matrix of the execution some iteration $k \geq 1$ of the algorithm \ref{?}. 
    For any path $m \pi n$ in graph $\mathcal{G}$ with word $l = l(\pi)$ if 
    exists the derivation tree of $l$ for the grammar $G$ and starting non-terminal
    $S$ with the height $h \leq k$, then $\exists e = (m,S,n): e \in E_k$.

\end{lemma}

\begin{proof}{(Proof by induction)}

    \textbf{Basis:} Show that statement of the lemma holds for the $k = 1$. Matrix
    $M$ and edges of the graph $\mathcal{G}$ contains only labels from $L$. 
    Since the derivation tree of height $h = 1$ contains only one non-terminal 
    $S$ as a root and only symbols from $\Sigma \cup {\varepsilon}$ as leafs, 
    for all paths, which form a word with derivation tree of the height $h = 1$, 
    the corresponding nonterminals will be added to the $M_1$ via preprocessing step
    and first iteration of the algorithm. Thus, the lemma statement holds 
    for the $k = 1$.

    \textbf{Inductive step:} Assume that the statement of the lemma hold for any
    $k \leq (p - 1)$ and show that it also holds for $k = p$, where $p \geq 2$.
    
    For the algorithm iteration $p$ the Kronecker product $K_p$ and transitive
    closure $C_p$ are evaluated as described in the algorithm. By the properties
    of this operations, some edge $e = ((s,m),(f,n))$ exists in the directed
    graph, represented by adjacency matrix $C_p$, if and only if $\exists s
    \pi_1 f$ in the RSM graph, represented by matrix $M_{RSM}$, and 
    $\exists m \pi n$ in graph, represented by $M_{p-1}$. 
    
    For any path $m \pi n$, such that exist derivation tree of height $h < k$ 
    for the word $l(\pi)$ with root non-terminal $S$, there exists edge 
    $e = (m,S,n): e \in E_k$ by inductive assumption.
    
    Suppose, that exists derivation tree $T$ of height $h = p$ with the root 
    non-terminal $S$ for the path $m \pi n$. The tree $T$ is formed as
    $S \to a_1 .. a_d, d \geq 1$ where $\forall i \in [1..d]$ $a_i$ is sub-tree of
    height $h_i \leq p - 1$ for the sub-path $m_i \pi_i n_i$. 
    By inductive hypothesis, there exists path $\pi_i$ for each derivation sub-tree, 
    such that $m = m_1 \pi_1 m_2 .. m_{d} \pi_{d} m_{d+1} = n$ and concatenation 
    of these paths forms $m \pi n$, and the root non-terminals of 
    this sub-trees are included in the matrix $M_{p - 1}$. 
    
    Therefore, vertices $m_i ~\forall i \in [1..d]$ form path in the graph, 
    represented by matrix $M_{p-1}$, with complete set of labels.
    Thus, new edge between vertices $m$ and $n$ with the respective 
    non-terminal $S$ will be added to the matrix $M_p$ and this completes 
    the proof of the lemma.

\end{proof}

\begin{theorem}
    Let $\mathcal{G} = (V,E,L)$ be a graph and  $G = (\Sigma, N, P)$ be a grammar.
    Let $\mathcal{G}_R = (V, E_R, L)$  be a result graph for the execution 
    of the algorithm \ref{??}. The following statement holds: 
    $e = (m, S, n) \in E_R$, where $S \in N$, if and only if 
    $\exists m \pi n: S \to_G l(\pi)$. 
\end{theorem}{}
    
\begin{proof}
    
    This theorem is a consequence of the  
    Lemma~\ref{lemma:algo:correctness} and 
    Lemma~\ref{lemma:algo:completeness}.
    
\end{proof}{}

\begin{theorem}{}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = (\Sigma, N, P)$ be a grammar.
    The algorithm \ref{?} terminates in finite number of steps.
\end{theorem}

\begin{proof}
    
    The main algorithm \textit{while-loop} is executed while graph adjacency 
    matrix $M$ is changing. Since the algorithm only adds the edges with 
    non-terminals from $N$, the maximum required number of iterations 
    is $|N| \times |V| \times |V|$, where each component has finite size. 
    This completes the proof of the theorem.
    
\end{proof}{}

% TODO: more accurate upper bound for the algorithm complexity 

\subsubsection{Application of Dynamic Transitive Closure}

In this subsection we show how to reduce the time complexity of the Algorithm~\ref{tensor:cfpq} by avoiding redundant calculations. 


It is easy to see that the most time-consuming steps in the Algorithm~\ref{tensor:cfpq} are the Kronecker product and transitive closure computations. Recall that the matrix $M_2$ is always changed in incremental manner i. e. elements (edges) are added to $M_2$ (and are never deleted from it) on every iteration of the Algorithm~\ref{tensor:cfpq}. So one does not need to recompute the whole product or transitive closure if an appropriate date structure is maintained.


To deal with the Kronecker product computation, we use the left-distributivity of the Kronecker product. Let $A_2$ be a matrix with newly added elements and $B_2$ be a matrix with the all previously found elements, such that $M_2 = A_2 + B_2$. Then by the left-distributivity of the Kronecker product we have $M_1 \otimes M_2 = M_1 \otimes (A_2 + B_2) = M_1\otimes A_2 + M_1 \otimes B_2$. Notice that $M_1 \otimes B_2$ is known and is already in the matrix $M_3$ and its transitive closure also is already in the matrix $C_3$, because it was calculated on the previous iterations, so it is left to update some elements of $M_3$ by computing $M_1\otimes A_2$,  which can be done in $O(|A_2||M_1|)$ time, where $|A|$ denotes the number of non-zero elements in a matrix $A$.


The fast computation of transitive closure can be obtained by using incremental dynamic transitive closure technique. We use an approach by Ibaraki and Katoh~\cite{IBARAKI198395} to maintain dynamic transitive closure. The key idea of their algoritm is to recalculate reachability information only for those vertices, which become reachable after insertion of the certain edge (see Figure~\ref{edgeAdd} for details). The algorithm is presented in Listing~\ref{tensor:cfpq:dynamicTC} (we have slightly modified it to efficiently track new elements of the matrix $C_3$). 

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{The dynamic transitive closure procedure}
\label{tensor:cfpq:dynamicTC}
\Function{add}{$C_3, i, j$}
       \State{$n \gets$ Number of rows in $C_3$}
        \State{$C_3' \gets$ Empty matrix of size $n \times n$}
        \For{$u \neq 0 \in$ checkCondition($C_3, i, j$)}
        \State{newReachablePairs($C_3, C_3', u, j$)}
        \EndFor
        \State \Return $C_3'$
\EndFunction
 \Function{checkCondition}{$C_3, i, j$}
        \State{$A \gets$ Empty array of size $n$}
        \For{$u \in 0...n \mid  u \neq j $}
    \Comment{$1 \wedge 1 = 0 \wedge 0 = 1 \wedge 0 = 0$; $0 \wedge 1 = 1$}
       \State{ $A[u] = C_3[u,j] \wedge C_3[u,i]$}
        \EndFor
\State \Return $A$
\EndFunction
 \Function{newReachablePairs}{$C_3, C_3', u, j$}
      \State{$C_3'[u,v] = C_3[u, v] \wedge C_3[j, v]$}
 \Comment{$1 \wedge 1 = 0 \wedge 0 = 1 \wedge 0 = 0$; $0 \wedge 1 = 1$}
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{figure}
\begin{tikzpicture}[shorten >=1pt,node distance=2cm,on grid,auto] 
   \node[state] (q_0)   {$u$}; 
   \node[state] (q_1) [above right=of q_0] {$i$}; 
   \node[state] (q_2) [ right=of q_1] {$j$}; 
   \node[state] (q_3) [ below right=of q_2] {$v$}; 
    \path[->] 
    (q_0) edge[decorate, decoration={snake}]  node {} (q_1)
    (q_1) edge [thick]  node {} (q_2)
    (q_2) edge[decorate, decoration={snake}]  node {} (q_3)
    (q_0) edge [dashed]  node {} (q_3);        
\end{tikzpicture}

\caption{The vertex $j$ become reachable from the vertex $u$ after the addition of edge $(i, j)$. Then the vertex $v$ is reachable from $u$ after inserting the edge $(i, j)$ if $v$ is reachable from $j$.}
\label{edgeAdd}
\end{figure}

Final version of the modified Algorithm~\ref{tensor:cfpq} is shown in Listing~\ref{tensor:cfpq:cubic}.

\begin{algorithm}[h]
\floatname{algorithm}{Listing}
\begin{algorithmic}[1]
\footnotesize
\caption{Kronecker product based CFPQ using dynamic transitive closure}
\label{tensor:cfpq:cubic}
\Function{contextFreePathQuerying}{G, $\mathcal{G}$}
    % Input data preparation
    \State{$R \gets$ Recursive automata for $G$}
    \State{$M_1 \gets$ Adjacency matrix for $R$}
    \State{$M_2 \gets$ Adjacency matrix for $\mathcal{G}$}
    \State{$A_2 \gets$ Adjacency matrix for $\mathcal{G}$}
    %\State{$M_3 \gets$ The empty matrix}
    \State{$C_3 \gets$ The empty matrix}
    % Eps-transition handling for graph
    \For{$s \in 0..dim(M_1)-1$}
        \For{$i \in 0..dim(M_2)-1$}
            \State{$M_2[i,i] \gets M_2[i,i] \cup \textit{getNonterminals}(R,s,s)$}
        \EndFor
    \EndFor
    \While{Matrix $M_2$ is changing}
       \State{$M_3' \gets  M_1 \otimes A_2$}
        \State{$A_2 \gets$ The empty matrix of size $n \times n$}
        %\Comment{Evaluate Kroncker product}
       \For{$M_3'[i,j] \mid M_3'[i,j] = 1$}
            \State{$C_3[i,j] \gets 1$}
             \State{$C_3' \gets  \bigcup_{(i,j)} \textit{add}(C_3, i, j)$}
             \Comment{Updating the transitive closure}
             \State{$C_3 \gets C_3 + C_3'$}
        \EndFor
        \State{$n \gets$ dim($M_3)$}
        %\Comment{Matrix $M_3$ size = $n \times n$}
        % Add non-terminals (possibly new)
        \For{$(i,j)\ |\ C_3'[i,j] \neq 0$}
                \State{$s, f \gets \textit{getStates}(C_3',i,j)$}
                \If{$\textit{getNonterminals}(R,s,f) \neq \emptyset$}
                    \State{$x, y \gets \textit{getCoordinates}(C_3',i,j)$}
                    \State{$M_2[x,y] \gets M_2[x,y] \cup \textit{getNonterminals}(R,s,f)$}
                     \State{$A_2[x,y] \gets A_2[x,y] \cup \textit{getNonterminals}(R,s,f)$}
                \EndIf
        \EndFor
    \EndWhile
\State \Return $M_2$
\EndFunction
\end{algorithmic}
\end{algorithm}
\begin{theorem}{}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = (\Sigma, N, P)$ be a grammar.
    The Algorithm \ref{tensor:cfpq:cubic} calculates a result graph $\mathcal{G}_R = (V, E_R, L)$ in $O(n^3)$ time.
\end{theorem}

\begin{proof}
 Let $|A|$ be a number of non-zero elements in a matrix $A$. Consider the total time which is needed for computing the Kronecker products. The elements of the matrices $A_2^{(i)}$ are pairwise distinct on every $i$-th iteration of the Algorithm therefore we have $\sum\limits_i{T(M_1 \otimes A_2^{(i)})} = |M_1| \otimes \sum\limits_i {|A_2^{(i)}|} = |M_1|O(n^2)$ operations in total. 


Now we derive the time complexity of maintainig the dynamic transitive closure. Notice that $C_3$ has size of $O(n^2)$ so no more than $O(n^2)$ edges will be added during all iterations of the Algorithm. The function $checkCondition$ from the Listing~\ref{tensor:cfpq:dynamicTC} takes $O(n)$ time for every inserted edge $(i, j)$. Thus we have $O(n^2n) = O(n^3)$ operations in total. The function $newReachablePairs$ requires $O(n)$ time for a given vertex $u$. This operation is performed for every pair $(j, v)$ of vertices such that a vertex $j$ became reachable from the vertex $u$. The vertex $j$ become reachable from the vertex $u$ only once during the entire computation, so the function $newReachablePairs$ will be executed at most $O(n^2)$ times for every $u$ and hence $O(n^3)$ times in total for all vertices. Therefore $O(n^3)$ operations are performed to maintain dynamic transitive closure during all iteration of the Algorithm~\ref{tensor:cfpq:cubic}.


Notice that the matrix $C_3'$ contains only new elements, therefore $C_3$ can be updated derectly using only $|C_3'|$ operations and hence $O(n^2)$ operations in total. The same holds for cycle in line 18 of the Algorithm~\ref{tensor:cfpq:cubic}, because operations are performed only for non-zero elements of the matrix $|C_3'|$. Finally, we have that the time complexity of the Algorithm~\ref{tensor:cfpq:cubic} is $O(n^2) + O(n^3) + O(n^2) + O(n^2) = O(n^3)$.
\end{proof}{}

\subsubsection{Speeding up by a factor of $\log n$}

In this subsection we use the Four Russians' trick to speed up the dynamic transitive closure algorithm from the Listing~\ref{tensor:cfpq:dynamicTC}.
\begin{theorem}{}
    The computation of transitive closure matrices can be done in $O(n^3/\log n)$ time when $n^2$ edges are added to the graph.
\end{theorem}
\begin{proof}
Consider the function $checkCondition$ from the Listing~\ref{tensor:cfpq:dynamicTC}. Its operations are equivalent to the element-wise (Hadamard) product of two vectors of size $n$, where multipication operation is denoted as $\wedge$ and has the following properties: $1 \wedge 1 = 0 \wedge 0 = 1 \wedge 0 = 0$ and $0 \wedge 1 = 1$. The first vector represents reachability of a given vertex $i$ from other vertices $\{u_1, u_2, ..., u_n\}$ of the graph and the second vector represents the same for a given vertex $j$. The function $newReachablePairs$ also can be reduced to the computation of the Hadamard product of two vectors of size $n$ for a given $u_k$. The first vector contains the information whether vertices  $\{v_1, v_2, ..., v_n\}$ of the graph are reachable from a given vertex $u_k$ and the second vector represents the same for a given vertex $j$. The element-wise product of two vectors can be calculated naively in time $O(n)$ which gives the $O(n^3)$ time for maintaining the transitive closure. Thus, the time complexity of the transitive closure can be reduced by speeding up element-wise product of two vectors of size $n$. 


To achive this goal, we use the Four Russians' trick. Split each vector into $n/\log n$ parts of size $\log n$. Create a table $S$ such that $S(a, b)$ = $a \wedge b$ where $a, b \ \in {\{0,1\}}^{\log n}$. This takes a time $O(n^2 \log n)$, since there are $2^{\log n} = n$ variants of boolean vectors of size $\log n$ and hence $n^2$ pairs of vectors $(a, b)$ in total, and each component takes $O(\log n)$ time. With table $S$, we can calculate product of two parts of size $\log n$ in constant time. There are $n/\log n$ such parts, so the element-wise product of two vectors of size $n$ can be calculated in time $O(n/\log n)$ with $O(n^2 \log n)$ preprocessing. This gives us a dynamic transitive closure algorithm running in time $O(n^3/\log n)$: both of the functions $checkCondition$ and  $newReachablePairs$ are evaluated no more than $O(n^2)$ times during the whole computation, and each function calculates Hadamard product of two vectors in $O(n/\log n)$ time.
\end{proof} 
Notice that the maintaining of the dynamic transitive closure dominates the cost of the Algorithm~\ref{tensor:cfpq:cubic}, therefore we immediatly deduce the following.
\begin{corollary}{}
    Let $\mathcal{G} = (V,E,L)$ be a graph and $G = (\Sigma, N, P)$ be a grammar.
    The result graph $\mathcal{G}_R = (V, E_R, L)$ can be calculated in $O(n^3/\log n)$ time.
\end{corollary}



Subcubic for planar graphs using~\cite{10.1007/3-540-57273-2_72}.

Cojecture on sublinear dynamic transitive closure and subcubic CFPQ.
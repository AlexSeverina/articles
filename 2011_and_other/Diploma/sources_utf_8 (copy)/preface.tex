\section{Введение}	

Задачи автоматизированного  реинжиниринга  программ~\cite{Reeng} выдвигают особые требования~\cite{CurrentParsTechn} к генераторам синтаксических анализаторов. Во многом это связано с тем, что теория синтаксически управляемой трансляции развивалась одновременно языками, сейчас называемых устаревшими (legacy languages). Тогда еще не были получены основные теоретические результаты, положенные в основу наиболее распространенных современных генераторов синтаксических анализаторов. Поэтому устаревшие языки имеют особенности, затрудняющие синтаксический анализ даже с использованием современных инструментов (например ASF+SDF~\cite{ASF+SDF}, Elkhound~\cite{Elkhound}), которые значительно упрощают создание анализаторов.

Для устаревшего языка сложно (а зачастую и невозможно) задать однозначную контекстно-свободную грамматику. Необходимо существенно преобразовать его спецификацию, которая приводится в документации, чтобы получить такую грамматику. Но после этого она серьёзно усложняется и на её сопровождение требуется больше ресурсов~\cite{CurrentParsTechn}. Поэтому устаревший язык обычно задается с помощью неоднозначной контекстно-свободной грамматики.

При решении задач реинжиниринга часто требуются преобразования уже существующей грамматики. С одной стороны, при разработке  грамматики могут быть допущены неточности, с другой, документация устаревших языков и, в особенности, их диалектов может содержать ошибки, быть неполной или вообще отсутствовать. В результате, в целевом инструменте появляются ошибки, многие из которых возможно выявить только на этапе его тестирования. Для их исправления необходимо корректировать исходную грамматику. При этом, зачастую, изменение одного правила приводит к появлению десятков конфликтов в грамматике~\cite{CurrentParsTechn}, которые необходимо разрешать "`вручную"', что требует большого количества времени.

Кроме этого, на практике часто оказывается удобным иметь описание нескольким диалектов одного языка в одной грамматике. Это позволяет переиспользовать общие части грамматики, так как диалекты, как правило, имеют много общего. В то же время диалекты имеют характерные синтаксические конструкции, которые позволят автоматически определять принадлежность входной строки тому или иному диалекту. Однако при таких описаниях часто возникают конфликты, которые так же приходится разрешать "`вручную"'.

Для решения этих задач предлагается использовать неоднозначные контекстно-свободные грамматики и соответствующие инструменты построения анализаторов~\cite{CurrentParsTechn}. Основная особенность этих инструментов -- алгоритм, который способен работать с неоднозначными грамматиками (GLR-алгоритм). Анализатор, построенный по неоднозначной  грамматике с помощью данного алгоритма, в общем случае, в результате разбора строит не единственное дерево, а несколько деревьев -- лес, содержащий все возможные варианты вывода. Дальнейшая работа с полученным лесом организуется исходя из требований и  особенностей решаемой задачи. Это избавляет он необходимости "`ручного"' устранения конфликтов, что существенно сокращает время и упрощает разработку грамматики. Важным плюсом является ещё и то, что код становится более компактным и сопровождаемым.
      
%который можно сократить, используя специальные фильтры, а можно ,при задании в одной спецификации нескольких диалектов, вернуть весь лес для дальнейшего выбора нужного дерева/диалекта.   

%Работу GLR-алгоритма  можно рассматривать как параллельное исполнение набора LR-анализаторов. При этом данный набор дополняется процедурой управления стеками, оптимизирующей представление стеков путем их «склеивания» и «расклеивания», что позволяет хранить и строить параллельные выводы в рамках одного LR-анализатора, лишь в моменты их различия добавляя параллельный анализатор.

%Оказалось, что весьма наглядно такой алгоритм может быть представлен в виде набора взаимно-рекурсивных функций ~\cite{Non-det-rec-asc},~\cite{RECURSIVE-ASCENT PARSING},~\cite{RecursiveAscentParsing}. При этом расклеивание стека получается естественным образом как ветвление в одной из функций, а обратное склеивание может быть реализовано как кэширование результата функции.

Стоит отметить, что по производительности такой анализатор, являясь некоторой "`надстройкой"' \ над LR-анализатором, незначительно ему уступает. На сегодняшний день в соотношении производительность/класс разбираемых языков GLR-алгоритм выглядит наиболее предпочтительно.

Удобным способом определения грамматики языка программирования является расширенная форма Бэкуса-Наура(EBNF)~\cite{ISOEBNF} -- правила в такой грамматике в правых частях содержат регулярные выражения. На практике, использование EBNF позволяет упростить и сократить описание языка, сделать его более понятным. Кроме того, документация по языку, как правило, содержит конструкции EBNF. Однако многие современные инструменты не поддерживают EBNF-конструкции.

При работе с инструментом пользователь ожидает получить результат, описанный в терминах заданной им грамматики. Это выдвигает дополнительные требования к алгоритму. В случае, если входная грамматика была каким-либо образом преобразована, например с целью раскрыть конструкции EBNF, то появляется необходимость в построении "`обратного"' \ преобразования. Это преобразование должно "`перевести"' \ результат обратно в термины входной грамматики. Такие преобразования  требуют дополнительных ресурсов и усложняют инструмент. Поэтому наиболее предпочтительными является алгоритмы, работающие без дополнительных преобразований грамматики.

В рамках данной работы ставится цель разработки прототипа генератора анализаторов, позволяющего работать с неоднозначными расширенными контекстно-свободными грамматиками, предоставляющего, в то же время, ставшие привычными средства реализации трансляции, такие как атрибуты.

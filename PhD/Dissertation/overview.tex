\chapter{Обзор} \label{relWorks}

В данной главе будут введены основные термины и определения, рассмотрены основные подходы к анализу встроенных языков, инструменты для их обработки. Также будет рассмотрен алгоритм обобщённого восходящего синтаксического анализа RNGLR, лежащий в основе разработанного алгоритма. Кроме того, будут описаны компоненты, использовавшиеся при разработке инструментального пакета.

\section{Языки и грамматики}

В данном разделе будет приведён ряд обозначений, понятий и определений из теории формальных языков, которые будут использоваться в работе.

\begin{mydef}
    \textbf{Алфавит} $\Sigma$ --- это конечное множество символов.
\end{mydef}

\begin{mydef}
    \textbf{Цепочкой символов} в алфавите $\Sigma$ называется любая конечная последовательность символов этого алфавита. Цепочка, которая не содержит ни одного символа, называется пустой цепочкой. Для её обозначения будем использовать греческую букву $\varepsilon$ (не входит в алфавит $\Sigma$, а только помогает обозначить пустую последовательность символов).
\end{mydef}

\begin{mydef}
    \textbf{Язык} $L$ над алфавитом $\Sigma$ --- это подмножество множества всех цепочек в этом алфавите.
\end{mydef}

\begin{mydef} 
    \textbf{Грамматика} $G$ --- это четвёрка  $\langle T, N, P, S \rangle$ , где 
    \begin{itemize}
        \item $T$ --- алфавит терминальных символов или терминалов; 
        \item $N$ --- алфавит нетерминальных символов или нетерминалов, $T \cap  N = \oslash$ ; 
        \item $P$ --- конечное подмножество множества $(T \cup N)^+ \times (T \cup N)^*$.  Элемент $(a, b) \in P$ называется правилом вывода и записывается в виде $a \rightarrow b$, где $a$ называется левой частью правила, а $b$ --- правой частью, и левая часть любого правила из $P$ обязана содержать хотя бы один нетерминал; 
        \item $S$ --- стартовый символ грамматики, $S  \in N$. 
    \end{itemize}
\end{mydef}

\begin{mydef}    
    \textbf{Вывод} цепочки $\omega$ в грамматике $G=\langle T, N, P, S \rangle$.\\  Цепочка $b \in  ( T \cup  N )^*$ непосредственно выводима из цепочки   $a \in ( T \cup N )^+$ в грамматике $G$  (обозначается  $\rightarrow_G$ ), если  $a = x_1 \cdot y \cdot x_2, b = x_1 \cdot z \cdot x_2$, где $x_1, x_2, y \in   (T \cup N )^*, z \in  (T \cup N )^+$ и правило вывода  $y \rightarrow z$  содержится в $P$. Индекс $G$ в обозначении $\rightarrow_G$ обычно опускают, если $G$ понятна из контекста.

Цепочка $b \in  (T \cup  N )^*$  выводима из цепочки  $a \in (T \cup  N)^+$ в грамматике $G$  (обозначается  $a \Rightarrow_G b$ ), если существуют цепочки $z_0, z_1, \cdots, z_n  (n \geq 0)$, такие, что $a = z_0 \rightarrow z_1 \rightarrow ... \rightarrow z_n = b$ . Последовательность $z_0, z_1, ..., z_n$ называется выводом длины $n$.
\end{mydef}

\begin{mydef}
    \textbf{Языком, порождаемым грамматикой \\ $G = \langle T, N, P, S \rangle$} , называется множество $L(G)  = \{ \omega \in T^* | S \Rightarrow a \}$.
\end{mydef}

\begin{mydef}
    \textbf{Левосторонний вывод} цепочки $\omega$ в грамматике $G=\langle T, N, P, S \rangle$ --- вывод в котором на каждом шаге вывода заменяется самое левое из всех вхождений нетерминальных символов (то есть каждый шаг вывода имеет вид $u A \theta \Rightarrow u \beta \theta$, где $( A \rightarrow \beta ) \in P$, $u \in \Sigma ^*$ и $\theta \in (N \cup \Sigma)^* )$.
\end{mydef}

\begin{mydef}    
    \textbf{Правосторонний вывод} цепочки $\omega$ в грамматике $G=\langle  T, N, P, S  \rangle$ определяется аналогично левостороннему: заменяется самое правое вхождение нетерминала.
\end{mydef}

\begin{mydef}    
    Грамматика $G$ называется \textbf{неоднозначной} (ambiguous), если существует слово $\omega \in L(G)$, которое имеет два или более левосторонних вывода. В противном случае контекстно-свободная грамматика называется \textbf{однозначной} (unambiguous). 
\end{mydef}

\begin{mydef}    
    Язык $L_1$ называется \textbf{существенно неоднозначным}, если не существует такой грамматики $G$, что $G$ однозначна и $L_1 = L(G)$. 
\end{mydef}

\begin{mydef}
    \textbf{Деревом вывода} цепочки $\omega \in T^*$ в грамматике $G=\langle T, N, P, S \rangle$ называется упорядоченное дерево со следующими свойствами. 
\begin{itemize}
    \item Корень помечен $S$.

    \item Если его внутренний узел помечен $A \in N$ и $X_1, \ldots , X_k \in T \cup N$ ---   перечисленные слева направо пометки всех сыновей этого узла, то $A \rightarrow X_1 \ldots X_k \in P$.

    \item Если его внутренний узел помечен $A \in N$ и $\varepsilon$ --- пометка единственного сына этого внутреннего узла, то $A \rightarrow \varepsilon \in P$.

    \item $\omega = a_1 \ldots a_m$, где $a_1, \ldots , a_m \in T \cup \{\varepsilon\} $ перечисленные слева направо пометки всех листьев этого дерева.
    
\end{itemize}
\end{mydef}

\begin{mydef}    
    \textbf{Динамически формируемые строковые выражения} --- строковые выражения в программе на некотором языке программирования, значения которых в момент использования зависят от процесса выполнения этой программы. Язык, на котором написана программа, будем называть \textbf{внешним языком}. В случае, когда известно, что значение строкового выражения должно являться кодом на некотором языке, говорят о \textbf{встроенных языках} (также называемых встроенными строковыми языками или string-embedded languages~\cite{Alvor1}). Например, для листинга~\ref{lst:stringExpr} внешним языком является C\#. Про переменную \verb|sExec|, основываясь на строках 3--7, можно сделать предположение, что она должна содержать выражение на SQL. Таким образом, в данном примере присутствует SQL, встроенный в C\#, и динамически формируемый SQL-запрос. Отметим, что выражение на строке 9 является статическим, а строковое выражение на строке 10 является динамически формируемым, но не является кодом на некотором языке программирования. Обработка таких выражений в общем случае называется анализ строк (string analysis~\cite{StringAnalysis}).
\end{mydef}

\fvset{frame=lines,framesep=5pt}
\begin{listing}
    \begin{pyglist}[language=csharp,numbers=left,numbersep=5pt]

public void Example(string tbl, bool cond)
{
    string sExec =
        "SELECT sOrderDescription, cderitInfo, @sMagicKey FROM ts." + tbl;
        + (cond ? "WHERE fld = 1 " : "WHERE fld = 2 ");

    db.Execute(sExec);
    
    Console.WriteLine("Log:");
    Console.WriteLine("Выборка проведена успешно. Таблица: " + tbl);
}
\end{pyglist}
\caption{Пример кода метода на языке программирования C\#, содержащего динамически формируемые строковые выражения}
\label{lst:stringExpr}
\end{listing}

Одним из распространённых способов классификации грамматик является иерархия грамматик по Хомскому~\cite{chomsky}. Так как для различных классов грамматик в данной иерархии разрешимость задач различна и применяемые алгоритмы анализа также различаются, то рассмотрим её более детально.

\begin{itemize}
    \item \textbf{Тип 0} \\ 
    Любая грамматика является грамматикой типа 0. На вид правил грамматик этого типа не накладывается никаких дополнительных ограничений. Класс языков типа 0 совпадает с классом рекурсивно перечислимых языков.
    
    \item \textbf{Тип 1} \\ 
    Грамматика $G = \langle T, N, P, S \rangle$ называется неукорачивающей, если правая часть каждого правила из $P$ не короче левой части: для любого правила $\alpha \rightarrow \beta \in P$ выполняется неравенство $| \alpha | <= | \beta |$. В виде исключения в неукорачивающей грамматике допускается наличие правила $S \rightarrow \varepsilon$, при условии, что $S$ не встречается в правых частях правил. 
    
    \textbf{Грамматикой типа 1} будем называть неукорачивающую грамматику.
    
    Тип 1 также можно определить с помощью контекстно-зависимых грамматик. 
    Грамматика $G = \langle T, N, P, S \rangle$ называется контекстно-зависимой (КЗ), если каждое правило из $P$ имеет вид $\alpha \rightarrow \beta$, где $\alpha = \omega_1 A\omega_2, \beta = \omega_1\gamma\omega_2, A \in N, \gamma \in (T \cup N )^+   , \omega_1, \omega_2 \in (T \cup N)^*$. 
    В виде исключения в КЗ-грамматике допускается наличие правила с пустой правой частью 
    $S \rightarrow \varepsilon$, при условии, что $S$ (начальный символ) не встречается в правых частях правил. 
    
    Цепочку $\omega_1$ называют левым контекстом, цепочку $\omega_2$ называют правым контекстом. Язык, порождаемый контекстно-зависимой грамматикой, называется контекстно-зависимым языком. 
    
    \item \textbf{Тип 2} \\
Грамматика $G = \langle T, N, P, S \rangle$ называется контекстно-свободной (КС), если каждое правило из $P$ имеет вид $A \rightarrow \beta, где A \in N, \beta \in ( T \cup N )^*$.

Заметим, что в КС-грамматиках допускаются правила с пустыми правыми частями.  Язык, порождаемый контекстно-свободной грамматикой, называется контекстно-свободным языком. 

\textbf{Грамматикой типа 2} будем называть контекстно-свободную грамматику. 

    \item \textbf{Тип 3} \\
Грамматика $G = \langle T, N, P, S \rangle$ называется праволинейной, если каждое правило из $P$ имеет вид $A \rightarrow wB$ либо $A \rightarrow w$, где $A, B \in N, w \in T*$.

Грамматика $G = \langle T, N, P, S \rangle$ называется леволинейной, если каждое правило из $P$ имеет вид $A \rightarrow Bw$ либо $A \rightarrow w$, где $A, B \in N, w \in T*$.

При фиксированном языке $L$ два следующих утверждения эквивалентны: 
\begin{itemize}
    \item существует праволинейная грамматика $G_1$, такая что $L = L(G_1)$; 
    \item существует леволинейная грамматика $G_2$, такая что $L = L(G_2)$.
\end{itemize}

Из данного утверждения следует, что праволинейные и леволинейные грамматики определяют один и тот же класс языков, который будем называть классом регулярных языков. Право- и леволинейные грамматики будем называть регулярными грамматиками.  Регулярная грамматика является грамматикой \textbf{типа 3}. 

\end{itemize}

    Существуют различные способы описания языков. Если язык конечен, то его можно описать  простым перечислением входящих в него цепочек. Однако формальный язык может быть бесконечным и в таком случае требуются механизмы, позволяющие конечным образом представлять бесконечное множество цепочек. Можно выделить два основных подхода для такого представления: механизм распознавания, когда описывается процедура, проверяющая принадлежность цепочки описываемому языку,  и механизм порождения (генерации), когда задаётся механизм, способный построить все цепочки описываемого языка. Основной способ реализации механизма порождения --- использование грамматик, которые как раз и описывают правила построения цепочек некоторого языка. Вместе с этим, можно явным образом описать процедуру-генератор цепочек языка, что также будет являться описанием языка. Например, программа на любом языке программирования, генерирующая некоторый текст является описанием языка. В данной работе будут рассматриваться такие программы.


\section{Конечные автоматы и преобразователи}

Одним из способов задания регулярных языков является описание конечного автомата, который может быть использован и как генератор, и как распознаватель.

\begin{mydef}
\textbf{Конечный автомат} (Finite State Automata,~\cite{FSA}) --- это пятёрка $M = \langle Q,\Sigma,\Delta,I,F \rangle$, со следующими элементами.
\begin{itemize}
    \item $\Sigma$ --- конечный алфавит.
    \item $Q$ --- конечное множество состояний.
    \item $I$ --- множество начальных состояний. $I \subseteq Q$.
    \item $F$ --- множество заключительных или допускающих состояний. $F \subseteq Q$.
    \item $\Delta \subseteq Q \times \Sigma ^ * \times Q$.  Если $\langle p, x, q \rangle \in \Delta$, то $\langle p, x, q \rangle$ называется переходом (transition) из $p$ в $q$, а слово $x$ --- меткой (label) этого перехода. В общем случае автомат является недетерминированным (НКА), то есть позволяющим несколько переходов с одинаковым начальным состоянием и одинаковой меткой.
\end{itemize}
\end{mydef}

\begin{mydef}
Конечный автомат $\langle Q , \Sigma , \Delta , I , F \rangle$ называется детерминированным (deterministic) (ДКА), если 
\begin{itemize}
    \item множество $I$ содержит ровно один элемент;
    \item для каждого перехода $\langle p , x , q \rangle \in \Delta$ выполняется равенство $|x| = 1$;
    \item для любого символа $a \in \Sigma$ и для любого состояния $p \in Q$ существует не более одного состояния $q \in Q$ со свойством $\langle p , a , q \rangle \in \Delta$.
\end{itemize}
\end{mydef}

\begin{mydef}
Конечный автомат с $\varepsilon$-переходами --- конечный автомат, в котором есть возможность совершать переходы по $\varepsilon$.
\end{mydef}

\begin{mydef}
\textbf{$\varepsilon$-НКА $A$} --- это НКА $A={\langle\Sigma,Q,s,T,\delta\rangle}$, где все компоненты имеют тот же смысл, что и для НКА, за исключением $\delta : Q\times (\Sigma\cup\{\varepsilon\}) \to 2^Q$.
\end{mydef}

\begin{mydef}
 \textbf{Язык, распознаваемый конечным автоматом $M$,} --- это язык $L(M)$, состоящий из всех допускаемых данным автоматом слов. Также говорят, что автомат $M$ описывает или задаёт некоторый язык $L($M$)$.
\end{mydef}

Класс регулярных языков эквивалентен классу конечных автоматов в том смысле, что для любого регулярного языка $L_1$ можно построить детерминированный конечный автомат $M$, такой $ L(M)=L_1 $. При этом множество языков, допускаемых автоматами с $\varepsilon$-переходами, совпадает с множеством языков, допускаемых детерминированными конечными автоматами. Также будет удобно отождествлять регулярный язык и регулярное множество.

Конечные автоматы можно изображать в виде диаграммами переходов (transition diagram). На диаграмме каждому состоянию соответствует вершина графа, а переходу --- дуга. Дуга из $p$ в $q$, помеченная словом $x$, означает, что $\langle p , x , q \rangle$ является переходом данного конечного автомата. Вершины, соответствующие начальным и конечным состояниям, отмечаются отдельно: конечные состояния изображаются как двойной круг, начальные отмечаются отдельной входной дугой, не имеющей стартовой вершины. Также в данной работе будет использоваться следующая цветовая нотация: конечные вершины обозначены красным цветом, начальные --- зелёным.  Таким образом, автомат представим в виде графа и в данной работе к конечным автоматам будет применяться терминология из теории графов.

\begin{mydef}

\textbf{Конечный преобразователь} \\ (Finite State Transducer,~\cite{FST}) {---} это конечный автомат, который может возвращать конечное число символов для каждого входного символа. Конечный преобразователь может быть задан следующей шестёркой элементов: $\langle Q, \Sigma, \Delta, q_0, F, E \rangle$, где

\begin{itemize}
\item $Q$ --- множество состояний, 
\item $\Sigma$ --- входной алфавит, 
\item $\Delta$ --- выходной алфавит, 
\item $q_0 \in Q$ --- начальное состояние, 
\item $F \subseteq Q$ --- набор конечных состояний, 
\item $E \subseteq Q \times (\Sigma \cup \{\varepsilon\}) \times (\Delta \cup \{\varepsilon\})  \times Q$ --- набор переходов. 
\end{itemize}

\end{mydef}

Конечные преобразователи находят широкое применение в области обработки естественного языка (Natural Language Processing, \cite{Mohri}), также они используются и при проведении лексического анализа, который является переводом входной цепочки из одного языка в другой: из языка над алфавитом символов в язык над алфавитом терминалов. Большинство генераторов лексических анализаторов строят по описанию лексики языка соответствующий конечный преобразователь.

Важной операцией над конечными преобразователями является операция композиции. \textbf{Композиция} конечных преобразователей~{---}~это два последовательно  взаимодействующих конечных преобразователя, работающих таким образом: выход первого конечного преобразователя подаётся на вход второму конечному преобразователю, что позволяет описывать цепочки трансформаций. Ниже дано формальное определение операции композиция над конечными преобразователями, допускающие наличие $\varepsilon$-переходов.

\begin{mydef}

\textbf{Композицией} двух конечных преобразователей \\  $T_1~=~\langle Q_1, \Sigma_1, \Delta_1, q_{0_{1}}, F_1, E_1 \rangle$ и $T_2~=~\langle Q_2, \Sigma_2, \Delta_2, q_{0_{2}}, F_2, E_2 \rangle$ является конечный преобразователь  $T =\langle Q_1  \times Q_2, \Sigma_1, \Delta_2, \\ \langle q_{0_{1}}, q_{0_{2}} \rangle, F_1 \times F_2, E \cup E_{\varepsilon} \cup E_{i,\varepsilon} \cup E_{o,\varepsilon} \rangle$, где 

\begin{itemize}
\item $E = \{ \langle \langle p, q \rangle, a, b, \langle p', q' \rangle \rangle\ | \exists c \in \Delta_1 \cap \Sigma_2 : \langle p, a, c, p' \rangle \in E_1 \wedge \langle q, c, b, q' \rangle \in E_2\}$
\item $E_{\varepsilon} = \{ \langle \langle p, q \rangle, a, b, \langle p', q' \rangle \rangle\ | \langle p, a, {\varepsilon}, p' \rangle \in E_1 \wedge \langle q, {\varepsilon}, b, q' \rangle \in E_2\}$
\item $E_{i, \varepsilon} = \{ \langle \langle p, q \rangle, {\varepsilon}, a, \langle p, q' \rangle \rangle\ | \langle q, {\varepsilon}, a, q' \rangle \in E_2 \wedge p \in Q_1 \} $
\item $E_{o, \varepsilon} = \{ \langle \langle p, q \rangle,  a, {\varepsilon}, \langle p', q \rangle \rangle\ | \langle p, a, {\varepsilon}, p' \rangle \in E_1 \wedge q \in Q_2 \}. $
\end{itemize}
\end{mydef}

В рамках данной работы конечные преобразователи и их композиция будут использоваться для лексического анализа динамически формируемых строковых выражений.


\section{О применимости статического анализа строковых выражений}

Статический анализ динамически формируемых выражений полезен на различных этапах работы с кодом при решении различных задач~\cite{DevelopmentDSQLTools}. Давайте рассмотрим пример и поясним, какие задачи необходимо решать при работе с ним и каким образом анализ строковых выражений помогает решать данные задачи. Мы рассмотрим пример встроенного SQL, однако все рассмотренные задачи актуальны и для других языков.

\fvset{frame=lines,framesep=5pt}
\begin{listing}
    \begin{pyglist}[language=csharp,numbers=left,numbersep=5pt]

public void NewReport(int prodId = 0, int status = 0, int nType = 0)
{
    int nProdIdL = prodId;

    string sMagicKey = "[" + prodId.ToString() + "]";

    string tbl = status == 0 ? "InOrders " : "OutOrders ";

    while (nProdIdL > 0)
    {
        sMagicKey = "[" + sMagicKey + "]";
        nProdIdL = nProdIdL - 1;
    }

    string sExec =
        "SELECT sOrderDescription, cderitInfo, " + sMagicKey + " FROM ts."
        + tbl +
        "as t1 JOIN tCreData cd (NOLOCK) ON cd.ncredataid = t1.ncredataid";

    string sWhere = nType == 0
        ? "WHERE nOrderType = 0 AND nStatus > 2 "
        : "WHERE nStatus > 0 ";

    sExec = "INSERT INTO reports (description, creditInfo, id) VALUES "
            + sExec + sWhere;

    db.Execute(sExec);
}
\end{pyglist}
\caption{Пример кода метода на языке программирования C\#, формирующего и выполняющего динамический SQL-запрос}
\label{lst:csqlExample}
\end{listing}

Одной из задач, решаемых в рамках различных мероприятий является оценка качества кода и его сложности с использованием различных формальных метрик~\cite{SoftwareMetrics}. При построении таких метрик важно учитывать, что использование динамически формируемых выражений, сложность их конструирования, количество и содержание возможных значений и многие другие характеристики сказываются на качестве и сложности самого кода. По этой причине необходимо иметь возможность оценивать сложность динамически формируемых выражений с различных точек зрения~\cite{DSQLQualityMesure, DSQLQualityMesureBIG}. С одной стороны, необходимо оценивать сложность формирования выражения. Так в примере кода~\ref{lst:csqlExample} для формирования запроса используется цикл (строки 9--13), что может приводить к потенциально бесконечному множеству различных значений выражения и усложнять процесс сопровождения. С другой стороны, важна сложность возможных значений выражения. В примере кода~\ref{lst:csqlExample} в динамически формируемом запросе используется конструкция соединения таблиц (\verb|JOIN|, строка 17). Если количество соединений велико и условия в них сложны, то это может стать причиной проблем с производительностью и может служить признаком неудачного дизайна схемы данных~\cite{DSQLQualityMesureBIG}.

Другой ряд задач связан с сопровождением и модификацией систем, разработанных с активным использованием динамически формируемых выражений: извлечение знаний о системе~\cite{DSQLSemaFRecovery}, автоматизированный реинжиниринг программного обеспечения~\cite{DSQLReverseEngineering}. Например, при активном использовании встроенного SQL может возникать задача анализа или восстановления схемы данных~\cite{DevelopmentDSQLTools}. Для кода из листинга~\ref{lst:csqlExample}, проанализировав структурное представление динамически формируемого SQL-кода, можно сделать вывод, что данный метод обращается к таблицам \verb|InOrders|, \verb|OutOrders| и \verb|tCreData| на чтение, а к таблице \verb|reports| на запись. Без анализа строковых выражений эти знания не могут быть получены, а они могут быть полезны, например, при модификации схемы данных.

Так как встроенные языки всё ещё используются на практике, то важна их поддержка в интегрированных средах разработки, что может быть полезно не только при непосредственной разработке, но и при автоматизированном и ручном изучении кода, совмещённом с решением перечисленных выше задач. Дополнительная поддержка встроенных языков в средах разработки может включать подсветку синтаксиса и парных элементов, навигацию по коду с учётом динамически формируемого, диагностику и подсветку ошибок, что упрощает работу с кодом. Например, в листинге~\ref{lst:csqlExample} пропущен пробел между блоком \verb|WHERE| (переменная \verb|sWhere|, строки 20--22) и началом конструкции \verb|SELECT| (переменная \verb|sExec|, строки 15--18). То есть при выполнении данного метода будет формироваться некорректный запрос, но об этом станет известно только в момент выполнения метода. Однако ошибки такого рода можно обнаруживать без запуска программы и сообщать об этом разработчику.

\section{Подходы к анализу встроенных языков}

Анализ динамически формируемых выражений актуален как в задачах обеспечения безопасности программного обеспечения (поиск мест в коде, уязвимых для SQL-инъекций~\cite{SQLInjection}), так и для разработки, сопровождения и модернизации систем, разработанных с применением встроенных языков. Для решения подобных задач существует ряд различных подходов, основные из которых рассмотрены ниже. Инструменты, реализующие данные подходы, будут подробно описаны в следующем разделе.

\textbf{Проверка включения языков.} В рамках данного подхода в результате анализа внешнего кода строится язык $L_1$, являющийся приближением языка $L$, генерируемого программой. После чего проверяется включение $L_1$ в язык $L_2(G)$, описанный эталонной грамматикой $G$. Основной недостаток данного подхода --- невозможность получить какую-либо информацию, кроме знания о вхождении или не вхождении одного языка в другой. Как следствие, проведение более сложных видов статического анализа или трансформации невозможно. Можно выделить несколько вариантов данного подхода, различающихся классом языка $L_1$.

\begin{itemize}
    \item Регулярная аппроксимация: $L_1$ является регулярным языком. Однако язык $L$ не обязан быть регулярным, так как программа-генератор может быть реализована на тьюринг-полном языке, что может приводить к существенной потере точности при построении приближения. Достоинством такого подхода является разрешимость задачи проверки включения $L_1$ в $L_2$ для регулярного $L_1$ и $L_2$, являющегося однозначным контекстно-свободным языком~\cite{LangIncusion}. Инструмент, реализующий данный подход, --- Java String Analizer~\cite{JSA}, являющийся анализатором строковых выражений в коде на Java.

    \item Контекстно-свободное приближение: $L_1$ является контекстно-свободным языком.  Достоинством такого приближения является то, что оно более точное, однако проверка включения для двух контекстно-свободных языков является неразрешимой в общем случае задачей~\cite{LangIncusion}. По  этой причине в результате и при использовании такого приближения будет получено неточное решение. Данный подход реализован в инструменте PHPSA~\cite{PHPSA}, предназначенном для проверки корректности динамически формируемых программами на PHP выражений.

\end{itemize}

\textbf{Синтаксический анализ.} Данный подход основан на применении техник синтаксического анализа для работы с динамически формируемыми выражениями. Благодаря этому, кроме проверки корректности выражений, становится возможным решение более сложных задач, требующих знаний о структуре вывода или работы с деревом разбора, таких как семантический анализ или трансформации. Ниже перечислены существующие на текущий момент варианты данного подхода.

\begin{itemize}
    \item Абстрактный LR-анализ. В исследованиях группы во главе  с Kyung-Goo Doh предлагается комбинация анализа потока данных и синтаксического анализа на основе LALR(k) алгоритма, позволяющая строить множество LR-стеков для всех значений строкового выражения~\cite{LrAbstract1, LrAbstract2, LRAbstractParsingSema}. Так как задача проверки включения для двух КС языков неразрешима, то решение приближённое. В работе~\cite{LRAbstractParsingSema} обоснована возможность семантического анализа на основе классического для LR-анализа механизма: атрибутных грамматик~\cite{Dragon} и выполнения семантического действия при выполнении свёртки. Однако не до конца исследована эффективность данного подхода при работе с семантическими действиями, требующими больших ресурсов при вычислении.

    \item Синтаксический анализ регулярного множества. Для языка $L$ строится регулярная аппроксимация. Далее над построенной аппроксимацией решаются задачи лексического и синтаксического анализа. Данный подход рассмотрен в работах~\cite{Alvor1, Alvor2} и реализован в инструменте Alvor. Данный инструмент является плагином к среде разработки Eclipse, предоставляющим поддержку встроенного SQL в Java: статический поиск ошибок, тестирование запросов в базе данных. Достоинством такого подхода является разделение обработки на независимые шаги: построение аппроксимации, лексический анализ, синтаксический анализ~\cite{Alvor2}. Это позволяет более гибко переиспользовать существующие реализации тех или иных шагов и упрощает создание нового инструмента на базе имеющихся. Использование атрибутных грамматик --- классического для LR-анализа способа задания семантики --- и построение леса разбора в рамках данного подхода также не обсуждается.

\end{itemize}


\section{Обзор инструментов для работы со встроенными языками}

    Задачи анализа динамически формируемых строковых выражений возникают в различных контекстах и применительно к различным языкам, что приводит к появлению достаточно разнообразных инструментов, основные представители которых будут рассмотрены далее.

    Среди языков, код на которых динамически формируется в виде строк, одним из наиболее распространённых является SQL с его многочисленными диалектами.  При этом часто используется динамический SQL --- генерация выражений на SQL в рамках кода на SQL, часто в хранимых процедурах. Одна из актуальных задач, при решении которой необходимо обрабатывать динамический SQL, --- это миграция баз данных, и для её решения которой существует ряд промышленных инструментов. В силу особенностей решаемой задачи нас интересуют инструменты для трансляции хранимого кода баз данных. Самыми известными в данной области являются такие инструменты, как PL-SQL Developer~\cite{PLSQLDeveloper}, SwisSQL~\cite{SwissSQL}, SQL Ways~\cite{SQLWays}. Эти инструменты применяются для трансляции хранимого SQL-кода, однако только SQL Ways обладает возможностью трансформации строковых SQL-запросов в ряде простых случаев. Динамически формируемые запросы со сложной логикой построения не поддерживаются современными промышленными инструментами.
	
	Далее рассмотрим инструменты, которые изначально ориентированы на решение различных задач для динамически формируемых выражений. Многие из них ориентированы на предоставление поддержки встроенных языков в интегрированных средах разработки. Как правило, эти инструменты реализуют один из двух основных подходов. Первый подход заключается в проверке включения языков. Данный подход отвечает на вопрос, включается ли язык, порождаемый анализируемой программой, в язык, описанный пользователем, например, с помощью грамматики или простым перечислением строковых выражений, которых он ожидает получить в результате выполнения программы. Данный подход плохо переиспользуем для решения других задач.  Второй подход заключается в проведении лексического анализа и синтаксического разбора компактного представления множества динамически формируемых выражений. Подробное описание инструментов для анализа динамически формируемых выражений представлено ниже.

\textbf{Java String Analyzer} (JSA, \cite{JSA, JSAUrl}) {---}  инструмент для анализа формирования строк и строковых операций в программах на Java. Основан на проверке включения регулярной аппроксимации встроенного языка в контекстно-свободное описание эталонного. Для каждого строкового выражения строится конечный автомат, представляющий приближенное значение всех значений этого выражения, которые могут быть получены во время выполнения программы. Для того  чтобы получить этот конечный автомат, необходимо из графа потока данных анализируемой программы построить контекстно-свободную грамматику, которая получается в результате замены каждой строковой переменной нетерминалом, а каждой строковой операции {---} правилом продукции. После чего полученная грамматика аппроксимируется регулярным языком. В качестве результата работы данный инструмент также возвращает строки, которые не входят в описанный пользователем язык, но могут сформироваться во время исполнения программы. 

\textbf{PHP String Analyzer} (PHPSA, \cite{PHPSA, PHPSAUrl}) {---} инструмент для статического анализа строк в программах на PHP. Расширяет подход предыдущего инструмента JSA. Использует контекстно-свободную аппроксимацию, что достигается благодаря отсутствию этапа преобразования контекстно-свободной грамматики в регулярный язык, что повышает точность проводимого анализа. Для обработки строковых операций используется конечный преобразователь, который позволяет оставаться в рамках контекстно-свободной грамматики. Дальнейший анализ строковых выражений полностью взят из инструмента JSA.

\textbf{Alvor}~\cite{Alvor1, Alvor2, AlvorUrl} {---} плагин к среде разработки Eclipse\footnote{Сайт среды разработки Eclipse (посещён 23.06.2015): \url{http://www.eclipse.org/ide/}}, предназначенный для статической проверки корректности SQL-выражений, встроенных в Java\footnote{Во время написания данного текста велась работа над поддержкой встроенных языков в PHP.}. Для компактного представления множества динамически формируемого строкового выражения используется понятие абстрактной строки, которая фактически является регулярным выражением над используемыми в строке символами. В инструменте Alvor отдельным этапом выделен лексический анализ. Поскольку абстрактную строку можно преобразовать в конечный автомат, то лексический анализ заключается в преобразовании этого конечного автомата в конечный автомат над терминалами при  использовании конечного преобразователя, полученного генератором лексических анализаторов JFlex~\cite{JFlex}. Несмотря на то, что абстрактная строка позволяет конструировать строковые выражения при участии циклов, плагин сообщает о том, что не может поддержать такие языковые конструкции~(см.рис.~\ref{fig:alvor2}). Также инструмент Alvor не поддерживает обработку строковых операций, за исключением конкатенации~(см. рис.~\ref{fig:alvor3}).

\begin{figure}[h!]
\begin{center}
\begin{tabular}{  c  c }
\begin{minipage}{.5\textwidth}
  \includegraphics[width=\linewidth]{pics/alvor2}
\end{minipage}
    &
\begin{minipage}{.5\textwidth}
  \includegraphics[width=\linewidth]{pics/alvor1}
\end{minipage}
\end{tabular}    
\caption{Формирование строкового выражения с помощью цикла \textbf{\texttt{for}} и \textbf{\texttt{while}} в среде разработке Eclipse с установленным плагином Alvor}
\label{fig:alvor2} 
\end{center}
\end{figure}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{pics/alvor3.png}
\caption{Формирование строкового выражения с помощью строковой операции \textbf{\texttt{replace}}  в среде разработке Eclipse с установленным плагином Alvor}
\label{fig:alvor3} 
\end{center}
\end{figure}

\textbf{IntelliLang~\cite{IntelliLang}} --- плагин к средам разработки PHPStorm~\cite{PHPStorm} и IntelliJ IDEA\footnote{IntelliJ IDEA --- среда разработки для JVM-языков. Сайт (посещён 23.06.2015):\url{https://www.jetbrains.com/idea/}}, предоставляющий поддержку встроенных строковых языков, таких как HTML, SQL, XML, JavaScript в указанных средах разработки. Плагин обеспечивает подсветку синтаксиса, автодополнение, статический поиск ошибок. Для среды разработки IntelliJ IDEA расширение IntelliLang также предоставляет отдельный текстовый редактор для работы со встроенным языком. Для использования данного плагина требуется ручная разметка переменных, содержащих выражения на том или ином встроенном языке, что продемонстрировано на рисунке~\ref{fig:intelliLang}.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{pics/IDEA_html.png}
\caption{IntelliJ IDEA с установленным расширением IntelliLang: переменная \textbf{\texttt{html}} отмечена, как содержащая встроенный язык, а \textbf{\texttt{body}} не отмечена}
\label{fig:intelliLang} 
\end{center}
\end{figure}	
	
\textbf{PHPStorm \cite{PHPStorm}} --- интегрированная среда разработки для PHP, которая осуществляет подсветку и автодополнение встроенного кода на HTML, CSS, JavaScript, SQL. Однако такая поддержка осуществляется только в случаях, когда строка получена без использования каких-либо строковых операций. Также PHPStorm для каждого встроенного языка предоставляет отдельный текстовый редактор.	

\textbf{Varis~\cite{Varis}} ---  плагин для Eclipse, представленный в 2015 году, предоставляющий поддержку кода на HTML, CSS и JavaScript, встроенного в PHP. В плагине реализованы функции  подсветки встроенного кода, автодополнения, перехода к объявлению (jump to declaration), построения графа вызовов (call graph) для встроенного JavaScript. Рисунок~\ref{fig:varis} демонстрирует функции подсветки и автодополнения.

\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{pics/Varis.pdf}
\caption{Пример функциональности Varis: автодополнение и подсветка синтаксиса во встроенном HTML в среде разработки Eclipse}
\label{fig:varis} 
\end{center}
\end{figure}

\textbf{Абстрактный синтаксический анализ}. Kyung-Goo Doh,  Hyunha Kim, David A. Schmidt в серии работ~\cite{LrAbstract1, LrAbstract2, LRAbstractParsingSema} описали алгоритм статического анализа динамически формируемых строковых выражений на примере статической проверки корректности динамически генерируемого HTML в PHP-программах. Хотя для данного примера отсутствует этап проведения лексического анализа, в общем случае можно использовать композицию лексического анализа и синтаксического разбора. Для этого достаточно хранить состояние конечного преобразователя, который используется для лексического анализа, внутри состояния синтаксического разбора. Данный алгоритм также предусматривает обработку строковой операции \verb|string-replacement| с использованием конечного преобразователя, который по аналогии с лексическим конечным преобразователем хранит своё состояние внутри состояния синтаксического разбора. На вход абстрактный синтаксический анализатор принимает data-flow  уравнения, полученные при анализе исходного кода, и  LALR(1)-таблицу. Далее производится решение полученных на вход уравнений в домене LR-стеков.  Проблема возможного бесконечного роста стеков, возникающая в общем случае, разрешается с помощью абстрактной интерпретации (abstract interpretation~\cite{AbstractInterpretation}). В работе~\cite{LRAbstractParsingSema} данный подход был расширен вычислением семантики с помощью атрибутных грамматик, что позволило анализировать более широкий, чем LALR(1), класс грамматик. В качестве результата алгоритм возвращает набор абстрактных синтаксических деревьев. На текущий момент реализацию данного алгоритма в открытом доступе найти не удалось, хотя в работах авторов приводятся результаты апробации. Таким образом, на данный момент не существует доступного инструмента, основанного на данном алгоритме.

\section{Алгоритмы и структуры данных для обобщённого синтаксического анализа}

Анализ динамически формируемых выражений подразумевает работу со множеством значений. При синтаксическом анализе множества появится множество стеков и множество деревьев разбора. Среди существующих алгоритмов есть класс алгоритмов обобщённого синтаксического анализа, в рамках которого разработаны эффективные методы работы с множеством стеков и деревьев разбора. По этой причине рассмотрим некоторые алгоритмы обобщённого синтаксического анализа и применяемые в них структуры данных более подробно.

\subsection{Алгоритм обобщённого LR анализа}

Один из подходов к синтаксическому анализу --- это табличный LR анализ, при котором строится правосторонний вывод и дерево вывода строится снизу вверх. Механизм анализа основан на применении автомата с магазинной памятью, управляющие таблицы для которого строятся на основе грамматики обрабатываемого языка~\cite{Grune}. Идея состоит в том, что символы входной цепочки переносятся в стек до тех пор, пока на вершине стека не накопится цепочка, совпадающая с правой частью какого-либо из правил (операция ``перенос'' или shift). Далее все символы этой цепочки извлекаются из стека, и на их место помещается нетерминал, соответствующий этому правилу (операция ``свёртка'' или  reduce). Входная цепочка допускается автоматом, если после переноса в автомат последнего символа входной цепочки и выполнении необходимого числа свёрток в стеке окажется только стартовый нетерминал грамматики.

Как уже было сказано ранее, при выполнении табличного синтаксического анализа для данной грамматики строятся таблицы: таблица действий и таблица переходов. Таблица переходов ~--- это вспомогательная таблица, использующаяся при одном из действий и в ячейке может содержать либо состояние анализатора, либо символ ошибки.

Таблица действий определяет дальнейшее действие в текущем состоянии и с текущим символом на входе. Каждая ячейка данной таблицы может содержать одно из следующих значений.
\begin{itemize}
    \item \textbf{accept (``успех'')} ~--- разбор входной цепочки завершился успешно.
    \item \textbf{shift (``перенос'')} ~--- на вершину стека переносится состояние, которое соответствует входному символу, читается следующий символ.
    \item \textbf{reduce (``свёртка'')} ~--- в стеке набрались состояния, которые можно заменить одним, исходя из правил грамматики. Значение нового состояния берётся из таблицы переходов.
    \item \textbf{error (``ошибка'')} ~--- анализатор обнаружил ошибку во входной цепочке.
\end{itemize}

При работе с неоднозначными грамматиками могут возникнуть ситуации, когда в одну ячейку таблицы необходимо записать несколько действий. Это означает, что в процессе обработки некоторой цепочки при цепочки анализатор не сможет однозначно решить, какое действие совершить в текущем состоянии. Таким образом возникают конфликты shift/reduce, когда можно либо прочитать очередной символ, либо произвести свёртку, и reduce/reduce, когда можно произвести свёртку по нескольким правилам грамматики.

Для решения данной проблемы Масару Томитой был предложен алгоритм Generalized LR (GLR)~\cite{Tomita}, изначально предназначенный для анализа естественных языков. GLR-алгоритм был предназначен для работы с неоднозначными контекстно-свободными грамматиками, а значит умел обрабатывать shift/reduce и reduce/reduce конфликты. Используемые в данном алгоритме управляющие таблицы схожи с управляющими таблицами LR-алгоритма, но отличаются тем, что ячейки могут содержать несколько действий. Основная идея GLR-алгоритма состоит в проведении всех возможных действий во время синтаксического анализа. При этом для эффективного представления множества стеков и деревьев вывода используются специальные структуры данных, основанные на графах.

\subsection{Структурированный в виде графа стек}

Структурированный в виде графа стек (Graph Structured Stack или GSS)~\cite{Tomita} является ориентированным графом, чьи вершины соответствуют  элементам отдельных стеков, а ребра связывают последовательные элементы. Вершина может иметь несколько входящих рёбер, что соответствует слиянию нескольких стеков или несколько исходящих, что соответствует конфликту --- ситуации в которой дальнейший разбор может осуществляться несколькими способами. Объединение стеков происходит в процессе анализа, когда на вершинах различных веток, соответствующих одинаковой позиции во входном потоке, оказывается одинаковое состояние анализатора. За счёт такой организации GSS обеспечивается переиспользование общих участков отдельных стеков. Пример организации GSS приведён на рисунке~\ref{fig:gss}: наивное решение копировать стеки при возникновении конфликтов приводит к дублированию информации, чего можно избежать при использовании GSS. 

\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{pics/ex_gss.png}
\caption{Пример GSS}
\label{fig:gss} 
\end{center}
\end{figure}

\subsection{Сжатое представление леса разбора}

Для переиспользования общих поддеревьев вывода Ян Рекерс предложил компактное представление леса разбора (Shared Packed Parse Forest, SPPF)~\cite{SPPF}, которое позволяет компактно представлять множество деревьев вывода. Важным свойством SPPF является то, что из него можно извлечь только те и только те деревья, которые могли быть получены в результате построения вывода конкретного входа в заданной грамматике. Для обеспечения этого свойства в SPPF, кроме терминальных и нетерминальных узлов, добавляются дополнительные узлы различных типов. Конкретный набор типов дополнительные узлов может отличаться в зависимости от алгоритма анализа.

\fvset{frame=lines,framesep=5pt}
\begin{listing}
    \begin{pyglist}[numbers=left,numbersep=5pt]

s ::= m 
s ::= p
p ::= A n
m ::= A l
l ::= n
n ::= B C

\end{pyglist}
\caption{Грамматика $G_1$}
\label{lst:g1}
\end{listing}


Пример SPPF для грамматики $G_1$, представленной на листинге~\ref{lst:g1}, и входа \verb|ABC| приведён на рисунке~\ref{fig:ex_sppf}. Представлены два различных дерева вывода~(\ref{fig:ex_sppf1} и ~\ref{fig:ex_sppf2}) и результат их объединения в SPPF~\ref{fig:ex_sppf3}. Узлы с именами вида ``n <name>'' --- это нетерминальные узлы, ``е <name>'' --- терминальные, ``prod <num>'' --- дополнительные узлы, показывающие, согласно какой продукции из грамматики прозводился вывод нетерминала, являющегося предком данного узла.  

\begin{figure}[h!]
\centering
   \begin{subfigure}[b]{0.3\textwidth}
       \includegraphics[width=\textwidth]{pics/ex_sppf1}
       \caption{Первое дерево вывода}
       \label{fig:ex_sppf1}
   \end{subfigure}
   ~ 
   \begin{subfigure}[b]{0.3\textwidth}
       \includegraphics[width=\textwidth]{pics/ex_sppf2}
       \caption{Второе дерево вывода}
       \label{fig:ex_sppf2}
   \end{subfigure}
   ~
   \begin{subfigure}[b]{0.3\textwidth}
       \includegraphics[width=\textwidth]{pics/ex_sppf3}
       \caption{Объединение деревьев вывода в SPPF}
       \label{fig:ex_sppf3}
   \end{subfigure}
   \caption{Пример SPPF для грамматики $G_1$ и входа \textbf{\texttt{ABC}}}
   \label{fig:ex_sppf} 
\end{figure}

\subsection{Алгоритм RNGLR}

RNGLR-алгоритм (Right-Nulled Generalized LR)~\cite{RNGLR} является модификацией предложенного Масару Томитой алгоритма, который не был способен обрабатывать все контекстно-свободные грамматики. Чтобы устранить данный недостаток, Элизабет Скотт и Адриан Джонстоун предложили RNGLR-алгоритм, который расширяет GLR-алгоритм специальным способом обработки обнуляемых справа правил (right-nullable rules, имеющих вид $\mathrm{A} \rightarrow \alpha \beta$, где $\beta$ выводит пустую строку $\epsilon$), позволяя обрабатывать произвольные контекстно-свободные грамматики. Алгоритм синтаксического анализа динамически формируемых выражений, представленный в данной работе, основан на RNGLR-алгоритме, по этой причине его подробное описание в виде псевдокода приведено ниже.

\begin{algorithm}[!ht]
\begin{algorithmic}[1]
\caption{RNGLR-алгоритм}
\label{rnglr}
\Function{parse}{$grammar, input$}
  \State{$\mathcal{R} \gets \emptyset$} \Comment{Очередь троек: вершина GSS, нетерминал, длина свёртки}
  \State{$\mathcal{Q} \gets \emptyset$} \Comment{Коллекция пар: вершина GSS, состояние синтаксического анализатора}
  \If{$input = \epsilon$}
    \If{$grammar$ accepts empty input} {report success}
    \Else { report failure}
    \EndIf
  \Else
    \State{\Call{addVertex}{$0, 0, startState$}}
    \ForAll{$i$ in $0..input.Length-1$}
      \State{\Call{reduce}{$i$}}
      \State{\Call{push}{$i$}}
    \EndFor
    \If{$i=input.Length-1$ and there is a vertex in the last level of GSS which state is accepting}
      \State{report success}
    \Else { report failure}
    \EndIf
  \EndIf
\EndFunction
\Function{reduce}{$i$}
  \While{$\mathcal{R}$ is not empty}
    \State{$(v, N, l) \gets \mathcal{R}.Dequeue()$}
    \State{find the set $\mathcal{X}$ of vertices reachable from $v$ along the path of length $(l-1)$}
    \State{or length $0$ if $l=0$}
    \ForAll{$v_{h} = (level_{h}, state_{h})$ in $\mathcal{X}$}
      \State{$state_{t} \gets$ calculate new state by $state_{h}$ and nonterminal $N$}
      \State{\Call{addEdge}{$i, v_{h}, v.level, state_{tail}, (l=0)$}}
    \EndFor
  \EndWhile
\EndFunction
\Function{push}{$i$}
  \State{$\mathcal{Q^{'}} \gets$ copy $\mathcal{Q}$}
  \While{$\mathcal{Q^{'}}$ is not empty}
    \State{$(v, state) \gets \mathcal{Q}.Dequeue()$}
    \State{\Call{addEdge}{$i, v, v.level + 1, state, false$}}
  \EndWhile
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!ht]
\begin{algorithmic}[1]
\caption{Построение GSS}
\label{RNGLRMain}
\Function{addVertex}{$i, level, state$}
  \If{GSS does not contain vertex $v = (level, state)$}
    \State{add new vertex $v = (level, state)$ to GSS}
    \State{calculate the set of shifts by $v$ and the $input[i+1]$ and add them to $\mathcal{Q}$}
    \State{calculate the set of zero-reductions by $v$ and the $input[i+1]$ and}
    \State{add them to $\mathcal{R}$}
  \EndIf
  \State{\Return{$v$}}
\EndFunction
\Function{addEdge}{$i, v_{h}, level_{t}, state_{t}, isZeroReduction$}
  \State{$v_{t} \gets$ \Call{addVertex}{$i, level_{t}, state_{t}$}}
  \If{GSS does not contain edge from $v_{t}$ to $v_{h}$}
    \State{add new edge from $v_{t}$ to $v_{h}$ to GSS}
    \If{not $isZeroReduction$}
      \State{calculate the set of reductions by $v$ and the $input[i+1]$ and}
      \State{add them to $\mathcal{R}$}
    \EndIf
  \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

Для эффективного представления множества стеков во время синтаксического анализа в алгоритме RNGLR, как и в классическом GLR, используется структурированный в виде графа стек (GSS). Вершина GSS~--- это пара $(s,l)$, где $s$~--- состояние синтаксического анализатора, а $l$~--- уровень (позиция во входном потоке).

RNGLR-алгоритм последовательно считывает символы входного потока слева направо, по одному за раз, и строит GSS по ``слоям'': сначала осуществляются все возможные свёртки для данного символа, после чего сдвигается следующий символ со входа. Свёртка или сдвиг модифицируют GSS следующим образом. Предположим, что необходимо добавить ребро $(v_t,v_h)$ в GSS. По построению, конечная вершина добавляемой дуги к такому моменту уже обязательно находится в GSS. Если начальная вершина также содержится в GSS, то в граф добавляется новое ребро (если оно ранее не было добавлено), иначе создаются и добавляются в граф и начальная вершина, и ребро. Каждый раз, когда создаётся новая вершина $v=(s,l)$, алгоритм вычисляет новое состояние синтаксического анализатора $s'$ по $s$ и следующему символу входного потока. Пара $(v,s')$, называемая push, добавляется в глобальную коллекцию $\mathcal{Q}$. Также при добавлении новой вершины в GSS вычисляется множество $\epsilon$-свёрток, после чего элементы этого множества добавляются в глобальную очередь $\mathcal{R}$. Свёртки длины $l>0$ вычисляются и добавляются в $\mathcal{R}$ каждый раз, когда создаётся новое (не-$\varepsilon$) ребро. Подробное описание работы со структурированным в виде графа стеком GSS содержится в алгоритме~\ref{RNGLRMain}.

В силу неоднозначности грамматики входная строка может иметь несколько деревьев вывода, как правило, содержащих множество идентичных поддеревьев. Для того чтобы компактно хранить множество деревьев вывода, используется SPPF, являющееся ориентированным графом и в данном случае обладающее следующей структурой.
\begin{enumerate}
  \item \emph{Корень} (то есть, вершина, не имеющая входящих дуг) соответствует стартовому нетерминалу грамматики.
  \item {Терминальные} вершины, не имеющие исходящих дуг, соответствуют либо терминалам грамматики, либо деревьям вывода пустой строки $\varepsilon$.
  \item \emph{Нетерминальные} вершины являются корнем дерева вывода некоторого нетерминала грамматики; только вершины-продукции могут быть непосредственно достижимы из таких вершин.
  \item \emph{Вершины-продукции}, представляющие правую часть правила грамматики для соответствующего нетерминала. Вершины, непосредственно достижимые из них, упорядочены и могут являться либо терминальными, либо нетерминальными вершинами. Количество таких вершин лежит в промежутке $[l-k \dots l]$, где $l$~--- это длина правой части продукции, а $k$~--- количество финальных символов, выводящих $\varepsilon$. При этом правые обнуляемые символы игнорируются для уменьшения потребления памяти.
\end{enumerate}

SPPF создаётся параллельно с построением GSS. С каждым ребром GSS ассоциирован либо терминальный, либо нетерминальный узел. Когда добавление ребра в GSS происходит во время операции push, новая терминальная вершина создаётся и ассоциируется с ребром. Нетерминальные вершины ассоциируются с рёбрами, добавленными во время операции reduce. Если ребро уже есть в GSS, к ассоциированной с ним нетерминальной вершине добавляется новая вершина-продукция. Подграфы, ассоциированные с рёбрами пути, вдоль которого осуществлялась свёртка, добавляются как дети к вершине-продукции. После того, как входной поток прочитан до конца, производится поиск всех вершин, имеющих принимающее состояние анализатора, после чего подграфы, ассоциированные с исходящими из таких вершин рёбрами, объединяются в один граф. Из полученного графа удаляются все недостижимые из корня вершины, в результате чего остаются только корректные деревья разбора для входной строки. 

Алгоритм~\ref{rnglr} представляет более детальное описание алгоритма.

	
\section{Используемые инструменты}


\subsection{YaccConstructor}

    Одной из задач данной работы является создание инструментария, упрощающего создание целевых инструментов статического анализа строковых выражений, которые включают такие этапы, как лексический и синтаксический анализы. При создании лексических и синтаксических анализаторов широко распространённой практикой является использование генераторов, которые по описанию языка строят соответствующий анализатор. Данный подход должен быть реализован и для создания инструментов анализа встроенных языков.
    Работа с описаниями языков программирования --- грамматикой и лексический спецификацией --- в рамках решаемой задачи аналогична работе с ними в стандартных генераторах. По этой причине необходимо было выбрать готовую платформу для работы с грамматиками и создания синтаксических и лексических анализаторов.

		В качестве такой платформы был выбран исследовательский проект лаборатории языковых инструментов JetBrains YaccConstructor(YC)~\cite{YCArticle, YCUrl}, который является модульной платформой с открытым исходным кодом для исследований в области лексического и синтаксического анализа и разработки соответствующих инструментов. YC реализован на платформе Microsoft .NET\footnote{Microsoft .NET --- платформа для разработки программных продуктов компании Microsoft. Общие сведения о платформе (посещено 23.06.2015): \url{https://msdn.microsoft.com/ru-ru/library/zw4w595w(v=vs.110).aspx}}, основной язык разработки --- F\#~\cite{FSharp}

\begin{figure}[h!]
\begin{center}
\includegraphics[width=.9\textwidth]{pics/Varis.pdf}
\caption{Архитектура платформы YaccConstructor}
% * <Andrew Ivanov> 11:55:29 26 Jun 2015 UTC+0300:
% Это явно не архитектура YC
\label{fig:ycarch} 
\end{center}
\end{figure}

		
	Архитектура YC, представленная на рисунке~\ref{fig:ycarch}, позволяет собирать требуемый инструмент из существующих модулей: можно выбрать фронтенд, соответствующий используемому языку спецификации грамматики, задать необходимые преобразования грамматики, указать необходимый генератор. Генераторы (backend) представляют различные инструменты, которые преобразуют внутреннее представление грамматики в нечто, полезное для конечного пользователя. Например, это могут быть генераторы синтаксических анализаторов, основанные на различных алгоритмах или принтеры, генерирующие текст грамматики в определённом формате или на определённом языке. YC является расширяемой платформой: модуль любого типа может быть реализован, в том числе с переиспользованием уже существующих, и подключён к платформе.  

	В рамках YC разработан выразительный язык спецификации грамматик YARD, поддерживающий атрибутные грамматики, грамматики в EBNF и многое другое. Например, в листинге~\ref{lst:calcExample} представлена грамматика языка арифметических выражений Calc на языке YARD.  

\fvset{frame=lines,framesep=5pt}
\begin{listing}
    \begin{pyglist}[numbers=left,numbersep=5pt]
    
    [<Start>]
    expr: factor [MULT expr]
    powExpr: NUM | LBR expr RBR
    factor: powExpr [POW factor]
    
\end{pyglist}
\caption{Пример грамматики языка арифметических выражений на языке YARD}
\label{lst:calcExample}
\end{listing}


	Выразительность синтаксиса языка описания грамматики удобна для разработчика, однако генераторы, как правило, не умеют работать с грамматиками в таком виде. Часто требуется, чтобы в правой части правила не было регулярных выражений, а стояла просто цепочка из терминалов и нетерминалов. Для решения этой проблемы в YC реализован ряд преобразований грамматик. В результате их применения к грамматике, представленной в листинге~\ref{lst:calcExample}, можно получить грамматику, представленную в листинге~\ref{lst:calcTransformExample}.

\fvset{frame=lines,framesep=5pt}
\begin{listing}
    \begin{pyglist}[numbers=left,numbersep=5pt]
    
    [<Start>]
    expr: factor 
    expr: factor MULT expr
    powExpr: NUM 
    powExpr: LBR expr RBR
    factor: powExpr
    factor: powExpr POW factor
    startRule: expr

\end{pyglist}
\caption{Пример преобразованной грамматики языка арифметических выражений}
\label{lst:calcTransformExample}
\end{listing}

	Также в рамках платформы YC в качестве одного из модулей ранее был реализован генератор синтаксических анализаторов на основе RNGLR-алгоритма. Это позволяет переиспользовать общие функции и структуры данных при разработке анализатора для встроенных языков. 
	Таким образом, алгоритм анализа встроенных языков и соответствующий генератор может быть реализован в рамках платформы YC в качестве одного из модулей. При этом можно использовать готовый язык описания грамматики и преобразования, а также переиспользовать необходимые элементы генератора анализаторов на основе RNGLR-алгоритма. Таким образом, YC был выбран в качестве основы для реализации благодаря удобной архитектуре и большому количеству готовых решений. 


\subsection{ReSharper SDK}

    Для демонстрации разработанного в рамках данной работы инструмента необходимо создать на его основе конечное решение. Для этого необходимо окружение, способное обрабатывать внешний язык, так как такие операции над внешним языком, как построение дерева разбора, базовый анализ, такой как построение графа потока управления или графа потока данных, лежат за пределами рассматриваемой в данной работе задачи, и их выполнение должно осуществляться сторонними инструментами. При этом такие инструменты должны предоставлять необходимую для решения основной задачи функциональность. Кроме того, необходимо иметь удобный способ взаимодействия с пользователем: необходимо получать код для анализа и отображать результаты в виде, удобном для пользователя. Один из самых распространённых способов работы с программным кодом --- это работа в интегрированной среде разработки.

    Так как реализация работы велась на платформе Microsoft .NET, то соответствующее окружение для обработки внешнего языка и организации взаимодействия с пользователем на данной платформе должно работать на данной платформе. Одной из самых известных сред разработки для платформы .NET, позволяющей создавать расширения на .NET языках, является Microsoft Visual Studio IDE\footnote{Сайт среды разработки Microsoft Visual Studio IDE (посещён 23.06.2015): \url{https://www.visualstudio.com/}}. Она и была выбрана в качестве цели для интеграции инструмента статического анализа строковых выражений. Однако у данной среды разработки достаточно сложный механизм создания расширений, что вызвано его универсальностью. При решении нашей задачи универсальность не требовалась, поэтому можно было бы использовать менее универсальный и более простой механизм.

Такой механизм предоставляется ReSharper SDK~\cite{ReSharperSDK}.  ReSharper~\cite{ReSharper} --- расширение для Microsoft Visual Studio, предоставляющее пользователю широкий набор дополнительных анализов кода. Для разработчиков предоставляется свободно распространяемая SDK, реализующая анализы таких языков, как C\#, VB.NET и др. Большая часть функциональности ReSharper выделена в свободно распространяемую SDK, что даёт возможность сторонним разработчикам создавать собственные расширения к ReSharper, переиспользуя его функциональность. В контексте данной работы это позволяет упростить создание плагинов для поддержки различных встроенных языков. Кроме того, позволяет ReSharper SDK предоставляет более удобную обёртка над многими интерфейсами Microsoft Visual Studio, что упрощает взаимодействие с ней и полезно, например, при предоставлении результатов анализа пользователю.
% * <Andrew Ivanov> 12:03:06 26 Jun 2015 UTC+0300:
% Поправить
% ^ <Andrew Ivanov> 12:03:24 26 Jun 2015 UTC+0300:
% "позволяет ReSharper SDK предоставляет более удобную обёртка"

Кроме того, ReSharper является многоязыковым инструментом, то есть поддерживает большой набор различных языков и спроектирован так, чтобы максимально упростить поддержку новых языков. Это позволяет создавать инструменты, обрабатывающие не только различные встроенные языки, но и различные внешние.

Среди функциональности, предоставляемой ReSharper SDK можно выделить необходимую для реализации поддержки встроенных языков в Microsoft Visual Studio.  
\begin{itemize}
    \item Дерево разбора внешнего языка (C\#, JavaScript и другие, поддерживаемые ReSharper), узлы которого содержат координаты в исходном коде, что позволяет точно связывать текстовое и структурное представление кода.
    \item Анализ потока данных и анализ потока управления для поддерживаемых языков. На основе существующих анализов можно строить более сложные, необходимые, например, для построения регулярной аппроксимации.
    \item Вывод сообщений об ошибках и графическое выделение некорректных мест в текстовом редакторе.
    \item Взаимодействие с редактором кода, позволяющее настраивать подсветку синтаксиса, получать позицию курсора и управлять ею, что нужно для динамической подсветки парных элементов.
\end{itemize}

Таким образом ReSharper SDK и Microsoft Visual Studio IDE выбраны в качестве основы для примера разработки целевого инструмента на основе разработанного решения.

\section{Выводы}

На основе проведённого обзора можно сделать следующие выводы, обосновывающие необходимость проведения исследований в области статического анализа динамически формируемых строковых выражений.

\begin{itemize}
    \item Проблема анализа строковых выражений актуальна в нескольких областях: поддержка встроенных языков в интегрированных средах разработки, оценка качества кода, содержащего динамически формируемые строковые выражения, реинжиниринг программного обеспечения.
    \item Для решения ряда важных задач необходимо структурное представление кода, однако на текущий момент не представлено законченного решения, позволяющего строить деревья вывода для динамически формируемых выражений.
    \item Большинство реализаций поддерживают конкретный внешний и конкретный встроенный язык и как правило решают одну достаточно узкую задачу. При этом, зачастую, плохо расширяемы, как в смысле поддержки других языков, так и в смысле решения новых задач. Полноценные средства разработки инструментов статического анализа динамически формируемых выражений, упрощающие создание решений для новых языков, отсутствуют.
\end{itemize}

Кроме того, обзор позволяет выявить предпочтительные направления исследований, используемые методы, технологии, подходы.

\begin{itemize}
    \item В качестве приближения множества возможных значений будет использоваться регулярная аппроксимация, так как при работе с ней ряд важных задач является разрешимым в общем случае, что не верно для контекстно-свободной. Более того, работа с регулярной аппроксимацией упрощает решение такой задачи, как лексический анализ встроенных языков.
    \item Лексический и синтаксический анализы должны быть разделены. Это оправдано как с теоретической, так и с практической точек зрения, так как лексический анализ не привносит потери точности и упрощается переиспользование спецификаций языков и самих анализаторов. 
    \item В качестве основы алгоритма синтаксического анализа можно выбрать обобщённый синтаксический анализ, так как в рамках него реализовано эффективное управление множеством стеков и деревьев разбора, что важно при работе с динамически формируемыми выражениями.
\end{itemize}
\clearpage

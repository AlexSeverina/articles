%for compilation: xelatex psi_2015.tex 
\documentclass{llncs}

\usepackage{makeidx}  % allows for indexgeneration
\usepackage{listings}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{caption}
\usepackage{algorithmicx}
\usepackage{mathspec}
\usepackage{textcomp}

\begin{document}

\frontmatter          % for the preliminaries

\pagestyle{headings}  % switches on printing of running heads
\addtocmark{Hamiltonian Mechanics} % additional mark in the TOC

\title{Relaxed Parsing for Regular Approximations of String-Embedded Languages}
\titlerunning{Relaxed Parsing for Regular Approximations of String-Embedded Languages}  % abbreviated title (for running head)


\author{Ekaterina Verbitskaia\inst{1} \and Semen Grigorev\inst{2}
\and Dmitry Avdyukhin\inst{3}}
%
%\authorrunning{Ivar Ekeland et al.} % abbreviated author list (for running head)
%

\institute{Saint Petersburg State University\\
\email{kajigor@gmail.com},
\and
\email{rsdpisuy@gmail.com}
\and
\email{dimonbv@gmail.com}}

\maketitle              % typeset the title of the contribution

\begin{abstract}
We present a technique for syntax analysis of a regular set of input strings. 
This problem is relevant for analysis of string-embedded languages when a host 
program generates clauses of embedded language at run time. Our technique 
is based on a generalization of RNGLR algorithm, which, inherently, allows 
us to construct a finite representation of parse forest for regularly 
approximated set of input strings. This representation can be further 
utilized for semantic analysis and transformations in the context of 
reengineering, code maintenance, program understanding etc. The approach 
in question implements \emph{relaxed parsing}: non-recognized strings 
in approximation set are ignored with no error detection. 
\keywords{string-embedded languages, string analysis, parsing, parser generator, RNGLR.}
\end{abstract}

\section*{Introduction}
There is a broad class of applications which utilize the idea of \emph{string embedding} of one 
language into another. In this approach a host program generates string representation of 
clauses in some external language, which are then passed to a dedicated runtime 
component for analysis and execution. One significant example of string embedded 
language is embedded SQL~\cite{DSQLISO}; among others some frameworks 
such as JSP~\cite{JSP} and PHP mySQL interface\footnote{http://php.net/manual/en/mysqli.query.php} 
can be mentioned.

Despite providing a high level of expressiveness and flexibility, string embedding makes the 
behavior of the system less predictable and harder to reason about since a whole class of 
verification procedures is postponed until run time, which complicates development, 
testing and maintenance. To overcome this defficiency it is desirable to perform syntax 
analysis of well-formedness of all generated clauses prior to execution. However, since the 
host language as a rule is Turing-complete, the precise analysis is undecidable; the common 
approach is to analyse an over-approximating set of strings represented in some constructive form. 
It's worth to mention that, similarly to regular syntax analysis, the analysis of string-embedded 
languages often follows the two-level scheme: first a set of strings is tokenized to provide an 
approximation for tokenized stream set, then this set is parsed by a syntax analyzer.

This paper contributes a generalization of RNGLR~\cite{RNGLR} algorithm, which, instead of
linear stream of tokens, analyzes a regular set of streams. Our algorithm can be considered as
proper generalization since it provides exactly the same result as the original one on a
trivial set; moreover, our implementation reuses original RNGLR control tables. The distinctive 
feature of our approach in comparison with other techniques for analysis of string-embedded 
languages is that it provides the set of parsing trees, encoded in the form of Shared Packed 
Parse Forest (SPPF)~\cite{SPPF}. The choice of RNGLR looks quite natural in this regard
since in its original form it already incorporates the technique to deal with multiple
ways of parsing. On the other hand, our approach can be categorized as \emph{relaxed} 
parsing since it silently ignores non-recognized part of input; we do not consider this 
property as an essential drawback because it only means that to provide best results
it has to be combined with some existing recognition-centric approach.

The rest of the paper is organized al follows: in the next section we provide a
survey of related works and results [TODO].

\section{Related Works}

Our parsing algorithm is based on a RNGLR-algorithm presented by Elizabeth Scott 
and Adrian Johnstone in~\cite{RNGLR}. In order to better understand the paper, a reader 
should be familiar to its principles of work, so we briefly describe RNGLR-algorithm 
in this section.  Also we point out differences between our approach and existing
tools which operate with regular approximation of string-embedded language since
we use such type of approximation as input for our algorithm.

\subsection{Regular Approximation of Sting-Embedded Language}
Some tools are aimed to build high quality regular approximation. For example, 
Stranger~\cite{Stranger} which use forward reachability analysis to compute 
over-approximation of all string values for program. Further analysis in Stranger 
is based on patterns detection in approximation or generation finite subset of 
strings for analyzing with standalone tools. Implementation of our algorithm may 
use such tools as input generators.

Paper~\cite{JSA} presents Java String Analyzer (JSA) — tool for static syntax 
correctness checking of embedded SQL statements.  This tool build regular approximation 
with Mohri-Nederhof~\cite{MohriNederhof} algorithm and then check its inclusion into reference grammar 
without parsing and forest construction.
 
Our algorithm is inspired by Alvor~\cite{Alvor} which apply GLR-based technique 
for syntax correctness checking of regular approximation. Key difference of our 
algorithm is building of parse forest finite representation. 

\subsection{RNGLR}
RNGLR stands for Right-Nulled Generalized LR and is able to process all context-free 
grammars including ambiguous. Ambiguities of grammar produce Shift/Reduce and 
Reduce/Reduce conflicts; the algorithm carry out all possible actions in such situations. 
The algorithm uses parser tables, each cell of which can contain multiple actions 
in case of conflicts. 

RNGLR-algorithm uses Graph Structured Stack (GSS) — efficient representation of 
the set of stacks produced during conflict processing. GSS is an ordered graph, 
vertices of which corresponds to elements of classical stack and edges link sequential 
elements together. Each vertex can have multiple incoming edges and by means of 
it be shared between several stacks. Vertex is a pair $(s, l)$, where $s$ is a 
parser state and $l$ is a level — position in an input string. Vertices in GSS 
are unique and there is no multiple edges. GSS construction routine is illustrated 
with pseudocode sample~\ref{rnglr}: addVertex and addEdge functions. 

The feature of RNGLR-algorithm which let it process all context-free grammars is
a specific way of handling \textit{right nullable} rules (i.e. rules of the form 
$\mathrm{A} \rightarrow \alpha \beta$, where $\beta$ reduces to the empty string). 
That is, not only reductions for items $\mathrm{A} \rightarrow \alpha \cdot$ are 
applied, but also for the items of the form  $\mathrm{A} \rightarrow \alpha \cdot 
\beta$, where $\beta \Rightarrow \epsilon$. Thus, reduction length — the number of 
symbols to be reduced to a nonterminal — may be less than or equal to the length 
of righthand side of the rule. There are also possible reductions of 0-length, 
also called as $\epsilon$-reductions, corresponding to items of the form $\mathrm{A} 
\rightarrow \cdot$. 

RNGLR-algorithm reads an input from left to right, one token at a time, and 
constructs levels of GSS sequentially for each position in the input. In the 
main loop of the algorithm for each token from the input, firstly, all possible 
reductions are applied (see reduce function in pseuducode sample~\ref{rnglr}), and then the next  token 
is shifted (see push function in pseuducode sample~\ref{rnglr}).

\begin{algorithm}[!ht]
\begin{algorithmic}[1]
\caption{RNGLR algorithm}
\label{rnglr}
  
\Function{addVertex}{$level, state$}
  \If{GSS does not contain vertex $v = (level, state)$}
    \State{add new vertex $v = (level, state)$ to GSS}
    \State{calculate the set of shifts by $v$ and the next token and add them to $\mathcal{Q}$}
    \State{calculate the set of zero-reductions by $v$ and the next token and add them to $\mathcal{R}$}
  \EndIf
  \State{\Return{$v$}}
\EndFunction

\Function{addEdge}{$v_{h}, level_{t}, state_{t}, isZeroReduction$}
  \State{$v_{t} \gets$ \Call{addVertex}{$level_{t}, state_{t}$}}
  \If{GSS does not contain edge from $v_{t}$ to $v_{h}$}
    \State{add new edge from $v_{t}$ to $v_{h}$ to GSS}
    \If{not $isZeroReduction$}
      \State{calculate the set of reductions by $v$ and the next token and add them to $\mathcal{R}$}
    \EndIf
  \EndIf
\EndFunction

\Function{reduce}{}
  \While{$\mathcal{R}$ is not empty}
    \State{$(v, N, l) \gets \mathcal{R}.Dequeue()$}
    \State{find the set $\mathcal{X}$ of vertices reachable from $v$ along the path of length $(l-1)$, or length $0$ if $l=0$}
    \ForAll{$v_{h} = (level_{h}, state_{h})$ in $\mathcal{X}$}
      \State{$state_{t} \gets$ calculate new state by $state_{h}$ and nonterminal $N$}
      \State{\Call{addEdge}{$v_{h}, v.level, state_{tail}, (l=0)$}}
    \EndFor
  \EndWhile
\EndFunction

\Function{push}{}
  \State{$\mathcal{Q^{'}} \gets$ copy $\mathcal{Q}$}
  \While{$\mathcal{Q^{'}}$ is not empty}
    \State{$(v, state) \gets \mathcal{Q}.Dequeue()$}
    \State{\Call{addEdge}{$v, v.level + 1, state, false$}}
  \EndWhile
\EndFunction

\end{algorithmic}
\end{algorithm}

\section{Algorithm}
Input of the algorithm is a reference grammar $G$ with alphabeth of terminal symbols $T$ 
and a finite automaton $(Q, \Sigma, \delta, q0, F)$, where 
$\Sigma \subseteq T$. RNGLR parser tables and some accessory information ($parserSource$ 
in pseudocode sample~\ref{parsing}) are generated by reference grammar $G$. 
Likewise RNGLR-algorithm, we associate GSS vertices with the position in the input,
and in our case the position is a state of the input automaton. We construct the inner 
data structure by copying input automaton graph and extending vertex type with 
the following collections: 
\begin{description}
  \item[processed] \hfill \\ GSS vertices, all the pushes for which are processed. 
                             This collection aggregates all GSS vertices associated with inner graph vertex.
  \item[unprocessed] \hfill \\ GSS vertices, pushes for which are to be processed. 
                               This collection is analogous to $\mathcal{Q}$ from classic RNGLR-algorithm.
  \item[reductions] \hfill \\ Queue which is analogous to $\mathcal{R}$ from classic RNGLR-algorithm: 
                              stores reductions to be processed.
  \item[passingReductionsToHandle] \hfill \\ Pairs of GSS vertex and GSS edge to apply passing reductions along them.
\end{description}

Besides parser $state$ and $level$ (which is equal to the input automaton state), 
we store collection of passing reductions in GSS vertex. Passing reduction is a 
three-tuple $(startV, N, l)$, representing reductions which path passed through 
the GSS vertex. This three-tuple is very similar to the one describing reductions, 
but in this case $l$ is a remaining length of the path. Passing reductions are 
stored in all vertices of the path except the first and the last during path 
searching in makeReductions function (see pseuducode sample~\ref{processVertex}).

The general idea of the algorithm is to traverse input graph and sequentially construct GSS
in the similar manner as RNGLR does. When deal with graph instead of linear stream,
the next symbol means the set of terminals on outgoing edges of current vertex.
This leads to slightly different process of push and reduce calculation: 
see line 9 in pseudocode sample~\ref{processVertex} and lines 7 and 22 in pseudocode 
sample~\ref{gss_construction}. We use queue $Q$ to control the order of input graph vertices 
processing. Every time new GSS vertex is added, zero reductions should be processed 
and then new tokens could be shifted, so corresponging graph vertex should be 
enqueueed for further processing. Adding of new GSS edge could produce reductions 
to handle, so input graph vertex with which tail of the added edge is associated should 
also be enqueueed. See details of GSS construction in pseudocode sample~\ref{gss_construction}. 
Reductions are applied along the paths in GSS, and if new edge 
which tail vertex have been in the graph before is added, then new paths will possibly 
be added which means some reductions would be lost. So it is necessary to recalculate 
those passing reductions: see applyPassingReductions function in pseudocode sample~\ref{processVertex}.
\begin{algorithm}[!ht]
\begin{algorithmic}[1]
\caption{Parsing algorithm}
\label{parsing}

\Function{parse}{$inputGraph, parserSource$}
  \If{$inputGraph$ contains no edges}
    \If{$parserSource$ accepts empty input }
      \State{report success}
    \Else
      \State{report failure}
    \EndIf
  \Else
    \State{\Call{addVertex}{$inputGraph.startVertex, startState$}}
    \State{$Q.Enqueue(inputGraph.startVertex)$}
    \While{no $error$ have found and $Q$ is not empty}
      \State{$v \gets Q.Dequeue()$}
      \State{\Call{processVertex}{$v$}}
    \EndWhile
    \If{$v_f$ is the vertex in the last level of GSS and its state is accepting}
      \State{report success}
    \Else
      \State{report failure}
    \EndIf
  \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!ht]
\begin{algorithmic}[1]
\caption{Single vertex processing}
\label{processVertex}

\Function{processVertex}{$v$}
  \State{\Call{makeReductions}{$v$}}
  \State{\Call{push}{$v$}}
  \State{\Call{applyPassingReductions}{$v$}}
\EndFunction

\Function{push}{$innerGraphV$}
  \State{$\mathcal{U} \gets$ copy $innerGraphV.unprocessed$}
  \State{clear $innerGraphV.unprocessed$}
  \ForAll{$v_{h}$ in $\mathcal{U}$}  
    \ForAll{edge $e$ in outgoing edges of $innerGraphV$}
      \State{$push \gets$ calculate next state by $v_{h}.state$ and the token on $e$}
      \State{\Call{addEdge}{$v_{h}, e.Target, push, false$}}
      \State{add $v_{h}$ in $innerGraphV.processed$}
    \EndFor
  \EndFor
\EndFunction

\Function{makeReductions}{$innerGraphV$}
  \While{$innerGraphV.reductions$ is not empty}
    \State{$(startV, N, l) \gets innerGraphV.reductions.Dequeue()$}
    \State{find the set of vertices $\mathcal{X}$ reachable from $startV$ along the path of length ($l-1$), or $0$ if $l=0$; add $(startV, N, l-i)$ in $v.passingReductions$ where v is an i-th vertex of the path}
    \ForAll{$v_{h}$ in $\mathcal{X}$}
      \State{$state_{t} \gets$ calculate new state by $v_{h}.state$ and nonterminal $N$}
      \State{\Call{addEdge}{$v_{h}, startV, state_{t}, (l=0)$}}
    \EndFor
  \EndWhile
\EndFunction

\Function{applyPassingReductions}{$innerGraphV$}
  \ForAll{$(v, edge)$ in $innerGraphV.passingReductionsToHandle$}
    \ForAll{$(startV, N, l) \gets v.passingReductions.Dequeue()$}
      \State{find the set of vertices $\mathcal{X}$ reachable from $edge$ along the path of length ($l-1$)}
      \ForAll{$v_{h}$ in $\mathcal{X}$}
        \State{$state_{t} \gets$ calculate new state by $v_{h}.state$ and nonterminal $N$}
        \State{\Call{addEdge}{$v_{h}, startV, state_{t}, false$}}
      \EndFor
    \EndFor
  \EndFor
\EndFunction

\end{algorithmic}
\end{algorithm}

\begin{algorithm}[!ht]
\begin{algorithmic}[1]
\caption{Construction of GSS}
\label{gss_construction}
\Function{addVertex}{$innerGraphV, state$}
  \If{$innerGraphV.processed$ or $innerGraphV.unprocessed$ contains vertex $v$ which state = $state$ }
    \State{\Return{($v, false$)}}
  \Else
    \State{$v \gets$ create new vertex for $innerGraphV$ with state $state$}
    \State{add $v$ in $innerGraphV.unprocessed$}
    \ForAll{$e$ in outgoing edges of $innerGraphV$}
      \State{calculate the set of zero-reductions by $v$ and the token on $e$ and add them in $innerGraphV.reductions$}
    \EndFor
    \State{\Return{$(v, true$)}}
  \EndIf
\EndFunction

\Function{addEdge}{$v_{h}, innerGraphV, state_{t}, isZeroReduction$}
  \State{$(v_{t}, isNew) \gets$ \Call{addVertex}{$innerGraphV, state_{t}$}}
  \If{GSS does not contain edge from $v_{t}$ to $v_{h}$}
    \State{$edge \gets$ create new edge from $v_{t}$ to $v_{h}$}
    \State{$Q.Enqueue(innerGraphV)$}
    \If{not $isNew$ and $v_{t}.passingReductions.Count>0$}
      \State{add $(v_{t}, edge)$ in $innerGraphV.passingReductionsToHandle$}
    \EndIf
    \If{not $isZeroReduction$}
      \ForAll{$e$ in outgoing edges of $innerGraphV$}
        \State{calculate the set of reductions by $v$ and the token on $e$ and add them in $innerGraphV.reductions$}
      \EndFor
    \EndIf
  \EndIf
\EndFunction
\end{algorithmic}
\end{algorithm}


\section{Proof of Correctness}

\section{Construction of Parse Forest Finite Representation}
The forest of parse trees can have infinite size in case of infinite number of paths in 
the input graph, so some finite representation could be helpful for practical use. 
It is natural to use Shared Packed Parse Forest (SPPF) presented by Rekers~\cite{SPPF}
as such representation. SPPF is a directed graph which merge the nodes of 
derivation trees. 

\section{Discussion}

Presented algorifm notify about errors in input automata only if $L_a \bigcup L_r = \emptyset$. There are two possible ways to solve this problem.
We can previously check correctness and report all errors and then apply our algorithm for forect construction of correct subset.
The other way is modification of our algorithm such way that for input regular set it returns forest for all correct sentences in $L_a$ 
and notify about incorrect sentences if they exist.

Full theoretical estimation of string-embedded languages parsing complexity in depends on input is not provided 
in known works, so it is open question for future reserach.

Described algorithm produce SPPF which utilizes for trees extraction and sematic calculation in original RNGLR. Semantic actions may be smecified by using attributed grammar.
Semantic procssing and transformations for string-embedded languages may be useful, for examplr, for migration to more principal aproaches of dynamic code generattion, as proposrd in~\cite{EvalToStaged}.
We also can use this approac to specify semantic, but unfortunately in our case SPPF contains cycles which cannot be elaminated, so termination 
and correctness of semantic calcualtion and transformation is topic for research. 

% Context-free approximation processing?
% Implementation in IDE?  


%
% ---- Bibliography ----
%
\begin{thebibliography}{}
%
\bibitem{Stranger}
Fang Yu, Muath Alkhalaf, Tevfik Bultan, Oscar H. Ibarra.
Automata-based Symbolic String Analysis for Vulnerability Detection //
Formal Methods in System Design, Vol.~44, \textnumero~1, 2014, P.~44--70.

\bibitem{JSA}
Aske Simon Christensen, Anders M{\o}ller, Michael I. Schwartzbach.
Precise Analysis of String Expressions //
Proceedings of the 10th International Conference on Static Analysis, 2003, P.~1--18.

\bibitem{Alvor}
Aivar Annamaa, Andrey Breslav, Jevgeni Kabanov, Varmo Vene.
An Interactive Tool for Analyzing Embedded SQL Queries //
Proceedings of the 8th Asian Conference on Programming Languages and Systems, 2010, P.~131--138.

\bibitem{RNGLR}
Elizabeth Scott, Adrian Johnstone.
Right Nulled GLR Parsers // ACM Trans. Program. Lang. Syst., Vol.~28, \textnumero~4,
2006, P.~577--618.

\bibitem{SPPF}
Jan Rekers.
Parser Generation for Interactive Environments. PhD Thesis. Universty of Amsterdam, 1992, 174~p.

\bibitem{LangInclusion}
Peter R. J. Asveld, Anton Nijholt.
The Inclusion Problem for Some Subclasses of Context-free Languages //
Theoretical Computer Science, Vol.~230, \textnumero~1-2, 1999, P.~247--256.

\bibitem{SELinIDE}
Semen Grigorev, Ekaterina Verbitskaia, Andrey Ivanov, Marina Polubelova, Ekaterina Mavchun.
String-embedded Language Support in Integrated Development Environment //
Proceedings of the 10th Central and Eastern European Software Engineering Conference in Russia, 2014, P.~21:1--21:11.

\bibitem{MohriNederhof}
Mehryar Mohri, Mark-jan Nederhof.
Regular Approximation of Context-Free Grammars Through Transformation //
Robustness in Language and Speech Technology, Kluwer Academic Publishers, 2001, P.~153--163. 

\bibitem{AbstractLALR}
Kyung-Goo Doh, Hyunha Kim, David A. Schmidt.
Abstract LR-parsing // Formal Modeling, Springer-Verlag, 2001, P.~90--109.

\bibitem{AbstractLALRHTML}
Hyunha Kim, Kyung-Goo Doh, David A. Schmidt.
Static Validation of Dynamically Generated HTML Documents Based on Abstract Parsing and Semantic Processing //
Proceedings of the 20th International Symposium on Static Analysis, 2013, P.~194--214.

\bibitem{EvalToStaged}
Martin Lester, Luke Ong, Max Sch{\"{a}}fer.
Information Flow Analysis for a Dynamically Typed Language with Staged Metaprogramming //
Proceedings of the 26th Computer Security Foundations Symposium, 2013, P.~209--223.

\bibitem{DSQLISO}
ISO. ISO/IEC 9075:1992. Information Technology~--- Database Languages~--- SQL, 1992.

\bibitem{JSP}
Damon Houglan, Aaron Tavistock. Core JSP // Prentice Hall PTR, Upper Saddle River, NJ, USA, 2000, 416~p.

\end{thebibliography}
\end{document}

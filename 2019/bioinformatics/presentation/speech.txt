1. Hi, my name is Semyon, I'm from the saint Petersburg state university. I want to talk about
2.
3. Classical way is to use probabilistic grammar for secondary structure modelling. We propose to use parser only for features extraction. Namely, we use ordinary, not probabilistic, grammar for features description. Then we use parser for features extraction. After that we use artificial neural network for extracted features processing.
4. Let discuss structure of our solution in more details. The input consists of two parts. The first is a grammar which should not be context-free. We can use more expressive classes of grammars. We only need to have ability to represent parsing result as a set of matrices. The second part is a sequence to be processed.

 These two parts is input for parser. Our implementation is based on Okhotin's algorithm which reduce parsing to matrices multiplication. As a result we can utilize GPGPUs for parsing.

 Result of parsing is a set of boolean matrices: one matrix for each nonterminal. Each matrix represents information about all substrings which is derivable from the given nonterminal. In practice we use only matrix for start nonterminal. If cell i,j contains 1 then substring from i to j derivable from the start nonterminal.

 The input for neural network is a vector of features, so we should vectorize out matrices. We use simple line-by-line vectorization. As far as bottom left triangle is always filled by zeros, we skip it. For long sequences we also compress vectors to decrease network size. We just treat sequences of bits as byte. It is technical trick because most libraries for neural networks can not handle bit vectors, but can handle byte vectors.

 Well. Now we are ready to run dense neural network. At the current state it is classical dense network with agressive dropout and batch normalization. It is necessary for learning stabilization.

Finally we get some results which are depend on problem which we try to solve.

5. Let discuss some parts in more carefully. Firs part is grammar. In our case it is context-free grammar. S-one is a start nonterminal --- it is our point of interest.
This grammar contains two rules which describe arbitrary string of length from 2 up to 10, and arbitrary symbol, respectively.
6.
7.
8.
9.
10.
11.
12.
13.
14.
15.
16.
17.

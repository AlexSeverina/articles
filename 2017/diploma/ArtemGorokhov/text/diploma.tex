% Тут используется класс, установленный на сервере Papeeria. На случай, если
% текст понадобится редактировать где-то в другом месте, рядом лежит файл matmex-diploma-custom.cls
% который в момент своего создания был идентичен классу, установленному на сервере.
% Для того, чтобы им воспользоваться, замените matmex-diploma на matmex-diploma-custom
% Если вы работаете исключительно в Papeeria то мы настоятельно рекомендуем пользоваться
% классом matmex-diploma, поскольку он будет автоматически обновляться по мере внесения корректив
%

% По умолчанию используется шрифт 14 размера. Если нужен 12-й шрифт, уберите опцию [14pt]
\documentclass[14pt]{matmex-diploma-custom}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[caption=false]{subfig}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.9}
\usepackage{multirow}

\usepackage{url}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{algorithmicx}
%\documentclass[14pt]{matmex-diploma-custom}
\hyphenation{Ge-ne-ra-lised}
\newtheorem{mydef}{Определение}

\begin{document}
	\algnewcommand\algorithmicswitch{\textbf{switch}}
	\algnewcommand\algorithmiccase{\textbf{case}}
	\algnewcommand\algorithmicassert{\texttt{assert}}
	\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}
	% New "environments"
	\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}
	\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}
	
	\algtext*{EndSwitch}
	\algtext*{EndCase}
	\algtext*{EndWhile}% Remove "end while" text
	\algtext*{EndIf}% Remove "end if" text
	\algtext*{EndFor}% Remove "end for" text
	\algtext*{EndFunction}% Remove "end function" text
	
	% Год, город, название университета и факультета предопределены,
	% но можно и поменять.
	% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
	\filltitle{ru}{
		chair              = {Программная инженерия},
		title              = {Поддержка расширенных контекстно-свободных грамматик 
			в алгоритме синтаксического анализа Generalised LL},
		type               = {bachelor},
		position           = {студента},
		group              = 471,
		author             = {Горохов Артем Владимирович},
		supervisorPosition = {к.\,ф.\,-м.\,н.,\,доц.},
		supervisor         = {Григорьев С.\,В.},
		reviewerPosition   = {СУИ НИУ ИТМО, программист},
		reviewer           = {Авдюхин Д.А.}
	}
	
	\filltitle{en}{
		chair              = {Software engineering},
		title              = {Support of extended context-free grammars in Generalised LL parsing algorithm},
		author             = {Artem Gorokhov},
		supervisorPosition = {associate professor},
		supervisor         = {Semyon Grigorev},
		reviewerPosition   = {ITMO University, programmer},
		reviewer           = {Dmitry Avduhin}
	}
	\maketitle
	%\setcounter{tocdepth}{1}
	\tableofcontents
	% У введения нет номера главы
	\section*{Введение}
	
	Общеупотребимый способ описания синтаксиса языков программирования ---
	расширенные контекстно-свободные грамматики. Например спецификации языков 
	$C$, $C++$, $Java$ и т.д. С одной стороны, эта форма проста для понимания людей, 
	а с другой, достаточно формальна и допускает автоматизированное создание 
	синтаксических анализаторов.
	
	Существуют различные инструменты для создания синтаксических анализаторов, которые 
	по входной грамматике позволяют создать инструментальное средство для синтаксической 
	обработки текстов, созданных на этом языке. Проблема заключается в том, что эти инструменты
	сначала преобразуют грамматику к контекстно-свободной форме, и только по ней 
	строят синтаксический анализатор.
	
	Есть работы, которые описывают синтаксический анализ с помощью расширенных
	контекстно-свободных грамматик(extended context-free grammar (ECFG)).
	Hо нет инструментов, основанных на данных работах. Кроме того, подходы, описанные
	в данных исследованиях, поддерживают лишь подклассы контекстно-свободных языков.
	
	Алгоритмы обобщённого синтаксического анализа, например Genera-lised LL~\cite{scott2010gll}, 
	способны использовать контекстно-свободные грамматики описывающие произвольные 
	контекстно-свободные языки. Но они так же не работают с грамматиками в форме EBNF 
	без предварительного преобразования к контекстно-свободной форме.
	
	В биоинформатике стоит задача поиска генов и иных последовательностей в геномах. 
	Эти последовательности имеют некоторые общие свойства, которые можно описать 
	контекстно-свободной грамматикой. Есть инструменты типа infernal~\cite{Infernal}, которые 
	используют синтаксический анализ для поиска структур в геномах. Но не всегда 
	генетический материал образует обычную последовательность. Метагеномные сборки - 
	результат считывания генов нескольких организмов, представленный в виде графа, пути 
	в котором задают гены этих организмов. Было бы здорово применить полученный GLL алгоритм для
	синтаксического анализа метагеномных сборок.
	
	На нашей кафедре, в рамках исследовательского проекта YaccConstructor~\cite{YaccConstructor},
	разрабатывается подход поиска структур заданных с помощью контекстно-свободной
	грамматики в метагеномных сборках, основанный на алгоритме Generalised LL.
	Предполагается, что синтаксический анализ по ECFG без преобразований даст ощутимый
	прирост производительности существующего подхода.
	
	\section{Постановка задачи}
	
	Целью данной работы является разработка модификации алгоритма GLL работающей с 
	грамматиками в расширенной форме Бэкуса-Наура и проверка того, как полученный 
	алгоритм влияет на производительность поиска структур заданных с помощью 
	контекстно-свободной грамматики в метагеномных сборках. Для её достижения были 
	поставлены следующие задачи.
	
	\begin{itemize}  
		\item Выбрать или разработать подходящее представление ECFG.
		\item Спроектировать структуру данных для представления леса разбора по ECFG.
		\item Разработать алгоритм на основе Generalised LL, строящий лес разбора по ECFG.
		\item Реализовать алгоритм в рамках проекта YaccConstructor.
		\item Провести эксперименты и сравнение.
	\end{itemize}
	
	\section{Обзор}
	
	\subsection{Расширенные контекстно-свободные грамматики}
	Статический анализ программ oбычно выполняется над структурным представлением кода. 
	И синтаксический анализ - это классический способ получить такое представление. Генераторы 
    синтаксических анализаторов часто используются для автоматизации создания анализатора: 
    эти инструменты получают синтаксический анализатор по грамматике.
	
	Расширенная форма Бэкуса-Наура(EBNF)~\cite{EBNFISO} является метасинтаксисом для представления 
	контекстно-свободных грамматик. В дополнение к конструкциям используемым в форме
	Бэкуса-Наура, в ней используется следующие конструкции: альтернатива |,
	необязательные символы [\dots], повторение \{\dots\} и группировка (\dots).
	
	Эта форма широко используется для спецификации грамматики в технической документации
	ввиду того, что выразительная сила EBNF делает спецификацию синтаксиса более компактной
	и удобочитаемой. Поскольку документация является одним из основных источников информации
	о языке для разработчиков синтаксических анализаторов, было бы полезно иметь генератор
	анализаторов, который поддерживает грамматики в EBNF. Заметим, что EBNF является 
	лишь стандартизированной формой для \textit{расширенных контекстно-свободных грамматик}
	~\cite{ECFG}, которые могут быть определены следующим образом:
	
	\begin{mydef}
		Расширенная контекстно-свободная грамматика (ECFG) ~\cite{ECFG} --- это кортеж $(N, \Sigma, P, S)$,
		где N и $\Sigma$ конечные множества нетерминалов и терминалов cоответственно, 
		$S\in N$ является стартовым символом, а P (продукция) является отображением из N в
		регулярное выражение над алфавитом $N \cup \Sigma$.
		
	\end{mydef}
	ECFG широко используется в качестве входного формата для генераторов синтаксических анализаторов, 
	но классические алгоритмы синтаксического анализа часто требуют CFG, и, 
	как результат, генераторы анализаторов требуют преобразования в CFG. 
	Возможно преобразование ECFG в CFG \cite{ELL}, но это преобразование приводит к увеличению
	размера грамматики и изменению её структуры: при трансформации добавляются новые
	нетерминалы. В результате синтаксический анализатор строит дерево вывода относительно
	преобразованной грамматики, и разработчику языка сложнее отлаживать грамматику 
	и использовать результат синтаксического анализа. Кроме того, увеличение размера грамматики 
    отрицательно сказывается на производительности синтаксического анализа.
    
	Существует широкий спектр методов анализа и алгоритмов~\cite{AttributedELL,ELRR,
		ECFGparsing,ELLParser,ELL,ECFG,ELALR,ELRParsing}, которые способны обрабатывать 
	грамматику в ECFG. Детальный обзор результатов и задач в области обработки ECFG 
	представлены в статье ``Towards a Taxonomy for ECFG and RRPG Parsing''~\cite{ECFG}.
	Заметим только, что большинство алгоритмов основаны на классических методах
	LL~\cite{ELLParser,AttributedELL,PredictiveECFG} и LR~\cite{ELRParsing,ELALR,ELRR},
	но они работают только с ограниченными подклассами ECFG. Таким образом, нет решения 
	для обработки произвольных (в том числе неоднозначных) ECFG.
	
	Алгоритмы синтаксического анализа на основе LL более интуитивны, чем основанные на LR, и могут
	обеспечить лучшую диагностику ошибок. В настоящее время LL(1) представляется
	наиболее практичным алгоритмом. К сожалению, некоторые языки не являются LL(k) (для любого k),
	и леворекурсивные грамматики --- проблема для инструментов на основе LL. 
	Другим ограничением для LL анализаторов являются неоднозначности в грамматике, 
	которые, вместе с предыдущими недостатками, усложняют создание синтаксических 
	анализаторов. Алгоритм Generalised LL, предложенный в~\cite{scott2010gll}, решает 
	все эти проблемы: он обрабатывает произвольные CFG, в том числе неоднозначные и
	леворекурсивные.
	В худшем случае временная и пространственная сложность GLL зависит кубически от 
	размера входа. А для LL(1) грамматик, он демонстрирует линейную временную и
	пространственную сложность.
    
    Чтобы увеличить производительность Generalised LL алгорима, его авторы Elizabeth Scott 
    и Adrian Johnstone предложили поддержку лево-факторизованных грамматик в этом алгоритме~\cite{scott2016structuring}.
    Из описания GLL алгоритма ясно, что для уменьшения времени анализа и количества используемой памяти
    можно снизить количество дескрипторов для обработки. Один из путей для достижения этого --- 
    уменьшение размера грамматики(снижение количества различных позиций в ней).
    Этого можно достичь факторизацией грамматики. Пример факторизации показан на рис.~\ref{fig:ExampleOfFactorization}:
    из грамматики $G_0$ в процессе факторизации получается грамматика $G_0'$.
    Этот пример рассмотрен в работе~\cite{scott2016structuring}, и показано, что для некоторых грамматик факторизация 
    существенно увеличивает производительность алгоритма GLL.
    \begin{figure}
        \centering
        \subfloat[Исходная грамматика $G_0$]{
            $
            \begin{array}{rl}
            S::= a\ a\ b\ c\ d \ | \ a\ a\ c\ d \ | \ a\ a\ c\ e |\ a\ a
            \end{array}
            $
        }
        ~
        \subfloat[Факторизованная грамматика $G_0'$]{
            $
            \begin{array}{rl}
            S::= a\ a\ ( b\ c\ d\ |\ c\ ( d\ |\ e )\ |\ \varepsilon \ )
            \end{array}
            $
        }
        \caption{Пример факторизации грамматики}
        \label{fig:ExampleOfFactorization}
    \end{figure}
    В данной работе эта идея развита в поддержку расширенных контекстно-свободных грамматик.
	
	\subsection{Структурированный в виде графа стек}
	В процессе синтаксического анализа используется стек, позволяющий отслежвать историю 
	разбора нетерминалов. Но грамматика может быть неоднозначной и для каждого варианта 
    разбора плодится новый стек, который в дальнейшем поддерживается.
    Но такие стеки не эффективно хранить и использовать, так как они имеют довольно много
    одинаковых узлов. Поэтому был предложен структурированный в виде графа стек
    (Graph Structured Stack(GSS)). GSS комбинирует в себе все варианты стеков.
    
    Анастасия Рагозина в своей работе использует стек предложенный в работе~\cite{afroozeh2015faster}.
    В его узлах хранятся нетерминалы и начальные позиции их разбора во входе.
    На рёбрах, исходящих из узла с меткой $(A, i)$, хранятся позиции в грамматике с которых нужно
    продолжать разбор после разбора нетерминала A, а так же корень построенного SPPF до начала 
    разбора нетерминала A.
    
	\subsection{Сжатое представление леса разбора}
	Результатом работы синтаксического анализатора является структурное представление
    входа: дерево разбора. Если возможно несколько выводов входа, строится несколько деревьев:
    для каждого варианта разбора. Например для грамматики $G_0$~\ref{fig:fig0} и входа $ссс$
    будут построены 2 дерева, показанные на рис.~\ref{fig:Gtrees}.
    
    Для некоторых грамматик количество деревьев может экспоненциально зависеть от размера входа.
    Чтобы снизить расходы для хранения и обработки всех деревьев, используется структура данных
    Shared Packed Parse Forest(SPPF). 
    Будем использовать бинаризованную версию SPPF, предложенную в~\cite{brnglr}, для уменьшения
    потребления памяти и достижения кубической наихудшей временной и пространственной сложности.
    Бинаризованный SPPF может использоваться в GLL~\cite{scott2013gll} и содержит следующие типы узлов.
    ($i$ и $j$ --- начало и конец выведенной подстроки для данного узла) 
    \begin{itemize}
        \item Упакованные узлы вида $(M, k)$, где $M$ --- позиция в грамматике, k --- начало выведенной
        подстроки правого ребёнка. У упакованных узлов обязательно есть правый ребёнок ---
        символьный узел, и опциональный левый --- символьный или промежуточный узел.
        \item Символьный узел помечен $(X, i, j)$ где $X$ --- терминал или нетерминал.
        Терминальные символьные узлы --- листья. 
        Нетерминальные символьные узлы могут иметь несколько упакованных детей. 
        \item Промежуточные узлы помечены $ (M, i, j) $, где $M$ --- позиция в грамматике, 
        могут иметь несколько упакованных детей, каждый из которых представляет различные варианты разбора.
    \end{itemize}
    Дети символьных и промежуточных узлов --- упакованные. Различные упакованные дети --- различные варианты поддеревьев.
    То есть если у узла или его потомков есть более одного упакованного ребёнка, то для него есть несколько вариантов 
    разбора для строки. Промежуточные и упакованные узлы необходимы для бинаризиции SPPF
    Так, деревья, представленные на рис.~\ref{fig:Gtrees}, объединяются в SPPF показанный на рис.~\ref{fig:GSPPF}.
    \begin{figure}
        \centering
        $
        \begin{array}[b]{rl}
        S ::= S\ S\ | \ c \ \ \ 
        \end{array}
        $
        \caption{Грамматика $G_0$}
        \label{fig:fig0}
    \end{figure}
    \begin{figure}[ht]   
        \centering
        \subfloat[Возможные деревья вывода]{
            \includegraphics[scale=.6]{pictures/Gtrees.pdf}
            \label{fig:Gtrees}
        }
        ~
        \subfloat[SPPF]{
            \includegraphics[scale=.6]{pictures/GSPPF.pdf}
            \label{fig:GSPPF}
        }
        \caption{Пример для входа $ ccc $ и грамматики $G_0$}
        \label{fig:fig01}
    \end{figure}
    \subsection{Алгоритм Generalised LL}
	
	Цель обобщенных алгоритмов синтаксического анализа - обеспечить создание синтаксических
	анализаторов по произвольным контекстно-свободным грамматикам.
	Алгоритм Generalised LL~(GLL)~\cite{scott2010gll} включает в себя свойства классических LL алгоритмов:
	он более интуитивен и обеспечивает более хорошую диагностику ошибок, 
	чем обобщенные LR алгоритмы. Кроме того, опыт показывает, что решения на основе
	GLR более сложны, чем основанные на GLL, что согласуется с наблюдением в [11], что
	синтаксические анализаторы ECFG на основе LR очень сложны. Таким образом, в качестве
	основы для решения был выбран GLL алгоритм. 
	
	Идея алгоритма GLL основана на обработке так называемых дескрипторов, которые 
	могут однозначно определить состояние процесса синтаксического анализа. Дескриптор
	представляет собой кортеж $(L, i, T, S)$, где:
	\begin{itemize}
		\item $L$ указатель на позицию в грамматике вида~$(S \to \alpha \cdot \beta)$;
		\item $i$ --- позиция во входе;
		\item $T$ --- корень построенного леса разбора;
		\item $S$ --- текущий узел стека~(GSS)~\cite{afroozeh2015faster}.
	\end{itemize}
	
	GLL двигается одновременно по входу и грамматике, создавая множество дескрипторов
	в случае неоднозначности и использует очередь для управления обработкой дескрипторов.
	В начальном состоянии есть только один дескриптор, который состоит из начальной 
	позиции в грамматике~$(S \to \cdot \beta)$, во входе (i = 0), фиктивного узла дерева (\$)
	и дна стека. На каждом шаге алгоритм извлекает дескриптор из очереди и действует
	в зависимости от грамматики и входа. Если есть неоднозначность, то алгоритм помещает
	в очередь дескрипторы для всех возможных случаев, чтобы обработать их позже. 
	Для достижения кубической временной сложности важно помещать в очередь только дескрипторы,
	которые не создавались ранее. Для того чтобы решить добавлять дескриптор или нет
	используется глобальное хранилище всех созданных дескрипторов.
	Существует подход на основе таблиц~\cite{ragozina} для реализации GLL, который генерирует
	только таблицы для данной грамматики вместо полного кода синтаксического анализатора.
	Эта идея похожа на алгоритм в оригинальной статье и использует те же техники
	построения леса разбора и обработки стека. Псевдокод, иллюстрирующий этот подход, 
	можно найти в приложении. Обратите внимание, что в приложении и далее в псевдокод не включена
	проверка для множеств first/follow.
	
	\subsection{Проект YaccConstructor}
    YaccConstructor --- исследовательский проект кафедры системного программирования и лаборатории
    языковых инструментов JetBrains. Проект направлен на изучение алгоритмов синтаксического и 
    лексического анализа и занимается разработкой инструмента YaccConstructor, предоставляющего платформу для
    создания и изучения новых алгоритмов. Инструмент имеет модульную архитектуру и включает в себя язык описания 
    грамматик Yard, который поддерживает расширенные контекстно-свободные грамматики. Кроме того в инструменте 
    реализован генератор синтаксических анализаторов на основе Generalised LL алгоритма.
    Инструмент разработан на платформе $.NET$, на языке программирования $F\#$.
	
	\subsection{Анализ метагеномных сборок}
	
    Биоинформатика включает в себя множество задач, решения которых необходимы в биологических исследованиях.
    Одна из них --- задача поиска организмов в биологическом материале.
    В результате эксперимента получают последовательности генов --- строки над алфавитом $\{A;C; G; T\}$.
    Извлечённые из материала последовательности объединяются в граф, пути в котором задают полученные 
    гены. Этот граф и есть метагеномная сборка.
    
    Известный подход для поиска организмов в метагеномной сборке это выделение участков соответствующих структурам
    тРНК, 16s рРНК и др. У этих структур есть некоторые общие свойства, которые могут быть описаны контекстно-свободной грамматикой.
    Таким образом, можно использовать алгоритмы синтаксического анализа для поиска структур.
	В работе~\cite{ragozina} был предложен подход к анализу метагеномных
	сборок с помощью алгоритма GLL. Этот подход был реализован в рамках проекта YaccConstructor.
    В этой работе будет использоваться эта реализация.
	
	\section{Представление ECFG}
	
	Чтобы облегчить задание грамматики в форме ECFG для синтаксического анализатора
	будем использовать рекурсивный автомат (Recursive Automaton (RA)~\cite{tellier2006learning}
	для представления ECFG. Будем использовать следующее определение RA.
	\begin{mydef}
		Рекурсивный автомат $R$ это кортеж $(\Sigma, Q, S, F, \delta)$, где $\Sigma$
		--- конечное множество терминалов, $Q$ - конечное множество состояний, $S \in Q$ 
		--- начальное состояние, $F \subseteq Q$ --- множество конечных состояний,
		$\delta : Q \times (\Sigma \cup Q) \to Q$ --- функция перехода.
	\end{mydef}
	В рамках этой работы единственное различие между рекурсивным автоматом и общеизвестным
	конечным автоматом (FSA) состоит в том, что переходы в RA обозначаются либо терминалом ($\Sigma$),
	либо состоянием автомата ($Q$). Далее в этой работе будем называть переходы по элементам из
	$Q$ \textit{нетерминальными переходами}, а по терминалам --- \textit{терминальными переходами}.
    Переход по нетерминалу в состояние $q$ подразумевают построение вывода для некоторой подстроки начиная с текущей позиции
    вывода по этому нетерминалу и последующий разбор оставшейся подстроки начиная с состояния $q$.
     
	Заметим, что позиции грамматики эквивалентны состояниям автомата, которые 
	строятся из правых частей продукций. Правые части продукций ECFG являются регулярными
	выражениями над объединенным алфавитом терминалов и нетерминалов. Итак, наша цель ---
	построить RA с минимальным числом состояний для заданной ECFG, что можно сделать следующими шагами.
	\begin{itemize}
		\item Построить конечный автомат, используя метод Томпсона~\cite{Thompson:1968:PTR:363347.363387} для каждой правой
		части продукций.
		\item Создать карту из каждого нетерминала в соответствующее начальное состояние автомата.
		Эта карта должна оставаться консистентной на протяжение всех следующих шагов.
		\item Преобразовать автоматы из предыдущего шага в детерминированные без 
		$\varepsilon$-переходов используя алгоритм, описанный в~\cite{aho1974design}.
		\item Минимизировать детерминированный автомат, используя, например, алгоритм
		Джона Хопкрофта~\cite{hopcroft1971n}.
		\item Заменить нетерминальные переходы переходами по, стартовым состояниям автоматов,
		соответствующим данным нетерминалам, используя карту $M$. Результат 
		этого шага --- искомый рекурсивный автомат. Также используем карту $M$
		для определения функции $\Delta : Q \to N$ где $N$ --- имя нетерминала.
	\end{itemize}
	Пример преобразования ECFG в RA представлен на рис.~\ref{fig:fig1}, где состояние
	0 --- начальное состояние результирующего RA.
	\begin{figure}
		\centering
		\subfloat[Грамматика $G_1$]{
			$
			\begin{array}[b]{rl}
			S ::= a^{+} S\ b? \ | \ c \ \ \ 
			\end{array}
			$
			\label{fig:grammarG0}
		}
		~
		\subfloat[Конечный автомат для $G_1$]{
			\includegraphics[scale=.6]{pictures/G0initialAutomaton.pdf}
			\label{fig:initialAutomatonsForG0}
		}
		~
		\subfloat[Рекурсивный автомат $R_1$ для $G_1$]{
			\includegraphics[scale=.6]{pictures/G0minimizedAutomaton.pdf}
			\label{fig:RAForG0}
		}
		\caption{Преобразование грамматики в рекурсивный автомат}
		\label{fig:fig1}
	\end{figure}
	
	\section{Лес разбора по ECFG}
	Результатом процесса синтаксического анализа является структурное представление 
	входа --- дерево или лес разбора в случае нескольких вариантов деревьев.
	Для начала, определим дерево вывода для рекурсивного автомата: 
	это дерево, корень которого помечен начальным состоянием, листовые узлы помечены
	терминалом или $\varepsilon$, а внутренние узлы помечены нетерминалами N и их
	дети образуют последовательность меток в пути в автомате, который начинается в 
	состоянии $q_i$, где $ \Delta(q_i) = N $. Более формально:
	
	\begin{mydef}
		
		Дерево вывода последовательности $\alpha$ для рекурсивного автомата $R=(\Sigma, Q, S, F, \delta)$ это дерево со следующими свойствами:
		
		\begin{itemize}
			\item Корень помечен $\Delta(S)$;
			\item Листья ---теминалы $a\in (\Sigma \cup \varepsilon)$;
			\item Остальные узлы --- нетерминалы $A\in \Delta(Q)$;
			\item У узла с меткой $N_i = \Delta(q_i)$ есть:
			\begin{itemize}
				\item 
				дети $l_0 \dots l_n (l_i \in \Sigma \cup \Delta(Q))$ тогда и только тогда,
				когда существует путь $p$ в $R$, $p = q_i \xrightarrow[]{l_0} q_{i+1} \xrightarrow[]{l_1} \dots \xrightarrow{l_n} q_m$, где
				$q_m \in F$, $l_i = 
				\left\{
				\begin{matrix}
				k_i, \text{ if }  k_i \in \Sigma,\\
				\Delta(k_i), \text{ if } k_i \in Q,
				\end{matrix}
				\right.
				$
				\item только один ребенок помеченный $\varepsilon$ тогда и только тогда,
				когда $ q_i \in F $
			\end{itemize}
		\end{itemize}
	\end{mydef}
	Для произвольных грамматик RA может быть неоднозначным с точки зрения допустимых путей,
	и, как результат, можно получить несколько деревьев разбора для одной входной строки.
	Shared Packed Parse Forest (SPPF)~\cite{SPPF} может использоваться как компактное
	представление всех возможных деревьев разбора. Будем использовать бинаризованную версию SPPF,
	предложенную в~\cite{brnglr}, для уменьшения потребления памяти и достижения кубической
	наихудшей временной и пространственной сложности. Бинаризованный SPPF может использоваться
	в GLL~\cite{scott2013gll} и содержит следующие типы узлов (здесь i и j называют правый и
	левый extent --- начало и конец выведенной подстроки во входной строке):
	
	\begin{itemize}
		\item Упакованные узлы вида $(S, k)$, где $S$ состояние автомата, k --- начало выведенной
		подстроки правого ребёнка. У упакованных узлов обязательно есть правый ребёнок ---
		символьный узел, и опциональный левый --- символьный или промежуточный узел.
		\item Символьный узел помечен $(X, i, j)$ где $X \in \Sigma \cup \Delta(Q) \cup \{\varepsilon\}$.
		Терминальные символьные узлы ($X \in \Sigma \cup \{\varepsilon\}$) --- листья. 
		Нетерминвльные символьные узлы ($X \in \Delta(Q)$) могут иметь несколько упаковынных детей. 
		\item Промежуточные узлы помечены $ (S, i, j) $, где $S$ состояние в автомате, могут иметь несколько упаковынных детей.
	\end{itemize}
	
	Опишем модификации исходных функций построения SPPF.
	Функция \textbf{getNodeT$ (x, i) $}, которая создает терминальные узлы, 
	повторно используется без каких-либо модификаций из базового алгоритма.
	Чтобы обрабатывать недетерминизм в состояниях, определим функцию 
	\textbf{getNodes}, которая проверяет, является ли следующее состояние RA финальным
	и в этом случае строит нетерминальный узел в дополнение к промежуточному.
	Она использует изменённую функцию \textbf{getNodeP}: вместо позиции в грамматики он 
	принимает в качестве входных данных отдельно состояние RA и символ для нового узла SPPF:
	текущий нетерминал или следующее состояние RA.
	
	\input{./getNodes.tex}
	\input{getNodeP.tex}
	
	Рассмотрим пример SPPF для ECFG $ G_1 $~(рис.~\ref{fig:grammarG0}).
	Эта грамматика содержит конструкции (условное вхождение(?) и повторение(+)),
	которые должны быть преобразованы с использованием дополнительных нетерминалов 
	для создания обычного GLL-анализатора.
	Предложенный генератор строит рекурсивный автомат $ R_1 $ ~(рис.~\ref{fig:RAForG0})
	и анализатор по нему. Возможные деревья ввода последовательности $ aacb $ показаны 
	на рис.~\ref{fig:treesForG0}. SPPF, созданный синтаксическим анализатором~(рис.~\ref{fig:SPPFForG0}),
	содержит в себе все три дерева.
	
	\begin{figure}[ht]   
		\centering
		\subfloat[Возможные деревья вывода]{
			\includegraphics[scale=.5]{pictures/G0trees.pdf}
			\label{fig:treesForG0}
		}
		~
		\subfloat[SPPF]{
			\includegraphics[scale=.5]{pictures/G0SPPFwithPackedNodes.pdf}
			\label{fig:SPPFForG0}
		}
		\caption{Пример для входа $ aacb $ и автомата $R_1$}
		\label{fig:fig2}
	\end{figure}
	
	\section{Алгоритм построения леса разбора по ECFG}
	В этом разделе описываются изменения в управляющих функциях базового алгоритма 
	Generalised LL, необходимые для обработки ECFG. Основной цикл аналогичен базовому
	GLL: на каждом шаге основная функция \textbf{parse} извлекает из очереди дескриптор
	$R$, подлежащий обработке. Пусть текущий дескриптор -- кортеж ($C_S, C_U, i, C_N$),
	где $C_S$ --- состояние RA, $C_U$ --- узел GSS, i --- позицию во входной строке 
	$\omega$, $C_N$ --- узел SPPF. В ходе обработки дескриптора могут возникнуть следующие
	не исключающие друг друга ситуации.
	\begin{itemize} 
		\item \textbf{$C_S$ --- финальное состояние.} Это возможно только если $C_S$
		--- стартовое состоение текущего нетерминала. Следует построить нетерминальный
		узел с ребёнком $(\varepsilon, i, i)$ и вызвать функцию \textbf{pop}, так как
		разбор нетерминала окончен.
		
		\item \textbf{Существует терминальный переход $C_S \xrightarrow[]{\omega.[i]} q$.}
		Во-первых, построить терминальный узел $ t = (\omega.[i], i, i+1) $, далее 
		вызвать функцию \textbf{getNodes} чтобы построить родителя для $ C_N $ и $ t $. 
		Функция \textbf{getNodes} возвращает кортеж $ (y, N) $, где $N$ --- опциональный
		нетерминальный узел. Создать дескриптор $ (q, C_U, i+1, y) $ и, если
        в $q$ есть несколько переходов, вызвать функцию \textbf{add} для этого дескриптора.
        Иначе поместить его в очередь вне зависимости от того был ли он создан до этого. 
        Если $ N \neq \$$,
		вызвать функцию \textbf{pop} для этого узла, состояния $ q $ и позиции во
		входе $ i + 1 $.
		
		\item\textbf{ Есть нетерминальные переходы из $C_S$.}
		Это значит что следует начать разбор нового нетерминала, поэтому должен быть
		создан новый узел GSS, если такового ещё нет. Для этого нужно вызвать функцию
		\textbf{create} для каждого такого перехода. Она осуществляет необходимые
		операции с GSS и проверяет наличие узла GSS для текущих нетерминала и 
		позиции во входе.
	\end{itemize}
	Псевдокод для необходимых функций представлен ниже:
	
	Функция \textbf{add} помещает в очередь дескриптор, если он не был создан до этого; эта функция не изменилась.
	\input{create.tex}
	
	\input{pop.tex}
	
	%\textbf{Pop} function is called when we reach final state. It queues descriptors for all outgoing edges from current GSS node.
	
	\input{parse.tex}
	
	\section{Реализация}
    
    Описанный алгоритм реализован в проекте YaccConstructor. 
    %Архитектура проекта показана на рис.~\ref{}. 
    На вход генератору поступает структурное представление грамматики, на основе которого 
    генератор создаёт управляющие таблицы. Далее они и входные данные поступают на вход
    синтаксическому анализатору, который строит SPPF. 
    
    В проекте уже был реализован генератор анализаторов и интерпретатор
    на основе алгоритма GLL, они были заменены предложенными в этой работе с сохранением остальной инфраструктуры.

    Чтобы осуществить поддержку графов в качестве входных данных было предложено использовать абстракцию над входом.
    Абстракции передаётся функция, вызываемая для всех следующих символов во входе. Так, работа алгоритма не зависит
    от особенностей реализации входной структуры данных. Проблема в том, что алгоритм не поддерживает
    циклы во входных графах в полной мере. Например, для грамматики $S ::= a*$ и входного графа на рис.~\ref{graphEx}
    Алгоритм просто не остановится, так как будет постоянно обрабатывать один и тот же дескриптор.
    Этого можно избежать, если для обработки терминалов не просто добавлять дескрипторы в очередь, а вызывать функцию \textbf{add}.
    Это не изменит теоретическую сложность алгоритма, но понятно, что на деле может сказаться на производительности в худшую сторону.
    Так, перед синтаксическим анализом можно проверять входной граф на наличие циклов и в случае их присутствия
    использовать решение описанное выше.
    \begin{figure}[ht]   
        \centering
        \includegraphics[scale=.5]{pictures/graphEx.pdf}
        \caption{Пример входа для грамматики $S ::= a^*$ на котором алгоритм не остановится.}
        \label{graphEx}
    \end{figure}
    
	\section{Эксперименты}
    Реализация описанного алгоритма GLL была сравнена с реализованным анализатором для факторизованных грамматик 
    Были сравнены собственная реализация анализатора для факторизованных грамматик и реализация алгоритма описанного в этой работе.
    Была использована грамматика $G_2$~(рис.~\ref{fig:grammarG1}), так так она содержит длинные последовательности 
    в альтернативах, которые не сливаются при факторизации. Рекурсивный автомат построенный для этой грамматике 
    показан на рис.~\ref{fig:automatonForG1}.
    
    \begin{figure}[ht]   
        \centering
        \subfloat[Грамматика $G_2$]{
            $
            \begin{array}{rl}
            S ::=& K\ (K\ K\ K\ K\ K \ |\ a\ K\ K\ K\ K) \\
            K ::=& S\ K\ |\ a\ K\ |\ a \\
            \end{array}
            $
            \label{fig:grammarG1}
        }
        
        \subfloat[RA для грамматики $G_2$]{
            \includegraphics[scale=.5]{pictures/G1automaton.pdf}
            \label{fig:automatonForG1}
        }
        \caption{Грамматика $G_2$ и RA для неё}
    \end{figure}
    
    Для этой грамматика синтаксический анализатор построенный по рекурсивному автомату создаёт меньше узлов GSS, так как 
    цепочки нетерминалов $K$ представлены единственным путём в RA. Эта особенность ведёт к снижению количества 
    узлов SPPF и дескрипторов.
    
    Эксперименты проводились на входах различной длины, результаты приведены на рис.~\ref{expPlots}.
    Точные данные для входа $a^{450}$ показаны в таблице~\ref{expTable}.
    
    Была выбрана очень неоднозначная грамматика чтобы показать разницу между подходами на коротких входах,
    по этой причине время анализа столь велико.
    
    Тесты проводились на ПК со следующими характеристиками:
    \begin{itemize}
        \item OS: Microsoft Windows 10 Pro x64
        \item CPU: Intel(R) Core(TM) i7-4790 CPU @ 3.60GHz, 3601 Mhz, 4 Cores, 4 Logical Processors
        \item RAM: 16 GB
    \end{itemize}
    
    \begin{table}[ht]   
        \begin{center}
            \begin{tabular}{ | c | c | c | c | c | c | c |  }
                \hline
                & \rotatebox[origin=c]{90}{Время}
                & \rotatebox[origin=c]{90}{Дескрипторы} &
                 \rotatebox[origin=c]{90}{Рёбра GSS} &
                  \rotatebox[origin=c]{90}{Узлы GSS} &
                  \rotatebox[origin=c]{90}{Узлы SPPF} &
                  \rotatebox[origin=c]{90}{Память, Мб} \\ \hline
                Фактор-ая &&&&&&\\ грамматика & 10 мин. 13 с.  & 1104116        & 1004882      & 902        & 195 млн. &  11818 \\ \hline 
                RA       & 5 мин. 51 с.  & 803281        & 603472      & 902        & 120 млн. & 8026  \\ \hline \hline
                Ratio   &  43$\%$       & 28$\%$     & 40 $\%$    &  0 $\%$ &  39 $\%$ &  33 $\%$ \\ \hline
            \end{tabular}
        \end{center}
        \caption{Результаты экспериментов для входа $a^{450}$}
        \label{expTable}
    \end{table}
    
    
    
    Результаты данных экспериментов поддерживают предположение о том, что на некоторых грамматиках 
    описанный подход показывает результаты лучше, нежели анализатор построенный по факторизованным грамматикам.
    В среднем, с грамматикой $G_2$ версия с минимизированными автоматами работает на $43\%$ быстрее,
    использует на $28\%$ меньше дескрипторов, на $40\%$ меньше рёбер GSS, создаёт на $39\%$ меньше узлов SPPF
    и использует на $33\%$ меньше памяти.
    
    Кроме того было проведено сравнение производительности базового алгоритма GLL и описанного в данной 
    работе в задаче поиска 16s рРНК в метагеномной сборке. Решение уже было предложено в рамках проекта YaccConscructor.
    Результаты сравнения для части сборки приведены в таблице~\ref{expTable1} и показывают, что при работе с метагеномными сборками новый
    алгоритм, в среднем, использует на 60\% меньше памяти и работает в два раза быстрее.
    
    \begin{table}[h]
        \begin{tabular}{ | c | c | c | c | c | }
            \hline
            \multirow{2}{*}[-1ex]{} &\multicolumn{3}{c|}{Использование памяти} & \multirow{2}{*}[-1ex]{Время, мин } \\
            \cline{2-4}
            &  Дескрипторы & Рёбра GSS & Узлы GSS &  \\ \hline
            Грамматика  &  21,134,080       & 7,482,789      & 2,731,529      & 02.26  \\ \hline
            RA &  9,153,352        &  2,792,330     & 839,148        & 01.25  \\ \hline \hline
            Ratio   &  57$\%$       & 63$\%$     & 69 $\%$    &  45 $\%$ \\ \hline
        \end{tabular}
        \caption{Результаты экспериментов с метагеномной сборкой}
        \label{expTable1}
    \end{table}
    
    \input{performancePlots.tex}
	
	\section*{Заключение}
	В рамках данной работы разработана и реализована модификация алгоритма GLL,
	работающая с расширенными контекстно-свободными грамматиками и показано, что полученный
	алгоритм повышает производительность поиска структур заданных с помощью контекстно-свободной
	грамматики в метагеномных сборках. Более детально, были получены следующие результаты:
	\begin{itemize}
		\item В качестве подходящего представления ECFG выбраны рекурсивные конечные автоматы.
		\item Спроектирована структура данных для представления леса разбора по ECFG 
		на основе сжатого леса разбора(SPPF).
		\item Разработан алгоритм на основе Generalised LL, строящий лес разбора по ECFG.
		\item Алгоритм реализован в рамках проекта YaccConstructor.
		\item Проведены эксперименты, показавшие двухкратный прирост 
		производительности на имеющихся метагеномных сборках по сравнению 
		с существуюшим решением.
		\item Результаты работы успешно представлены на международной конференции
		``Tools and Methods of Program Analysis''(Москва, 2017г.)
	\end{itemize}
	
	\setmonofont[Mapping=tex-text]{CMU Typewriter Text}
	\bibliographystyle{ugost2008ls}
	\bibliography{diploma}
	\input{appendix}
\end{document}

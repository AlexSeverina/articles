% Тут используется класс, установленный на сервере Papeeria. На случай, если
% текст понадобится редактировать где-то в другом месте, рядом лежит файл matmex-diploma-custom.cls
% который в момент своего создания был идентичен классу, установленному на сервере.
% Для того, чтобы им воспользоваться, замените matmex-diploma на matmex-diploma-custom
% Если вы работаете исключительно в Papeeria то мы настоятельно рекомендуем пользоваться
% классом matmex-diploma, поскольку он будет автоматически обновляться по мере внесения корректив
%

% По умолчанию используется шрифт 14 размера. Если нужен 12-й шрифт, уберите опцию [14pt]
\documentclass[14pt]{matmex-diploma-custom}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{float}
\usepackage[caption=false]{subfig}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.9}
\usepackage{multirow}

\usepackage{url}
\usepackage{algpseudocode}
\usepackage{algorithm}
\usepackage{algorithmicx}
%\documentclass[14pt]{matmex-diploma-custom}
%\hyphenation{Ge-ne-ra-lised}
\newtheorem{mydef}{Определение}
%\tolerance=1
\emergencystretch=\maxdimen
%\hyphenpenalty=10000
%\hbadness=10000


\begin{document}
	\algnewcommand\algorithmicswitch{\textbf{switch}}
	\algnewcommand\algorithmiccase{\textbf{case}}
	\algnewcommand\algorithmicassert{\texttt{assert}}
	\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}
	% New "environments"
	\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}
	\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}
	
	\algtext*{EndSwitch}
	\algtext*{EndCase}
	\algtext*{EndWhile}% Remove "end while" text
	\algtext*{EndIf}% Remove "end if" text
	\algtext*{EndFor}% Remove "end for" text
	\algtext*{EndFunction}% Remove "end function" text
	
	% Год, город, название университета и факультета предопределены,
	% но можно и поменять.
	% Если англоязычная титульная страница не нужна, то ее можно просто удалить.
	\filltitle{ru}{
		chair              = {Программная инженерия},
		title              = {Поддержка расширенных контекстно-свободных грамматик 
			в алгоритме синтаксического анализа Generalised LL},
		type               = {bachelor},
		position           = {студента},
		group              = 471,
		author             = {Горохов Артем Владимирович},
		supervisorPosition = {к.\,ф.\,-м.\,н.,\,доц.},
		supervisor         = {Григорьев С.\,В.},
		reviewerPosition   = {СУИ НИУ ИТМО, программист},
		reviewer           = {Авдюхин Д.А.}
	}
	
	\filltitle{en}{
		chair              = {Software engineering},
		title              = {Support of extended context-free grammars in Generalised LL parsing algorithm},
		author             = {Artem Gorokhov},
		supervisorPosition = {associate professor},
		supervisor         = {Semyon Grigorev},
		reviewerPosition   = {ITMO University, programmer},
		reviewer           = {Dmitry Avduhin}
	}
	\maketitle
	%\setcounter{tocdepth}{1}
	\tableofcontents
	% У введения нет номера главы
	\section*{Введение}
	
	Общеупотребимый способ описания синтаксиса языков программирования ---
	расширенные контекстно-свободные грамматики. Примером могут служить спецификации языков 
	$C$, $C++$, $Java$ и т.д. С одной стороны, эта форма проста для понимания людей, 
	с другой, достаточно формальна и допускает автоматизированное создание 
	синтаксических анализаторов.
	
	Существуют различные инструменты, такие как ANTLR~\cite{ANTLR}, Bison~\cite{Bison},
    позволяющие для грамматики языка создать синтаксический анализатор для текстов, созданных на этом языке.
	Проблема заключается в том, что эти инструменты
	сначала преобразуют грамматику к форме Бэкуса-Наура и только затем
	строят синтаксический анализатор.
	
	Существуют работы, описывающие синтаксический анализ с помощью расширенных
	контекстно-свободных грамматик (Extended Context-Free Grammar, ECFG)~\cite{Breveglieri2014},~\cite{lee1997characterization},
	но практические средства, основанные на данных работах, не были созданы. Кроме того, подходы, описанные
	в данных исследованиях, поддерживают лишь подклассы контекстно-свободных языков.
	
	Алгоритмы обобщённого синтаксического анализа, например
    \begin{english} Generalised LL \end{english}~\cite{scott2010gll}, 
	способны использовать контекстно-свободные грамматики, описывающие произвольные 
	контекстно-свободные языки. Но они так же не допускают использования ECFG 
	без предварительного преобразования к контекстно-свободному виду.
	
	Одно из возможных применений обобщённого синтаксического анализа --- поиск генов и иных последовательностей в биологическом материале. 
	Из материала извлекаются геномы содержащихся в нём организмов --- последовательности над алфавитом $\{A;C; G; U\}$.
    Но для того чтобы снизить расходы на хранение этих последовательностей, по ним строится конечный автомат.
    В геноме существуют различные последовательности, позволяющие классифицировать организм, которые имеют некоторые общие свойства, которые можно описать 
    контекстно-свободной грамматикой~\cite{Anderson2013}, поэтому для их поиска можно применять синтаксический анализ.
    Синтаксический анализ конечных автоматов называют 
    синтаксическим анализом регулярных множеств. Одной из целей данной работы является применение
    полученного GLL алгоритма в
	синтаксическом анализе регулярных множеств, в частности --- метагеномных сборок.
	
	На кафедре Системного Программирования СПбГУ, в рамках исследовательского проекта YaccConstructor~\cite{YaccConstructor},
	разрабатывается подход для поиска структур, заданных с помощью контекстно-свободной
	грамматики в метагеномных сборках, основанный на алгоритме Generalised LL.
	Предполагается, что синтаксический анализ для расширенных контекстно-свободных грамматик
    без преобразований даст значительный прирост производительности существующего подхода.
	
	\section{Постановка задачи}
	
	Целью данной работы является модификация алгоритма Generalised LL, для обработки
	расширенных контекстно-свободных грамматик (ECFG) и проверка того, как полученный 
	алгоритм влияет на производительность поиска структур, заданных с помощью 
	контекстно-свободной грамматики в метагеномных сборках. Для её достижения были 
	поставлены следующие задачи.
	
	\begin{itemize}  
		\item Выбрать или разработать подходящее представление ECFG для использования в синтаксическом анализе.
		\item Спроектировать структуру данных для представления леса разбора для ECFG.
		\item Разработать алгоритм на основе Generalised LL, строящий лес разбора для ECFG.
        \item Разработать механизм анализа регулярных множеств в алгоритме построения леса разбора для ECFG.
		\item Реализовать разработанный алгоритм в рамках проекта YaccConstructor.
		\item Провести экспериментальное сравнение реализованного алгоритма с существующим при анализе метагеномной сборки.
	\end{itemize}
	
	\section{Обзор}
	
	\subsection{Расширенные контекстно-свободные грамматики}
	%Статический анализ программ oбычно выполняется для структурного представления кода. 
	%Генераторы синтаксических анализаторов часто используются для автоматизации создания анализатора: 
    %эти инструменты получают синтаксический анализатор по грамматике.
	
	Расширенная форма Бэкуса-Наура (EBNF)~\cite{EBNFISO} является метасинтаксисом для представления 
	контекстно-свободных грамматик. В дополнение к конструкциям, используемым в форме
	Бэкуса-Наура, в ней используется следующие конструкции: альтернатива |,
	необязательные символы [\dots], повторение \{\dots\} и группировка (\dots).
	
	Форма EBNF широко используется для спецификации грамматики в технической документации
	ввиду того, что её выразительная сила делает спецификацию синтаксиса более компактной
	и удобной для чтения. Поскольку документация является одним из основных источников информации
	о языке для разработчиков синтаксических анализаторов, полезно иметь генератор
	анализаторов, который поддерживает грамматики в EBNF. Заметим, что EBNF является 
	лишь стандартизированной формой для \textit{расширенных контекстно-свободных грамматик}
	~\cite{ECFG}.
	
	\begin{mydef}
		Расширенная контекстно-свободная грамматика (ECFG)~\cite{ECFG} --- это кортеж $(N, \Sigma, P, S)$,
		где N и $\Sigma$ конечные множества нетерминалов и терминалов cоответственно, 
		$S\in N$ является стартовым символом, а P (продукция) является отображением из N в
		регулярное выражение над алфавитом $N \cup \Sigma$.
		
	\end{mydef}
	ECFG широко используется в качестве входного формата для генераторов синтаксических анализаторов, 
	но классические алгоритмы синтаксического анализа часто требуют контекстно-свободную форму (CFG),
	в продукциях которой допускаются лишь последовательности из терминалов и нетерминалов. Таким образом 
	для работы генераторов анализаторов требуется преобразование в CFG.
	Возможно преобразование ECFG в CFG \cite{ELL}, но оно приводит к увеличению
	размера грамматики и изменению её структуры: при трансформации добавляются новые
	нетерминалы. В результате синтаксический анализатор строит дерево вывода относительно
	преобразованной грамматики, и разработчику языка сложнее отлаживать грамматику 
	и использовать результат синтаксического анализа. Кроме того, увеличение размера грамматики 
    отрицательно сказывается на производительности анализа.
    
	Существует широкий спектр методов анализа и алгоритмов~\cite{AttributedELL,ELRR,
		ECFGparsing,ELLParser,ELL,ECFG,ELALR,ELRParsing}, которые способны обрабатывать 
	ECFG. Детальный обзор результатов и задач в области обработки ECFG 
	представлены в статье ``Towards a Taxonomy for ECFG and RRPG Parsing''~\cite{ECFG}.
	Следует отметить, что большинство алгоритмов основано на классических методах
	LL~\cite{ELLParser,AttributedELL,PredictiveECFG} --- низходящий анализ и LR~\cite{ELRParsing,ELALR,ELRR}
    --- восходящий анализ,
	но они работают только с ограниченными подклассами расширенных контекстно-свободных грамматик ---
    LL(k), LR(k). Таким образом, нет решения 
	для обработки произвольных (в том числе неоднозначных) ECFG.
	
	Aлгоритмы синтаксического анализа на основе 
    LL проще для восприятия, чем основанные на LR, и могут
	обеспечить лучшую диагностику ошибок. В настоящее время LL(1) представляется
	наиболее практичным алгоритмом. К сожалению, некоторые языки не являются LL(k) (для любого k)
    и не могут быть использованы в LL(k) анализаторах, другие проблемы для инструментов на основе LL 
    --- леворекурсивные грамматики и неоднозначности в грамматике, 
	которые, вместе с предыдущим недостатком, усложняют создание синтаксических 
	анализаторов. Алгоритм Generalised LL, предложенный в~\cite{scott2010gll}, решает 
	все эти проблемы: он обрабатывает произвольные CFG, в том числе неоднозначные и
	леворекурсивные.
	В худшем случае временная и пространственная сложность GLL зависит кубически от 
	размера входа. А для LL(1) грамматик, он демонстрирует линейную временную и
	пространственную сложность.
    
    Чтобы увеличить производительность Generalised LL-алгорима, была предложена поддержка 
    лево-факторизованных грамматик в нём~\cite{scott2016structuring}.
    Из описания GLL-алгоритма ясно, что для уменьшения времени анализа и количества используемой памяти
    можно снизить количество дескрипторов для обработки. Один из путей для достижения этого --- 
    уменьшение размера грамматики (снижение количества различных позиций в ней).
    Этого можно достичь факторизацией грамматики. Пример факторизации показан на рис.~\ref{fig:ExampleOfFactorization}:
    из грамматики $G_0$ в процессе факторизации получается грамматика $G_0'$.
    Этот пример рассмотрен в работе~\cite{scott2016structuring}, и доказано, что для некоторых грамматик факторизация 
    существенно увеличивает производительность алгоритма GLL.
    \begin{figure}
        \centering
        \subfloat[Исходная грамматика $G_0$]{
            $
            \begin{array}{rl}
            S::= a\ a\ b\ c\ d \ | \ a\ a\ c\ d \ | \ a\ a\ c\ e |\ a\ a
            \end{array}
            $
        }
        ~
        \subfloat[Факторизованная грамматика $G_0'$]{
            $
            \begin{array}{rl}
            S::= a\ a\ ( b\ c\ d\ |\ c\ ( d\ |\ e )\ |\ \varepsilon \ )
            \end{array}
            $
        }
        \caption{Пример факторизации грамматики}
        \label{fig:ExampleOfFactorization}
    \end{figure}
    В данной работе эта идея развита в поддержку расширенных контекстно-свободных грамматик.
	
	\subsection{Стек, структурированный в виде графа}
	В процессе синтаксического анализа используется стек, позволяющий отслеживать историю 
	разбора нетерминалов. Но, при встречи неоднозначности в грамматике, для каждого варианта 
    разбора должен быть создан новый стек, основанный на текущем. Такое представление неэффективно, так как эти стеки имеют общие узлы,
    которые могут быть переиспользованы. Поэтому был предложен стек, структурированный в виде графа
    (Graph Structured Stack, GSS). GSS комбинирует в себе все варианты стеков.
    
    В работе~\cite{ragozina} используется стек, структура которого определена в~\cite{afroozeh2015faster}.
    В его узлах хранятся нетерминалы и начальные позиции их разбора во входе.
    На рёбрах, исходящих из узла с меткой $(A, i)$, хранятся позиции в грамматике с которых нужно
    продолжать разбор после разбора нетерминала A, а так же корень построенного SPPF до начала 
    разбора нетерминала A.
    
	\subsection{Сжатое представление леса разбора}
	Результатом работы синтаксического анализатора является структурное представление
    входа: дерево разбора. Если возможно несколько выводов входа, строится несколько деревьев:
    для каждого варианта разбора. Например для грамматики $G_0$ (рис.~\ref{fig:fig0}) и входа $ccc$
    будут построены 2 дерева, показанные на рис.~\ref{fig:Gtrees}.
    
    Для некоторых грамматик количество деревьев может экспоненциально зависеть от размера входа.
    Чтобы снизить расходы для хранения и обработки всех деревьев, используется структура данных
    Shared Packed Parse Forest (SPPF). 
    Будем использовать бинаризованную версию SPPF, предложенную в~\cite{brnglr}, для уменьшения
    потребления памяти и достижения кубической наихудшей временной и пространственной сложности.
    Бинаризованный SPPF может использоваться в GLL~\cite{scott2013gll} и содержит следующие типы узлов
    ($i$ и $j$ --- это начало и конец выведенной подстроки для данного узла).
    \begin{itemize}
        \item Упакованные узлы вида $(M, k)$, где $M$ --- позиция в грамматике, k --- начало выведенной
        подстроки правого ребёнка. У упакованных узлов обязательно существует правый ребёнок ---
        символьный узел, и опциональный левый --- символьный или промежуточный узел.
        \item Символьный узел помечен $(X, i, j)$ где $X$ --- терминал или нетерминал.
        Терминальные символьные узлы --- листья. 
        Нетерминальные символьные узлы могут иметь несколько упакованных детей. 
        \item Промежуточные узлы помечены $ (M, i, j) $, где $M$ --- позиция в грамматике, 
        могут иметь несколько упакованных детей, каждый из которых представляет различные варианты разбора.
    \end{itemize}
    Дети символьных и промежуточных узлов --- упакованные. Различные упакованные дети --- различные варианты поддеревьев.
    Если у узла или его потомков более одного упакованного ребёнка, то для него было построено несколько вариантов 
    разбора для строки. Промежуточные и упакованные узлы необходимы для бинаризиции SPPF.
    Так, деревья, представленные на рис.~\ref{fig:Gtrees}, объединяются в SPPF показанный на рис.~\ref{fig:GSPPF}.
    \begin{figure}
        \centering
        $
        \begin{array}[b]{rl}
        S ::= S\ S\ | \ c \ \ \ 
        \end{array}
        $
        \caption{Грамматика $G_0$}
        \label{fig:fig0}
    \end{figure}
    \begin{figure}[ht]   
        \centering
        \subfloat[Возможные деревья вывода]{
            \includegraphics[scale=.6]{pictures/Gtrees.pdf}
            \label{fig:Gtrees}
        }
        ~
        \subfloat[SPPF]{
            \includegraphics[scale=.6]{pictures/GSPPF.pdf}
            \label{fig:GSPPF}
        }
        \caption{Пример для входа $ ccc $ и грамматики $G_0$}
        \label{fig:fig01}
    \end{figure}
    \subsection{Алгоритм Generalised LL}
	
	Цель обобщенных алгоритмов синтаксического анализа --- обеспечить создание синтаксических
	анализаторов для произвольных контекстно-свободных грамматик.
	Алгоритм Generalised LL~(GLL)~\cite{scott2010gll} включает в себя свойства классических LL алгоритмов:
	он проще в понимании и обеспечивает более хорошую диагностику ошибок, 
	чем обобщенные LR алгоритмы. Кроме того, опыт показывает, что решения на основе
	GLR более сложны, чем основанные на GLL, что согласуется с наблюдением в [11], что
	синтаксические анализаторы ECFG на основе LR очень сложны. Таким образом, в качестве
	основы для решения был выбран GLL алгоритм. 
	
	Идея алгоритма GLL основана на обработке так называемых дескрипторов, которые 
	могут однозначно определить состояние процесса синтаксического анализа. Дескриптор
	представляет собой кортеж $(L, i, T, S)$, где:
	\begin{itemize}
		\item $L$ указатель на позицию в грамматике вида~$(S \to \alpha \cdot \beta)$;
		\item $i$ --- позиция во входе;
		\item $T$ --- корень построенного леса разбора;
		\item $S$ --- текущий узел стека~(GSS)~\cite{afroozeh2015faster}.
	\end{itemize}
	
	GLL двигается одновременно по входу и грамматике, создавая множество дескрипторов
	в случае неоднозначности и использует очередь для управления обработкой дескрипторов.
	В начальном состоянии существует только один дескриптор, который состоит из начальной 
	позиции в грамматике~$(S \to \cdot \beta)$, во входе (i = 0), фиктивного узла дерева (\$)
	и дна стека. На каждом шаге алгоритм извлекает дескриптор из очереди и действует
	в зависимости от грамматики и входа. Если имеется неоднозначность, то алгоритм помещает
	в очередь дескрипторы для всех возможных случаев, чтобы обработать их позже. 
	Для достижения кубической временной сложности важно помещать в очередь только дескрипторы,
	которые не создавались ранее. Для того чтобы решить добавлять дескриптор или нет
	используется глобальное хранилище всех созданных дескрипторов.
	Существует подход на основе таблиц~\cite{ragozina} для реализации GLL, который генерирует
	только таблицы для данной грамматики вместо полного кода синтаксического анализатора.
	Эта идея похожа на алгоритм в оригинальной статье и использует те же техники
	построения леса разбора и обработки стека. Псевдокод, иллюстрирующий этот подход, 
	можно найти в приложении. Обратите внимание, что в приложении и далее в псевдокод не включена
	проверка для множеств first/follow.
    
	\subsection{Анализ метагеномных сборок}
	В практических задачах часто могут возникать ситуации, когда необходимо проводить синтаксический анализ 
    сразу нескольких строк. Существует подход, при котором для строк подлежащим анализу строится 
    конечный автомат порождающий эти строки. И тогда задача сводится к анализу регулярного языка относительно 
    грамматики. Такой подход называют синтаксическим анализом регулярных множеств. Одно из применений этого подхода ---
    биоинформатика.
    
    Биоинформатика включает в себя множество задач, решения которых необходимы в биологических исследованиях.
    Одна из них --- задача идентификации организмов в биологическом материале. В результате оцифровывания материала получают
    геномы организмов --- строки над алфавитом $\{A;C; G; U\}$.
    Извлечённые из материала последовательности объединяются в метагеномную сборку --- конечный автомат, пути в котором задают полученные 
    гены.
    
    Существует множество подходов к анализу и идентификации образцов. Один из них --- поиск и сравнение участков таких структур как
    16s рРНК, тРНК, так как по ним можно достаточно точно классифицировать огранизм которому они принадлежат.
    Существуют такие инструменты, как REAGO~\cite{reago} и HMMER~\cite{hmmer}, использующие скрытые цепи Маркова для поиска, 
    Infernal~\cite{Infernal}, использующий ковариационные модели. Но они работают лишь с линейными цепочками генома ---
    не объединёнными в конечный автомат,
    такое представление требует большого количества памяти и неэффективно. С другой стороны, инструмент Xander~\cite{xander} использует 
    композицию скрытых моделей Маркова и метагеномной сбоки, представленной в виде автомата. Изъян данного инструмента в существенно 
    более низкой точности результата в сравнения с инструментами, использующими ковариационные модели.
    
    Другой подход разрабатывается на кафедре Системного Программирования СПбГУ.
    Поиск производится непосредственно в метагеномной сборке по таким структурам как тРНК, 16s рРНК.
    Эти структуры имеют некоторые общие свойства в строении, которые могут быть описаны
    контекстно-свободной грамматикой~\cite{Anderson2013}.
    Таким образом, можно использовать синтаксический анализ регулярных множеств для поиска структур.
	Этот подход описан в работе~\cite{ragozina}, основан на алгоритме синтаксического анализа Generalised LL и 
    был реализован в рамках проекта YaccConstructor.
	
    \subsection{Проект YaccConstructor}
    YaccConstructor~\cite{YaccConstructor} --- это исследовательский проект кафедры Системного Программирования СПбГУ и лаборатории
    языковых инструментов JetBrains. Проект направлен на изучение алгоритмов синтаксического и 
    лексического анализа и занимается разработкой инструмента YaccConstructor, предоставляющего платформу для
    создания и изучения новых алгоритмов. Инструмент имеет модульную архитектуру и включает в себя язык описания 
    грамматик Yard, который поддерживает расширенные контекстно-свободные грамматики. Кроме того в инструменте 
    реализован генератор синтаксических анализаторов на основе Generalised LL алгоритма.
    Инструмент разработан на платформе $.NET$, на языке программирования $F\#$.
    
	\section{Представление ECFG}
	
	Чтобы облегчить задание грамматики в форме ECFG для синтаксического анализатора
	будем использовать рекурсивный автомат (\begin{english} Recursive Automaton (RA)\end{english}~\cite{tellier2006learning}
	для представления ECFG. Будем использовать следующее определение RA.
	\begin{mydef}
		Рекурсивный автомат $R$ это кортеж $(\Sigma, Q, S, F, \delta)$, где $\Sigma$
		--- конечное множество терминалов, $Q$ - конечное множество состояний, $S \in Q$ 
		--- начальное состояние, $F \subseteq Q$ --- множество конечных состояний,
		$\delta : Q \times (\Sigma \cup Q) \to Q$ --- функция перехода.
	\end{mydef}
	В рамках этой работы единственное различие между рекурсивным автоматом и общеизвестным
	конечным автоматом (FSA) состоит в том, что переходы в RA обозначаются либо терминалом ($\Sigma$),
	либо состоянием автомата ($Q$). Далее в этой работе будем называть переходы по элементам из
	$Q$ \textit{нетерминальными переходами}, а по терминалам --- \textit{терминальными переходами}.
    Переход по нетерминалу в состояние $q$ подразумевают построение вывода для некоторой подстроки начиная с текущей позиции
    вывода по этому нетерминалу и последующий разбор оставшейся подстроки начиная с состояния $q$.
     
	Заметим, что позиции грамматики эквивалентны состояниям автомата, которые 
	строятся из правых частей продукций. Правые части продукций ECFG являются регулярными
	выражениями над объединенным алфавитом терминалов и нетерминалов. Итак, наша цель ---
	построить RA с минимальным числом состояний для заданной ECFG, что можно сделать следующими шагами.
	\begin{itemize}
		\item Построить конечный автомат, используя метод Томпсона~\cite{Thompson:1968:PTR:363347.363387} для правых
		частей продукций.
		\item Создать карту из каждого нетерминала в соответствующее начальное состояние автомата.
		Эта карта должна оставаться консистентной на протяжение всех следующих шагов.
		\item Преобразовать автоматы из предыдущего шага в детерминированные без 
		$\varepsilon$-переходов используя алгоритм, описанный в~\cite{aho1974design}.
		\item Минимизировать детерминированный автомат, используя, например, алгоритм
		Джона Хопкрофта~\cite{hopcroft1971n}.
		\item Заменить нетерминальные переходы переходами по, стартовым состояниям автоматов,
		соответствующим данным нетерминалам, используя карту $M$. Результат 
		этого шага --- искомый рекурсивный автомат. Также используем карту $M$
		для определения функции $\Delta : Q \to N$ где $N$ --- имя нетерминала.
	\end{itemize}
	Пример преобразования ECFG в RA представлен на рис.~\ref{fig:fig1}, где состояние
	0 --- начальное состояние результирующего RA.
	\begin{figure}
		\centering
		\subfloat[Грамматика $G_1$]{
			$
			\begin{array}[b]{rl}
			S ::= a^{+} S\ b? \ | \ c \ \ \ 
			\end{array}
			$
			\label{fig:grammarG0}
		}
		~
		\subfloat[Конечный автомат для $G_1$]{
			\includegraphics[scale=.6]{pictures/G0initialAutomaton.pdf}
			\label{fig:initialAutomatonsForG0}
		}
		~
		\subfloat[Рекурсивный автомат $R_1$ для $G_1$]{
			\includegraphics[scale=.6]{pictures/G0minimizedAutomaton.pdf}
			\label{fig:RAForG0}
		}
		\caption{Преобразование грамматики в рекурсивный автомат}
		\label{fig:fig1}
	\end{figure}
	
	\section{Лес разбора для ECFG}
	Результатом процесса синтаксического анализа является структурное представление 
	входа --- дерево или лес разбора в случае нескольких вариантов деревьев.
	Для начала, определим дерево вывода для рекурсивного автомата: 
	это дерево, корень которого помечен начальным состоянием, листовые узлы помечены
	терминалом или $\varepsilon$, а внутренние узлы помечены нетерминалами N и их
	дети образуют последовательность меток в пути в автомате, который начинается в 
	состоянии $q_i$, где $ \Delta(q_i) = N $. Более формально:
	
	\begin{mydef}
		
		Дерево вывода последовательности $\alpha$ для рекурсивного автомата $R=(\Sigma, Q, S, F, \delta)$ это дерево со следующими свойствами:
		
		\begin{itemize}
			\item корень помечен $\Delta(S)$;
			\item листья ---теминалы $a\in (\Sigma \cup \varepsilon)$;
			\item остальные узлы --- нетерминалы $A\in \Delta(Q)$;
			\item у узла с меткой $N_i = \Delta(q_i)$ существует:
			\begin{itemize}
				\item 
				дети $l_0 \dots l_n (l_i \in \Sigma \cup \Delta(Q))$ тогда и только тогда,
				когда существует путь $p$ в $R$, $p = q_i \xrightarrow[]{l_0} q_{i+1} \xrightarrow[]{l_1} \dots \xrightarrow{l_n} q_m$, где
				$q_m \in F$, $l_i = 
				\left\{
				\begin{matrix}
				k_i, \text{ if }  k_i \in \Sigma,\\
				\Delta(k_i), \text{ if } k_i \in Q,
				\end{matrix}
				\right.
				$
				\item только один ребенок помеченный $\varepsilon$ тогда и только тогда,
				когда $ q_i \in F $.
			\end{itemize}
		\end{itemize}
	\end{mydef}
	Для произвольных грамматик RA может быть неоднозначным с точки зрения допустимых путей,
	и, как результат, можно получить несколько деревьев разбора для одной входной строки.
	Shared Packed Parse Forest (SPPF)~\cite{SPPF} может использоваться как компактное
	представление всех возможных деревьев разбора. Будем использовать бинаризованную версию SPPF,
	предложенную в~\cite{brnglr}, для уменьшения потребления памяти и достижения кубической
	наихудшей временной и пространственной сложности. Бинаризованный SPPF может использоваться
	в GLL~\cite{scott2013gll} и содержит следующие типы узлов (здесь i и j называют правый и
	левый extent --- начало и конец выведенной подстроки во входной строке):
	
	\begin{itemize}
		\item упакованные узлы вида $(S, k)$, где $S$ состояние автомата, k --- начало выведенной
		подстроки правого ребёнка; у упакованных узлов обязательно существует правый ребёнок ---
		символьный узел, и опциональный левый --- символьный или промежуточный узел;
		\item символьный узел помечен $(X, i, j)$ где $X \in \Sigma \cup \Delta(Q) \cup \{\varepsilon\}$;
		терминальные символьные узлы ($X \in \Sigma \cup \{\varepsilon\}$) --- листья;
		нетерминальные символьные узлы ($X \in \Delta(Q)$) могут иметь несколько упакованных детей;
		\item промежуточные узлы помечены $ (S, i, j) $, где $S$ состояние в автомате, могут иметь несколько упакованных детей.
	\end{itemize}
	
	Опишем модификации исходных функций построения SPPF.
	Функция \textbf{getNodeT$ (x, i) $}, которая создает терминальные узлы, 
	повторно используется без каких-либо модификаций из базового алгоритма.
	Чтобы обрабатывать недетерминизм в состояниях, определим функцию 
	\textbf{getNodes}, которая проверяет, является ли следующее состояние RA финальным
	и в этом случае строит нетерминальный узел в дополнение к промежуточному.
	Она использует изменённую функцию \textbf{getNodeP}: вместо позиции в грамматики он 
	принимает в качестве входных данных отдельно состояние RA и символ для нового узла SPPF:
	текущий нетерминал или следующее состояние RA.
	
	\input{./getNodes.tex}
	\input{getNodeP.tex}
	
	Рассмотрим пример SPPF для ECFG $ G_1 $, показанные на рис.~\ref{fig:grammarG0}.
	Эта грамматика содержит конструкции (условное вхождение (?) и повторение (+)),
	которые должны быть преобразованы с использованием дополнительных нетерминалов 
	для создания обычного GLL-анализатора.
	Предложенный генератор строит рекурсивный автомат $ R_1 $~(рис.~\ref{fig:RAForG0})
	и анализатор для него. Возможные деревья ввода последовательности $ aacb $ показаны 
	на рис.~\ref{fig:treesForG0}. SPPF, созданный синтаксическим анализатором~(рис.~\ref{fig:SPPFForG0}),
	содержит в себе все три дерева.
	
	\begin{figure}[ht]   
		\centering
		\subfloat[Возможные деревья вывода]{
			\includegraphics[scale=.5]{pictures/G0trees.pdf}
			\label{fig:treesForG0}
		}
		~
		\subfloat[SPPF]{
			\includegraphics[scale=.5]{pictures/G0SPPFwithPackedNodes.pdf}
			\label{fig:SPPFForG0}
		}
		\caption{Пример для входа $ aacb $ и автомата $R_1$}
		\label{fig:fig2}
	\end{figure}
	
	\section{Алгоритм построения леса разбора для ECFG}
	В этом разделе описываются изменения в управляющих функциях базового алгоритма 
	Generalised LL, необходимые для обработки ECFG. Основной цикл аналогичен базовому
	GLL: на каждом шаге основная функция \textbf{parse} извлекает из очереди дескриптор
	$R$, подлежащий обработке. Пусть текущий дескриптор -- кортеж ($C_S, C_U, i, C_N$),
	где $C_S$ --- состояние RA, $C_U$ --- узел GSS, i --- позицию во входной строке 
	$\omega$, $C_N$ --- узел SPPF. В ходе обработки дескриптора могут возникнуть следующие
	не исключающие друг друга ситуации.
	\begin{itemize} 
		\item $C_S$ --- финальное состояние. Это возможно только если $C_S$
		--- стартовое состоение текущего нетерминала. Следует построить нетерминальный
		узел с ребёнком $(\varepsilon, i, i)$ и вызвать функцию \textbf{pop}, так как
		разбор нетерминала окончен.
		
		\item Существует терминальный переход $C_S \xrightarrow[]{\omega.[i]} q$.
		Во-первых, построить терминальный узел $ t = (\omega.[i], i, i+1) $, далее 
		вызвать функцию \textbf{getNodes} чтобы построить родителя для $ C_N $ и $ t $. 
		Функция \textbf{getNodes} возвращает кортеж $ (y, N) $, где $N$ --- опциональный
		нетерминальный узел. Создать дескриптор $ (q, C_U, i+1, y) $ и, если
        в $q$ ведёт несколько переходов, вызвать функцию \textbf{add} для этого дескриптора.
        Иначе поместить его в очередь вне зависимости от того был ли он создан до этого. 
        Если $ N \neq \$$,
		вызвать функцию \textbf{pop} для этого узла, состояния $ q $ и позиции во
		входе $ i + 1 $.
		
		\item Существуют нетерминальные переходы из $C_S$.
		Это значит что следует начать разбор нового нетерминала, поэтому должен быть
		создан новый узел GSS, если такового ещё нет. Для этого нужно вызвать функцию
		\textbf{create} для каждого такого перехода. Она осуществляет необходимые
		операции с GSS и проверяет наличие узла GSS для текущих нетерминала и 
		позиции во входе.
	\end{itemize}
	Псевдокод для необходимых функций представлен ниже:
	
	Функция \textbf{add} помещает в очередь дескриптор, если он не был создан до этого; эта функция не изменилась.
	\input{create.tex}
	
	\input{pop.tex}
	
	%\textbf{Pop} function is called when we reach final state. It queues descriptors for all outgoing edges from current GSS node.
	
	\input{parse.tex}
	
	
    
    
    \section{Синтаксический анализ регулярных множеств}
    Для работы с метагеномными сборками необходимо осуществить поддержку синтаксического анализа регулярных множеств.
    При работе с автоматом в качестве входных данных необходимо обрабатывать все переходы из текущей позиции (состояния) в автомате.
    Так, основная функция приобретает следующий вид:
    \input{parseReg.tex}
    Позициями во входе для автомата становятся номера состояний и обрабатываются все исходящие переходы во входе. Кроме того,    
    Функция \textbf{add} вызывается при обработке терминального перехода всегда, чтобы поддержать возможные циклы во входе.
    Например, для грамматики $S ::= a*$ и входного автомата на рис.~\ref{graphEx}
    дескриптор будет создаваться бесконечно, если не добавить его в множество созданных, и алгоритм не остановится.
    Данное изменение не меняет теоретическую сложность алгоритма, но может сказаться на производительности в худшую сторону.
    Поэтому этот подход можно применять лишь только в случае присутствия циклов во ходе, иначе вызывать функцию \textbf{add}
    только при наличии нескольких входящих переходовы в текущее состояние.
    
    \begin{figure}[ht]   
        \centering
        \includegraphics[scale=.5]{pictures/graphEx.pdf}
        \caption{Пример входа для грамматики $S ::= a^*$.}
        \label{graphEx}
    \end{figure}

    \section{Реализация}
    
    Описанный алгоритм реализован в проекте YaccConstructor. 
    %Архитектура проекта показана на рис.~\ref{}. 
    На вход генератору поступает структурное представление грамматики, на основе которого 
    генератор создаёт управляющие таблицы. Далее они и входные данные поступают на вход
    синтаксическому анализатору, который строит SPPF. 
    
    В проекте уже был реализован генератор анализаторов и интерпретатор
    на основе алгоритма GLL, они были заменены предложенными в этой работе с сохранением остальной инфраструктуры.

	\section{Эксперименты}
    В работе~\cite{scott2016structuring}
    было проведено экспериментальное сравнение алгоритма для факторизованных грамматик (Factorised GLL, FGLL) и базового GLL-алгоритма,
    продемонстрировавшее, что FGLL показывает б\`ольшую производительность для грамматик в форме Бэкуса-Наура, которые могут быть факторизованы.
    Предполагается, что предложенная в данной работе версия алгоритма
    продемонстрирует б\`ольшую производительность, чем FGLL, для грамматик, имеющих эквивалентные позиции для алгоритма минимизации автомата, но различные после факторизации. Так, например, для грамматики, в которой есть эквивалентные позиции для которых алгоритм создаёт большое количество дескрипторов,
    построенный для неё автомат, объединит данные позиции, сократив те самым множество создаваемых дескрипторов,
    что в свою очередь увеличит производительность. Примером такой ситуации может служить грамматика 
    $G_2$~(рис.~\ref{fig:grammarG1}), так так она содержит длинные последовательности 
    в альтернативах, которые не сливаются при факторизации, но эквивалентны для алгоритма минимизации автомата.
    Рекурсивный автомат построенный для этой грамматике показан на рис.~\ref{fig:automatonForG1}.
    
    \begin{figure}[ht]   
        \centering
        \subfloat[Грамматика $G_2$]{
            $
            \begin{array}{rl}
            S ::=& K\ (K\ K\ K\ K\ K \ |\ a\ K\ K\ K\ K) \\
            K ::=& S\ K\ |\ a\ K\ |\ a \\
            \end{array}
            $
            \label{fig:grammarG1}
        }
        
        \subfloat[RA для грамматики $G_2$]{
            \includegraphics[scale=.5]{pictures/G1automaton.pdf}
            \label{fig:automatonForG1}
        }
        \caption{Грамматика $G_2$ и RA для неё}
    \end{figure}
    
    Эксперименты проводились на входах различной длины, результаты приведены на рис.~\ref{expPlots}.
    Точные данные для входа $a^{450}$ показаны в таблице~\ref{expTable}.
        
    Тесты проводились на ПК со следующими характеристиками: Microsoft Windows 10 Pro x64, Intel(R) Core(TM) i7-4790 
    	CPU @ 3.60GHz, 3601 Mhz, 4 Cores, 4 Logical Processors, 16 GB.
    
    \input{performancePlots.tex}
    
    \begin{table}[ht]   
        \begin{center}
            \begin{tabular}{ | c | c | c | c | c | c | c |  }
                \hline
                & \rotatebox[origin=c]{90}{Время}
                & \rotatebox[origin=c]{90}{Дескрипторы} &
                 \rotatebox[origin=c]{90}{Рёбра GSS} &
                  \rotatebox[origin=c]{90}{Узлы GSS} &
                  \rotatebox[origin=c]{90}{Узлы SPPF} &
                  \rotatebox[origin=c]{90}{Память, Мб} \\ \hline
                Фактор-ая &&&&&&\\ грамматика & 10 мин. 13 с.  & 1104116        & 1004882      & 902        & 195 млн. &  11818 \\ \hline 
                RA       & 5 мин. 51 с.  & 803281        & 603472      & 902        & 120 млн. & 8026  \\ \hline \hline
                Ratio   &  43$\%$       & 28$\%$     & 40 $\%$    &  0 $\%$ &  39 $\%$ &  33 $\%$ \\ \hline
            \end{tabular}
        \end{center}
        \caption{Результаты экспериментов для входа $a^{450}$}
        \label{expTable}
    \end{table}
    
    Результаты данных экспериментов поддерживают предположение о том, что на некоторых грамматиках 
    предложенный подход показывает результаты лучше, нежели анализатор, построенный для факторизованных грамматик.
    Для этой рекурсивного автомата анализатор создаёт меньше дескрипторов, чем для грамматики, так как 
    цепочки нетерминалов $K$ в альтернативах представлены единственным путём в автомате. Эта особенность ведёт к снижению количества 
    узлов SPPF и размера GSS.
    В среднем, с грамматикой $G_2$ версия с минимизированными автоматами работает на $43\%$ быстрее,
    использует на $28\%$ меньше дескрипторов, на $40\%$ меньше рёбер GSS, создаёт на $39\%$ меньше узлов SPPF
    и использует на $33\%$ меньше памяти.
    
    Было проведено экспериментальное сравнение реализации разработанного алгоритма GLL с
    существующим в проекте YaccConstructor (основан на оригинальном алгоритма Generalised LL). 
    Кроме того было проведено сравнение производительности алгоритма GLL для факторизованных грамматики, реализованного в 
    проекте YaccConstructor и описанного в данной 
    работе в задаче поиска 16s рРНК в метагеномной сборке. Длинные рёбка сборки были предварительно отфильтрованы с помощью
    инструмента Infernal. В результате фильтрации сборка разбивается на компоненты, которые можно анализировать независимо друг от
    друга. Тем не менее предложенный ранее алгоритм не позволяет обработать некоторые компоненты, поэтому сравнение проводилось
    на остальных: 10 компонент с 400-100 состояний и переходов и 1118 компонент с менее чем 100 состояний и переходов.
    Результаты сравнения приведены в таблице~\ref{expTable1} и показывают, что при работе с метагеномными сборками новый
    алгоритм, в среднем, использует на 65\% меньше памяти и работает на 45\% быстрее базового GLL. Сравнение с анализатором 
    для факторизованной грамматики показывает на 4\% меньшее использование памяти новым алгоритмом и на 10\% меньшее время работы.
    
    \begin{table}[h]
        \begin{center}
        \begin{tabular}{ | c | c | c | c | c | c |}
            \hline
            & &\multicolumn{2}{c|}{GSS} & & \\
            \cline{3-4}
                              & Деск-ры & Рёбра   & Узлы   & Память& Время   \\ \hline
            GLL               &  802млн &  414млн & 339млн  & 20Гб & 52 мин. 43 с.  \\ \hline
            Фактор-ая &&&&&\\
            грамматика        &  382млн &  187млн & 134млн & 7Гб & 29 мин. 27 с.  \\ \hline
            RA                &  362млн &  190млн & 134млн & 6,8Гб & 26 мин. 34 с.  \\ \hline %\hline
            %Ratio   &  9$\%$       & 13$\%$     & 12 $\%$    &  3 $\%$  & 14 $\%$\\ \hline
        \end{tabular}
        \caption{Результаты экспериментов с метагеномной сборкой}
        \label{expTable1}
        \end{center}
    \end{table}
	
	\section*{Заключение}
	В рамках данной работы была разработана и реализована модификация алгоритма GLL,
	работающая с расширенными контекстно-свободными грамматиками. Показано, что полученный
	алгоритм повышает производительность поиска структур заданных с помощью контекстно-свободной
	грамматики в метагеномных сборках. Более детально, были получены следующие результаты.
	\begin{itemize}
		\item В качестве подходящего представления ECFG выбраны рекурсивные конечные автоматы.
		\item Спроектирована структура данных для представления леса разбора для ECFG 
		на основе сжатого леса разбора (SPPF).
		\item Разработан алгоритм на основе Generalised LL, строящий лес разбора для ECFG.
		\item Алгоритм реализован в рамках проекта YaccConstructor. Исходный код доступен в
              репозитории YaccConstructor~\cite{YCUrl}, автор работал под учётной записью ``gorohovart''.
		\item Проведено экспериментальное сравнение реализованного алгоритма с алгоритмом для факторизованных грамматик,
         показавшее прирост на рассмотренных метагеномных сборках.
		\item Результаты работы успешно представлены на международной конференции
		``Tools and Methods of Program Analysis'' (Москва, 2017г.) в докладе ``Extended Context-Free Grammars Parsing with Generalized LL''
	\end{itemize}
	
	\setmonofont[Mapping=tex-text]{CMU Typewriter Text}
	\bibliographystyle{ugost2008ls}
	\bibliography{diploma}
	\input{appendix}
\end{document}

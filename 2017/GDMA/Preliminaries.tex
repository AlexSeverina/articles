\section{Preliminaries}

In this work we are focused on the parsing algorithm, and not on the data representation, and we assume that whole input graph can be located in RAM memory in the optimal for our algorithm way.

We start by introduction of necessary definitions.
\begin{itemize}
  \item Context-free grammar is a quadruple $G=(N, \Sigma, P, S)$, where $N$ is a set of nonterminal symbols, $\Sigma$ is a set of terminal symbols, $S \in N$ is a start nonterminal, and $P$ is a set of productions. 
  \item $\mathcal{L}(G)$ denotes a language specified by grammar $G$, and is a set of terminal strings derived from start nonterminal of $G$: $L(G) = \{\omega | S \Rightarrow_{G}^{*} \omega\}$.
  \item Directed graph is a triple $M = (V,E,L)$, where $V$ is a set of vertices, $L \subseteq \Sigma$ is a set of labels, and a set of edges $E\subseteq V\times L\times V$. 
  We assume that there are no parallel edges with equal labels: for every $e_1=(v_1,l_1,v_2) \in E, e_2=(u_1,l_2,u_2) \in E$ if $v_1 = u_1$ and $v_2 = u_2$ then $l_1 \neq l_2$.
  \item $tag: E \rightarrow L$ is a helper function which allows to get tag of edge. $$tag(e = (v_1,l,v_2), e \in E) = l$$
  \item $\oplus: L^+ \times L^+ \rightarrow L^+$ denotes a tag concatenation operation.
%  \item Path $p$ in graph $M$ is a list of incident edges: 
%  \begin{align*}
%   p &= e_0,e_1,\dots,e_{n-1} \\
%     &= (v_0,l_0,v_1),(v_1,l_1,v_2),\dots,(v_{n-1},l_{n-1},v_n)
%  \end{align*}
%  where $v_i \in V$, $e_i \in E$, $e_i=(v_i,l_i,v_{i+1})$, $l_i \in L$, $|p| = n, n \geq 1$. 
%  \item $P$  is a set of paths $\{p: p \text{ path in } M\}$, where $M$ is a directed graph.
%  \item $\Omega: P \rightarrow L^+$ is a helper function which constructs a string produced by the given path. For every $p \in P$
  \item $\Omega$ is a helper function which constructs a string produced by the given path. For every $p \text{ path in } M$
  \begin{align*}
  & \Omega(p = e_{0},e_{1},\dots,e_{n-1}) = \\
  & tag (e_{0}) \oplus \dots \oplus tag (e_{n-1}).
  \end{align*}
\end{itemize}

Using these definitions, we state the context-free language constrained path querying as, given a query in form of grammar $G$, to construct the set of paths $$Q(M,G)=\{p|p \text{ is path in } M, \Omega(p) \in \mathcal{L}(G)\}.$$

Note that, in some cases, $Q(M,G)$ can be an infinite set, and hence it cannot be represented explicitly. 
In order to solve this problem, in this paper, we construct compact data structure representation which stores all elements of $Q(M,G)$ in finite amount of space and allows to extract any of them.

\subsection{Generalized LL Parsing Algorithm}\label{BasicGLL}

One of widely used classes of parsing algorithms is a LL(k)~\cite{Grune}---top-down algorithms which read input from left to right, build leftmost derivation, and use $k$ symbols for lookahead.
LL(k) parser may be implemented as deterministic pushdown automaton (DPDA).
On the other hand LL(k) parser may be implemented in recursive-descent manner: each rule transforms to function which can call functions for other rules in order specified by right hand side of corresponded rule.
In this case stack of DPDA are replaced with functions call stack.

Classical LL algorithm operates with a pointer to input (position $i$) and with a grammar slot---pointer to grammar in form $N \rightarrow \alpha \cdot x \beta $.
Parsing may be described as a transition of these pointers from the initial position ($i = 0$, $S \rightarrow \cdot \beta $, where $S$ is start nonterminal) to the final ($i = input.Length$, $s \rightarrow \beta \cdot$).
At every step, there are four possible cases in processing of these pointers. 

\begin{enumerate}
\item $N \rightarrow \alpha \cdot x \beta $, when $x$ is a terminal and $x = input[i]$. In this case both pointers should be moved to the right ($i \leftarrow i + 1$, $N \rightarrow \alpha  x \cdot \beta $).
\item $N \rightarrow \alpha \cdot X \beta $, when $X$ is nonterminal. In this case we push return address $N \rightarrow \alpha X \cdot \beta $ to stack and move pointer in grammar to position $X \rightarrow \cdot \gamma$.\label{itm:2}
\item $N \rightarrow \alpha \cdot $. This case means that processing of nonterminal $N$ is finished. We should pop return address from stack and use it as new slot.\label{itm:3}
\item $S \rightarrow \alpha \cdot $, where $S$ is a start nonterminal of grammar. In this case we should report success if $i = input.Length - 1$ or failure otherwise. 
\end{enumerate}

In the second case there can be several slots $X \rightarrow \cdot \gamma$ due to the fact that this algorithm is nondeterministic, so a strategy on how to choose one of them to continue parsing is needed.
In LL(k) algorithm lookahead is used to avoid nondeterminism, but this strategy is still not good enough because there are context-free languages for which deterministic choice is impossible even for infinite lookahead~\cite{LLnonLL}.
On the contrary to LL(k), generalized LL does not choose at all, handling all possible variants by using descriptors mechanism.
Descriptor is a quadruple $(L, s, j, a)$ where $L$ is a grammar slot, $s$ is a stack node, $j$ is a position in the input string, and $a$ is a node of derivation tree.
Each descriptor fully describes one parser state, thus instead of immediate processing of all variants, GLL store all possible branches and process them sequentially late.

The stack in parsing process is used to store return information for the parser---a state to return for continue after finishing current state processing.
%name of function which will be called when current function finishes computation. 
As mentioned before, generalized parsers process all possible derivation branches and parser must store it's own stack for every branch. 
It leads to an infinite stack growth being done naively.  
Tomita-style graph structured stack (GSS)~\cite{Tomita} combines stacks resolving this problem.
Each GSS node contains a pair of position in input and a grammar slot in GLL. 

In order to provide termination and correctness, we should avoid duplication of descriptors, and be able to process GSS nodes in arbitrary order. It is necessary to use the following additional sets for this.
\begin{itemize}
\item $R$---working set which contains descriptors to be processed. Algorithm terminates whenever $R$ is empty.
\item $U$---all created descriptors. Each time when we want to add a new descriptor to $R$, we try to find it in this set first.
This way we process each descriptor only once which guarantee termination of parsing.
\item $P$---popped nodes. Allows to process descriptors (and GSS nodes) in arbitrary order. 
\end{itemize}

%Instead of explicit code generation used in classical algorithm, we use table version of GLL~\cite{TableGLL} in order to simplify adaptation to graph processing.
%As a result, main control function is different from the original one because it should process LL-like table instead of switching between generated parsing functions.
%Control functions of the table based GLL are presented in Algorithm~\ref{mainTblFunctions}.
%All other functions are the same as in the original algorithm and their descriptions can be found in the original article~\cite{scott2010gll}.

%\begin{algorithm}[ht]
%\begin{algorithmic}[1]
%\caption{Control functions of table version of GLL}
%\label{mainTblFunctions}
%\Function{dispatcher}{ \ }
%  \If{$R.Count \neq 0$}  
%      \State{$(L,v,i,cN) \gets R.Get()$}
%      \State{$cR \gets dummy$}
%      \State{$dispatch \gets false$}
%  \Else
%      \State{$stop \gets true$}
%  \EndIf
%\EndFunction
%
%\Function{processing}{ \ }
%  \State{$dispatch \gets true$}
%  \Switch{$L$}
%  \Case{$(X \rightarrow \alpha \cdot x \beta)$ where $x = input[i + 1])$}
%       \If{$cN = dummyAST$} 
%          \State{$cN \gets \Call{getNodeT}{i}$} 
%       \Else 
%          \State{$cR \gets \Call{getNodeT}{i}$}
%       \EndIf
%       \State{$i \gets i + 1$}
%       \State{$L \gets (X \rightarrow \alpha x \cdot \beta)$}
%       \If{$cR \neq dummy$}
%          \State{$cN \gets \Call{getNodeP}{L, cN, cR}$} 
%       \EndIf
%       \State{$dispatch \gets false$}        
%  \EndCase
%  \Case{$(X \rightarrow \alpha \cdot x \beta)$ where $x$ is nonterminal}
%       \State{$v \gets$ \Call{create}{$(X \rightarrow \alpha x \cdot \beta), v, i, cN$}}
%       \State{$slots \gets pTable[x][input[i]]$}
%       \ForAll{$L \in slots$}
%          \State{\Call{add}{$L,v,i,dummy$}} 
%       \EndFor
%  \EndCase
%  \Case{$(X \rightarrow \alpha \cdot )$}
%       \State{\Call{pop}{v,i,cN}} 
%  \EndCase
%  \Case{$(S \rightarrow \alpha \cdot )$ when $S$ is start nonterminal}
%       \State{final result processing and error notification} 
%  \EndCase
%  \EndSwitch
%\EndFunction
%
%\Function{control}{}
%  \While{not $stop$}  
%      \If{$dispatch$}
%        \State{\Call{dispatcher}{ \ }}
%      \Else
%         \State{\Call{processing}{ \ }}
%      \EndIf
%  \EndWhile
%\EndFunction
%
%\end{algorithmic}
%\end{algorithm}

There can be more than one derivation tree of a string with relation to ambiguous grammar.
Generalized LL build all such trees and compact them in a special data structure Shared Packed Parse Forest~\cite{SPPF}, which will be described in the following section.

\subsection{Shared Packed Parse Forest}

Binarized Shared Packed Parse Forest (SPPF)~\cite{brnglr} compresses derivation trees optimally reusing common nodes and subtrees.
Version of GLL which uses this structure for parsing forest representation achieves worst-case cubic space complexity~\cite{gllParsingTree}.

Binarized SPPF can be represented as a graph in which each node has one of four types described below.
Let $i$ and $j$ be the start and the end positions of substring, and let us call a tuple $(i,j)$ an \textit{extension} of node.

\begin{itemize}
    \item \textbf{Terminal node} with label $(i, T, j)$.
    \item \textbf{Nonterminal node} with label $(i, N, j)$. 
    This node denotes that there is at least one derivation for substring $\alpha=\omega[i..j-1]$ such that $N \Rightarrow^*_G \alpha, \alpha = \omega[i..j-1] $.
    All derivation trees for the given substring and nonterminal can be extracted from SPPF by left-to-right top-down graph traversal started from respective node.     
    \item \textbf{Intermediate node}: a special kind of node used for binarization of SPPF. These nodes are labeled with $(i,t,j)$, where $t$ is a grammar slot.
    \item \textbf{Packed node} with label $(N \rightarrow \alpha \cdot \beta, k)$. 
    Subgraph with ``root'' in such node is one variant of derivation from nonterminal $N$ in case when the parent is a nonterminal node labeled with $(<\mkern-9mu | \mkern-9mu> (i, N, j))$.

\end{itemize}

Example of SPPF presented in figure~\ref{SPPF}. We remove redundant intermediate and packed nodes from the SPPF to simplify it and to decrease the size of structure.

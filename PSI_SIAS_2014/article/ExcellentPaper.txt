\documentclass{mais}
\usepackage{mathtext}
\usepackage[T2A]{fontenc}
\usepackage[cp1251]{inputenc}
\usepackage[english,russian]{babel}
\usepackage{cmap}
\usepackage[mag=1000,a4paper,left=2.2cm,right=3.0cm,top=3.0cm,bottom=3.0cm]{geometry} % ,noheadfoot
\usepackage{graphicx}
\usepackage{amsfonts,amssymb,amscd,amsmath,amsthm}
\usepackage{mathrsfs}
\usepackage{epsf}
\usepackage{wrapfig}
\usepackage{cite}
\usepackage{graphicx}
\usepackage{epstopdf}
\usepackage{hyperref}



%% поля, заполняемые редакцией

\date{20 декабря}\ydate{2012}%дата получения
\firstpage{5}%начальная страница статьи

%% поля, заполняемые автором

\title{Инструментальная поддержка встроенных языков в интегрированных средах разработки}

\author{Григорьев~С.\,В., Вербицкая~Е.\,А., Полубелова~М.\,И., Иванов~А.\,В., Мавчун~Е.\,В.}%Фамилия И.О. автора, ссылки на поддержку

\authorcr{Григорьев~С.\,В., Вербицкая~Е.\,А., Полубелова~М.\,И., Иванов~А.\,В., Мавчун~Е.\,В.} %Фамилия И.О. автора для строки с авторским знаком

\UDC{004.4'232} %Номер УДК
\shorttitle{Инструментальная поддержка встроенных языков в IDE}
\entitle{IDE Support of String-Embedded Languages}%Название статьи на английском языке. Каждое значимое слово пишется с большой буквы
\enauthor{Grigorev~S., Verbitskaia~E., Polubelova~M., Ivanov~A., Mavchun~E.}

\affiliationen {\small Saint Petersburg State University, Universitetsky prospekt, 28, Saint Petersburg, 198504, Russia}

\affiliation{\small Cанкт-Петербургский государственный университет\\198504 Россия, г. Санкт-Петербург, г. Старый Петергоф,\\ Университетский проспект, 28}

%указывается официальное название места работы и официальный почтовый адрес

%%%%% места работы двух и более авторов разделяются знаком "\\ "

\email{\{rsdpisuy,kajigor,polubelovam,ivanovandrew2004,emavchun\}@gmail.com}

%информация об авторах
\authorinform{\\{\textbf{Григорьев Семен Вячеславович}}, \\Cанкт-Петербургский государственный университет,\\магистр информационных технологий
\\{\textbf{Вербицкая Екатерина Андреевна}}, \\Cанкт-Петербургский государственный университет,\\студент
\\{\textbf{Полубелова Марина Игоревна}}, \\Cанкт-Петербургский государственный университет,\\студент
\\{\textbf{Иванов Анрей Васильевич}}, \\Cанкт-Петербургский государственный университет,\\бакалавр информационных технологий
\\{\textbf{Мавчун Екатерина Валерьевна}}, \\Cанкт-Петербургский государственный университет,\\студент}

\keywords{встроенные языки, абстрактный синтаксический анализ, генератор парсеров, генератор лексических анализаторов, интегрированная среда разработки, динамический SQL}
\enkeywords{string-embedded language, abstract parsing, parser generator, lexer generator, integrated development environment, IDE, dynamic SQL}

\enabstract{
Complex information systems are often implemented using more than one programming language. Sometimes this variety takes form of one host and one or few string-embedded languages. Textual representation of clauses in a string-embedded language is built at run time by a host program and then analyzed, compiled or interpreted by a dedicated runtime component (database, web browser etc.) Most general-purpose programming languages may play role of the host; one of the most evident examples of string-embedded language is dynamic SQL which was specified in ISO SQL standard and is supported by the majority of DBMS. Standard IDE functionality such as code completion or syntax highlighting can really helps developers who use this technique. There are several tools providing this functionality, but they all process only one concrete string-embedded language and cannot be easily extended for supporting other language. We present a platform which allows to easily create tools for string-embedded language processing. We also demonstrate a plug-in for ReSharper based on this platform which provides code highlighting and static errors checking for string-embedded languages in C\# (TSQL, JSON). }

\begin{document}

\maketitle

\begin{abstract}
Часто при разработке сложных программных систем используется более, чем один язык программирования. В таком случае принято говорить об основном (или исходном) языке и одном или нескольких встроенных языках. Из строковых выражений основного языка динамически формируются программы на отличном от него языке, которые потом интерпретируются специальными, работающими во время исполнения компонентами, такими как базы данных или веб-браузеры. Большинство языков программирования общего назначения могут играть роль как основного, так и встроенного языка. Самый яркий пример реализации такого подхода --- динамический SQL, специфицированный в стандарте ISO SQL и поддерживаемый большинством СУБД.

Автодополнение и подсветка синтаксиса --- стандартная для интерактивных сред разработки функциональность --- значительно упрощает процесс разработки с использованием встроенных языков. Существует несколько инструментов, предоставляющих функциональность интегрированных сред разработки для встроенных языков, но они в основном поддерживают только один конкретный встроенный язык и поддержка другого языка требует нетривиального ручного вмешатесльства. Мы разработываем платформу, позволяющую создавать инструменты для статического анализа динамически формируемых выражений. Мы также продемонстрируем плагин к ReSharper, осуществляющий подсветку синтаксиса и обнаружение ошибок для встроенных в C\# SQL и JSON, созданный с помощью этой платформы.
\end{abstract}


\section*{Введение}
Часто при разработке сложных программных систем используется более, чем один язык программирования. В таком случае принято говорить об основном (или исходном) языке и одном или нескольких встроенных языках. Из строковых выражений основного языка динамически формируются программы на отличном от него языке, которые потом интерпретируются специальными, работающими во время исполнения компонентами, такими как базы данных или веб-браузеры. Большинство языков программирования общего назначения могут играть роль как основного, так и встроенного языка. Ниже приведены примеры использования встроенных языков. 

Вызов JavaScript из Java: 
\begin{verbatim}
import javax.script.*;  
public class InvokeScriptFunction {  
    public static void main(String[] args) throws Exception {  
        ScriptEngineManager manager = new ScriptEngineManager();  
        ScriptEngine engine = manager.getEngineByName("JavaScript");  
        // JavaScript code in a String  
        String script = 
        	"function hello(name) { print('Hello, ' + name); }";  
        // evaluate script  
        engine.eval(script);  
        // javax.script.Invocable is an optional interface.  
        // Check whether your script engine implements or not!  
        // Note that the JavaScript engine implements Invocable interface.  
        Invocable inv = (Invocable) engine;  
        // invoke the global function named "hello"  
        inv.invokeFunction("hello", "Scripting!!" );  
    }  
}
\end{verbatim}

Код с использованием динамического SQL:

\begin{verbatim}
CREATE PROCEDURE [dbo].[MyProc]  @TABLERes   VarChar(30)
AS
    EXECUTE ('INSERT INTO ' + @TABLERes + ' (sText1)' +
    ' SELECT ''Additional condition: '' + sName' +
    ' from #tt where sAction = ''1000000''')
GO
\end{verbatim}

Использование нескольких встроенных в PHP языков (MySQL, HTML) 

\begin{verbatim}
<?php
    $query = 'SELECT * FROM '. $my_table; // Embedded SQL
    $result = mysql_query($query);
    
    // HTML markup generation
    echo "<table>\n";
    while ($line = mysql_fetch_array($result, MYSQL_ASSOC)) {
        echo "\t<tr>\n";	
        foreach ($line as $col_value) {
            echo "\t\t<td>$col_value</td>\n";
        }
        echo "\t</tr>\n";
    }
    echo "</table>\n";
?>
\end{verbatim}

Встроенные языки позволяют компенсировать недостаток выразительности языков общего назначения в случае использования их в контексте специфичном для предметной области. Однако использование такого подхода сопряжено с рядом трудностей. Динамически формируемые выражения обычно конструируются из строковых констант и выражений основного языка посредством конкатенации в циклах, ветках условных операторов или рекурсивных процедурах, причем эти структуры могут вкладываться друг в друга, что порождает множество различных вариантов. Фрагменты кода на встроенных языках воспринимаются компилятором исходного языка как простые строки, не подлежащие анализу. Таким образом, стандартные средства не позволяют проводить даже простой синтаксический анализ динамически формируемых выражений. Невозможность статической проверки корректности формируемого выражения приводит к высокой вероятности возникновения ошибок во время выполнения программы.

Распространенной практикой при написании кода является использование интегрированных сред разработки, производящих подсветку синтаксиса и автодополнение, сигнализирующих о синтаксических ошибках, предоставляющих возможность проводить рефакторинг кода. Все эти функции значительно упрощают процесс разработки и отладки приложений. Полезными могут оказаться инструменты, проводящие статический анализ множества выражений, которые динамически формируются из строковых выражений основного языка во время выполнения программы. Данный процесс назовем {\it статическим анализом динамически формируемых выражений} или {\it абстрактным анализом}.

В рамках исследовательского проекта YaccConstructor~\cite{Kirilenko}, посвященного проведению экспериментов в области синтаксического анализа, ведется работа над платформой для создания инструментов, предназначенных для статического анализа кода на встроенных языках. В данной статье описаны разрабатываемая инфраструктура поддержки встроенных языков и ее компоненты: генераторы абстрактных лексических и синтаксических анализаторов. Также уделено внимание поддержке многих языков и приведен пример использования платформы для создания плагина к ReSharper~\footnote{Сайт проекта ReSharper:~\url{http://www.jetbrains.com/resharper}} (плагин к Microsoft Visual Studio~\footnote{Сайт проекта Microsoft Visual Studio: ~\url{http://www.visualstudio.com}}, расширяющий стандартные средства IDE), позволяющего анализировать динамически формируемые выражения.

\section{Платформа}
Многие редакторы и IDE используются для различных языков программирования. Чтобы дать возможность обрабатывать разные встроенные языки, которые на данном этапе не поддерживаются редактором или IDE, необходимо иметь соответствующую функциональность. Для этого используются модули, реализующие поддержку встроенных языков, ниже будем называть это {\it языковыми расширениями}. Возможность IDE поддерживать разные встроенные языки может быть полезна не только пользователям, желающим получить поддержку встроенного языка, но и разработчикам для создания новых языковых расширений.

Существующие инструменты для работы со встроенными языками реализуют поддержку какого-то одного конкретного языка или поддержка нового языка может потребовать нетривиального ручного вмешательства. Чтобы получить поддержку встроенного языка без изменений в исходном коде, необходимо, с одной стороны, предоставить механизм для простой реализации поддержки нового языка и интеграции его в систему, а с другой --- дать пользователю возможность указывать в исходном коде строки, соответствующие конкретным встроенным языкам.

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.6]{picture/Structure_of_platform}
    \end{center}
    \caption{Структура платформы}
    \label{moduleDepence}
\end{figure} 

На рисунке~\ref{moduleDepence} представлена общая структура платформы, основные модули которой описаны ниже.

{\bf Lang1, Lang2, ..., LangN} --- модули, реализующие поддержку встроенных языков. Каждый из таких модулей реализует общий интерфейс, позволяющий унифицировано подключать поддержку нового языка. Для создания нового языкового расширения разработчику необходимо установить плагин для ReSharper, описать грамматику и лексическую спецификацию языка, по этим файлам генерируется лексер и парсер. В результате разработчик получает модуль, позволяющий поддерживать новый встроенный язык.

SDK предоставляет разработчику набор инструментов и готовых функций (набор генераторов, функции синтаксического анализа), упрощающих разработку нового языкового расширения. Кроме того, он содержит интерфейс для парсеров {\bf IInjectedLanguageModule} и атрибут {\bf InjectedLanguage}, который даёт пользователю возможность указывать в коде программы встроенный язык для строковых выражений. Атрибут {\bf InjectedLanguage} содержит поле {\bf languageName} типа {\bf String} ({\bf languageName}~---~название встроенного языка). По значению поля {\bf languageName} происходит поиск языкового расширения, соответствующего языку, название которого пользователь указал в атрибуте. Если языковое расширение для указанного пользователем языка не было подключено, то пользователь получит сообщение об ошибке.

Данный атрибут может быть применён к объявлениям методов. Если же используется стандартный метод, то необходимо указать его в отдельном конфигурационном файле. Например, если реализуется собственный метод для выполнения Transact SQL запросов, то для того, чтобы проверять корректность принимаемого запроса, он должен быть отмечен атрибутом как показано в примере ниже.

\begin{verbatim}
[InjectedLanguage (“TSQL”)]
public static void ExecuteImmediate(string query)
{
    Logger.log(query);
    DB.execute(query);
}
\end{verbatim}

Если предположить, что \verb|DB.execute| --- это библиотечный метод и мы не можем отметить его объявление, то необходимо добавить его в конфигурационный  файл разрабатываемого инструмента.

Для простоты использования готового инструмента необходимо иметь возможность динамически загружать языковое расширение для поддержки нового встроенного языка. Динамическая загрузка осуществляется с помощью средства для создания расширяемых приложений Mono.Addins.

\subsection{Анализ встроенных языков}
Для синтаксического анализа обобщённого представления множества строк, таких как data-flow уравнение, регулярное выражение, существует алгоритм абстрактного синтаксического анализа~\cite{Doh}. Часто удобно считать, что компактное представление описывается с помощью графа, где на дугах содержатся терминальные символы (токены), а вершины соответствуют случаям конкатенации строк в процессе формирования запроса. Например, пусть обрабатывается следующий код, формирующий и выполняющий динамический запрос.

\begin{verbatim}
IF @X = @Y
    SET @TABLE = '#tbl1'
ELSE
    SET @TABLE = 'tbl2'
SET @S = 'SELECT x FROM ' + @TABLE
EXECUTE (@S)
\end{verbatim}

Переменная \verb|@S|, содержащая динамически формируемый запрос, может принимать два значения в точке выполнения запроса. После обработки этого кода множество значений переменной \verb|@S| в точке выполнения может быть представлено графом, показанным на рисунке~\ref{codeEx}. 

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.95]{picture/SimpleSql.eps}
    \end{center}
    \caption{Входной граф для лексического анализатора, построенный по коду из примера 1}
    \label{codeEx}
\end{figure}

Граф, полученный в результате применения к нему процедуры {\it токенизации} или {\it абстрактного лексического анализа}, показан на рисунке~\ref{codeExGraph}.

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.65]{picture/simple_sql.eps}
    \end{center}
    \caption{Граф для динамического запроса из примера}
    \label{codeExGraph}
\end{figure}

Следующий шаг  --- {\it абстрактный синтаксический анализ}, который основан на идее переиспользования управляющих конструкций из классического синтаксического анализа и реализации специального механизма их интерпретации. По описанию синтаксиса анализируемого языка генерируются управляющие таблицы для анализатора. Интерпретатор таблиц (LR-автомат) при этом модифицируется таким образом, чтобы вычислять все возможные состояния синтаксического анализатора для каждой вершины графа~\cite{Breslav}. 

Рассмотрим пример. Пусть задана следующая грамматика:

\begin{verbatim}
s -> Ae
e -> BD | CD
\end{verbatim}

На вход построенному по данной грамматике анализатору подаётся граф, представленный на рисунке~\ref{inputExGraph}.

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.9]{picture/simple_grammar_inpt.eps}
    \end{center}
    \caption{Пример входного графа}
    \label{inputExGraph}
\end{figure}

Во время синтаксического анализа будет вычислено множество состояний анализатора в каждой вершине графа (см. рисунок~\ref{StateInputExGraph}).

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.9]{picture/simple_grammar_items.eps}
    \end{center}
    \caption{Состояния парсера для графа, представленного на рисунке~\ref{inputExGraph}}
    \label{StateInputExGraph}
\end{figure}

Несмотря на то, что уже существуют реализации инструментов для работы с динамически формируемыми выражениями в конкретных языках, хорошо показавшие себя на практике (например, Java String Analyzer~\footnote{Сайт проекта Java String Analyzer:~\url{http://www.brics.dk/JSA}}, Alvor~\footnote{Сайт проекта Alvor~\url{http://code.google.com/p/alvor}} или PHP String Analyzer~\footnote{Сайт проекта PHP String Analyzer~\url{http://www.score.is.tsukuba.ac.jp/~minamide/phpsa}}), отдельного внимания заслуживает вопрос обобщения лексического анализа и синтаксического разбора, используемых в таких инструментах, с целью создания генератора абстрактных анализаторов.  Кроме того, при промышленной разработке инструментов лексического и синтаксического анализа для языков программирования уже стали традиционными инструменты, позволяющие автоматически генерировать соответствующие анализаторы по спецификациям обрабатываемого языка. В области автоматизации разработки подобных инструментов для абстрактного анализа также получены результаты~\cite{Abstract_lexer}, но они требуют доработки.

\subsection{Генератор лексических анализаторов}
Генератор лексических анализаторов --- это инструмент для получения лексического анализатора по лексической спецификации обрабатываемого языка. Абстрактный лексический анализатор, как и классический,  основан на конечном преобразователе (finite-state transducer~\cite{Mohri}). Это конечный автомат, который может выводить конечное число символов для каждого входного символа. В качестве основы нашего инструмента мы используем генератор лексических анализаторов для F\# --- FsLex. По сгенерированному описанию автомата преобразователь переводит входной граф в граф, содержащий соответствующие спецификации токены.  

В отличие от классического анализа в абстрактном лексическом анализе бывают ситуации с “рваными” лексическими единицами, то есть случаи, когда токен находился на двух и более ребрах входного графа. Назовем такие токены {\it разрывными литералами}. В качестве примера рассмотрим код на C\#, который содержит динамически формируемый запрос, написанный на T-SQL.  Разрывный литерал был сконструирован при помощи тернарного оператора. 

\begin{verbatim}
private void Go(bool cond)
{
    string name_table = cond ? "1" : "2";
    Program.ExecuteImmediate("select fld from tbl_" + name_table);
}
\end{verbatim}

Результатом аппроксимации динамического запроса является граф, который подается на вход лексическому анализатору и который представлен на рисунке~\ref{InputGraph}

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.85]{picture/lexer_ex.eps}
    \end{center}
    \caption{Результат аппроксимации динамического запроса в примере 1}
    \label{InputGraph}
\end{figure} 

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.45]{picture/lexer_ex_tok.eps}
    \end{center}
    \caption{Результат лексического анализа для графа, представленного на рисунке~\ref{InputGraph}}
    \label{LexerGraph}
\end{figure}

Результат работы токенизатора показан на рисунке~\ref{LexerGraph}. На этом рисунке также можно увидеть структуру {\bf backreference}(или {\bf br}). Эта структура хранит для каждого токена строки исходного кода из которых он образован, а также  координаты начала и конца токена внутри этих строк. Сохраненная привязка может понадобится при дальнейшем разборе полученного графа и при выдаче сообщений о лексических ошибках. 

\subsection{Генератор синтаксических анализаторов}

В рамках проекта YaccConstructor реализован генератор  синтаксических анализаторов~\cite{Kirilenko}, основанный на RNGLR-алгоритме~\cite{Scott}, который является модификацией классического GLR-алгоритма, поддерживающей работу с произвольными КС-грамматиками. Важной особенностью данной реализации является построение легковесного внутреннего представления результатов,  над которым после завершения разбора выполняется вычисление пользовательской семантики. Это позволяет не производить лишних вычислений. Например, после получения промежуточного результата пользователь может выбрать только одно дерево и вычислять семантику только для него. Кроме этого, часть вычислений может оказаться ненужными, если они производились в ветке стека, которая впоследствии окажется ошибочной. Поэтому  использование данной  структуры позволяет ускорить абстрактный анализ. 

При обработке графов в RNGLR-алгоритме в момент разветвления возникает ситуация, аналогичная классическим конфликтам {\bf Shift/Reduce} и {\bf Reduce/Reduce}, когда необходимо выполнять анализ по нескольким путям. В данном случае необходимость ветвления вызвана тем, что существует несколько вариантов для операции {\bf Shift}.  Ситуация не является классическим конфликтом, но по аналогии мы будем называть такие ситуации {\bf Shift/Shift} конфликтами. В алгоритм анализа внесена возможность обработки таких ситуаций. 

\subsubsection{Обнаружение ошибок и восстановление после них}

В случае классического синтаксического анализа с линейным входом, если не производится восстановление после ошибок, результатом анализа всегда является либо корректное дерево разбора, либо ошибка. В абстрактном синтаксическом анализе это не так: анализируется целое множество входных выражений, каждое из которых представляет собой некоторый путь во входном графе, и необходимо сообщать не только о первой найденной на каком-либо пути ошибке, но о первой ошибке на каждом пути. Для выполнения этого требования необходимо возвращать целый список ошибок. С другой стороны, не все выражения из входного множества обязательно содержат ошибку. Поэтому наряду со списком ошибок, если они были обнаружены в результате анализа, необходимо возвращать успешный результат разбора. Алгоритм абстрактного синтаксического анализа был изменен так, чтобы возвращать и компактное представление леса разбора(SPPF), и список ошибок. Стоит отметить, что вне зависимости от количества корректных выражений во входном множестве, всегда будет возвращено лишь одно SPPF.

GLR-алгоритмы предназначены для анализа неоднозначных грамматик и оперируют со структурированным в виде графа стеком, который разветвляется при возникновении конфликтов. Набор верхушек стека, из которых возможно продолжить анализ, называют {\it фронтом}. Если в процессе работы классического GLR-анализатора для некоторого состояния, лежащего на верхушке стека, невозможно сделать ни одного действия, то соответствующую ветку стека считают ошибочной и исключают из фронта. В классическом GLR-алгоритме анализа ошибка диагностируется в момент, когда во фронте не остается ни одной верхушки стека. Для абстрактного синтаксического анализатора такой подход верен не всегда. Ветви стека в абстрактном анализе соответствуют не только неоднозначностям грамматики, но и ветвлениям во входном графе, поэтому данная ситуация может сигнализировать об ошибке в одном из входных выражений. В случае обнаружения ошибки на некотором токене необходимо прекратить разбор тех выражений, которые содержали этот токен, чтобы не порождать ложных сообщений об ошибках. Алгоритм абстрактного синтаксического анализа обрабатывает входной граф, представленный списком вершин, отсортированным в топологическом порядке~\cite{Grigorev}. Эта особенность немного усложняет механизм игнорирования ошибочных путей. В тот момент, когда алгоритм обнаружил ошибку во входе, происходит вычисление игнорируемого интервала вершин. Если есть отложенные операции {\bf push}, то следующей вершиной, из которой должен быть продолжен анализ, является вершина с номером равным минимуму из номеров отложенных операций {\bf push}. Если же отложенных операций {\bf push} нет, то рассматриваем все вершины стеков, сравниваем номера уровней, на которые последует переход, берем минимальное из этих значений и продолжаем анализ из вершины с вычисленным номером. Такой подход позволяет пропустить только те части путей в графе, которые гарантированно не будут переиспользованы ни в одном корректном выражении.

Стоит отметить, что область диагностики ошибок и восстановления после них в GLR-алгоритмах синтаксического анализа плохо изучена~\cite{GLR}. Конфликты, возникающие при разборе, усложняют задачу точной диагностики ошибок. Добавив конфликт {\bf Shift/Shift}, мы еще больше усложнили эту задачу: появилась необходимость различать ошибки, полученные в результате выбора неправильной альтернативы во время классических конфликтов и ошибки, полученные в результате {\bf Shift/Shift} конфликта. Ситуация окажется намного сложнее при наличии разнородных конфликтов: если грамматика анализируемого языка неоднозначна, и входной граф при этом содержит множество ветвлений. В данной ситуации вероятно обнаружение большого количества ошибок, при этом не ясно, какие из срабатываний действительно соответствуют ошибкам во входных выражениях, а какие являются ложными и возникли вследствие неоднозначности грамматики.

В рамках платформы был реализован механизм восстановления после ошибок для классического RNGLR-алгоритма~\cite{Ivanov}. Однако вопрос о необходимости восстановления после ошибок в абстрактном анализе необходимо исследовать отдельно, так как  он может порождать слишком большое количество ложных ошибок для сложных выражений. Также необходимо оценить уменьшение производительности и выявить проблемы, связанные с переходом к абстрактному анализу. 

\subsubsection{Особенности вычисления семантики}
Для обеспечения такой функциональности, как подсветка и автодополнение, не достаточно только лишь информации о синтаксической корректности выражений. Необходима также работа с семантическими значениями языковых конструкций. При этом далеко не всегда нужно рассматривать все деревья разбора. При подсветке синтаксиса, например,  достаточно выбрать из леса разбора подмножество корректных деревьев таким образом, чтобы множество всех токенов (листьев) было покрыто. То есть, чтобы для каждого токена существовало дерево из выбранного подмножества, которое содержит этот токен. Действительно, если у двух разных деревьев листья совпадают, то при подсветке синтаксиса не так важно, какому именно дереву принадлежит тот или иной лист. Важно, что это дерево синтаксически корректно.

Рассмотрим пример:

\begin{verbatim}
expr: (expr PLUS expr) | NUM
\end{verbatim}

\begin{figure}[h!]
    \begin{center}
        \includegraphics[scale=0.75]{picture/shiftreduce.eps}
    \end{center}
    \caption{Граф, содержащий Shift/Shift конфликт}
    \label{Conflict}
\end{figure}

Для графа, представленного на рисунке~\ref{Conflict}, в результате синтаксического разбора будет построено четыре дерева разбора: для каждого пути будет построено по два дерева из-за неоднозначности грамматики. Однако порождённые конфликтом {\bf Shift/Reduce} или {\bf Reduce/Reduce}~деревья соответствуют одному и тому же пути в графе, а значит, множества их листьев совпадают. Поэтому при поддержке подсветки синтаксиса для каждого пути в графе достаточно рассмотреть только одно из таких деревьев. Наиболее сложной для реализации поддержки языков является ситуация, соответствующая ветвлению во входном графе, так как в худшем случае придётся рассматривать все возможные деревья разбора.

В рамках проекта создан генератор, который создаёт семантику для подсветки синтаксиса языка. Также он генерирует конфигурационный файл, в котором пользователь может указать, в какой цвет окрашивать ту или иную языковую конструкцию. 

\section{Дальнейшее развитие}

В дальнейшем планируется как развитие платформы, так и плагина. На уровне платформы необходимо реализовать механизмы, требующиеся для трансформаций кода на встроенных языках. Механизмы трансформации встроенных языков требуются для проведения миграции с одной СУБД на другую~\cite{Syrcose} или для миграции на новые технологии, например, LINQ. Эта задача связана с двумя проблемами: возможностью проведения нетривиальных трансформаций (могут потребоваться некоторые специфичные подходы~\cite{Terekhov,Boulychev}) и доказательство корректности трансформаций. Планируется реализация проверки корректности типов. Для SQL это должна быть как проверка типов внутри запроса, так и проверка того, что тип возвращаемого запросом результата соответствует типу хост-переменной, выделенной для сохранения результата в основном коде.

{\small
\begin{thebibliography}{99}%Пример оформления списка литературы. Для публикаций на русском языке в скобках приводится вариант на англ. языке, если есть (см. Пример 4) или транслитерация (см. Пример 5).

\bibitem{Kirilenko} \emph{Кириленко Я.А., Григорьев С. В.,Авдюхин Д. А.} Разработка синтаксических анализаторов в проектах по автоматизированному реинжинирингу информационных систем.//Научно-технические ведомости СПбГПУ информатика, телекоммуникации, управление.~---~2013.~---~№174.~---~С.~94--98. (English transl.:  \textit{ Kirilenko Ya.A., Grigorev S. V.,Avdyukhin D. A.} Razrabotka sintaksicheskikh analizatorov v proektakh po avtomatizirovannomu reinzhiniringu informatsionnykh sistem.//Nauchno-tekhnicheskie vedomosti SPbGPU informatika, telekommunikatsii, upravlenie.~---~2013.~---~174.~---~P.~94--98)

\bibitem{Doh} \emph{Kyung-Goo Doh, Hyunha Kim, and David A. Schmidt} Abstract parsing: Static analysis of dynamically generated string output using lr-parsing technology.// In Proceedings of the 16th International Symposium on Static Analysis, SAS ’09.~---~Springer-Verlag: Berlin; Heidelberg.~---~2009.~---~ P.~256–-272.

\bibitem{Breslav} \emph{Aivar Annamaa, Andrey Breslav, and Varmo Vene} Using abstract lexical analysis and parsing to detect errors in string-embedded dsl statements.// In Marina Walden and Luigia Petre, editors, Proceedings of the 22nd Nordic Workshop on Programming Theory.

\bibitem{Mohri} \emph{Mohri Mehryar} Finite-State Transducers in Language and Speech Processing. // Association for Computational Linguistics.~---~1997.~---~http://www.cs.nyu.edu/mohri/pub/cl1.pdf

\bibitem{Ivanov} \emph{Иванов А.В.} Восстановление после ошибок в GLR-алгоритме.// Курсовая работа.~---~ СПбГУ.~---~2013. (English transl.: \textit{Ivanov A.V.} Vosstanovlenie posle oshibok v GLR-algoritme.// Kursovaya rabota.~---~ SPbGU.~---~2013.)

\bibitem{Abstract_lexer} \emph{Вербицкая E.A., Григорьев С.В.} Абстрактный лексический анализ. // СПИСОК-2013: Материалы всероссийской научной конференции по проблемам информатики.~---~23–26~апр.~2013 г., Санкт-Петербург.~---~СПб.: Издательство ВВМ.~---~2013.~---~C.~792. (English transl.: \textit{Verbitskaya E.A., Grigorev S.V.} Abstraktnyy leksicheskiy analiz. // SPISOK-2013: Materialy vserossiyskoy nauchnoy konferentsii po problemam informatiki.~---~23–26~apr.~2013, Sankt-Peterburg.~---~SPb.: Izdatelstvo VVM.~---~2013.~---~P.~792)

\bibitem{Scott} \emph{Elizabeth Scott and Adrian Johnstone} Right nulled GLR parsers.// ACM Trans. Program. Lang.~---~Syst. 28, 4 (July 2006)~---~P.~577--618.

\bibitem{Grigorev} \emph{Semen Grigorev and Iakov Kirilenko} GLR-based abstract parsing.// In Proceedings of the 9th Central \& Eastern European Software Engineering Conference in Russia (CEE-SECR~'13).~---~York, NY, USA.~---~Article 5.~---~9 pages.

\bibitem{GLR} \emph{Giorgios Robert Economopoulos} Generalised LR parsing algorithms.~---~2006.

\bibitem{Terekhov} \emph{Andrey Terekhov} Good technology makes the difficult task easy.// In Proceedings of the 2013 9th Joint Meeting on Foundations of Software Engineering (ESEC/FSE 2013).~---~ACM, New York, NY, USA.~---~P.683-–686.

\bibitem{Boulychev} \emph{D. Yu. Boulychev, D. V. Koznov, and Andrey A. Terekhov} On Project-Specific Languages and Their Application in Reengineering.// In Proceedings of the 6th European Conference on Software Maintenance and Reengineering (CSMR ’02).~---~IEEE Computer Society, Washington, DC, USA.~---~p. 177–-185.

\bibitem{Syrcose} \emph{Semen Grigorev and Iakov Kirilenko} From Abstract Parsing to Abstract Translation.// In Preliminary Proceedings of the 8th Spring/Summer Young Researchers Colloquium on Software Engineering.~---~2014~---~P.135--139. 



\end{thebibliography}}

\medskip

\end{document}
1) Hi! My name is Semyon and I show you that partial evaluation can optimize GPU procedures.

2) In case of big data analysis, we often split data into chunks to fit in memory and as a result, we have many runs of the single procedure with some parameters are fixed during all runs. 
So, the question is can we utilize this fact to optimize memory access pattern and memory traffic?

3) Yes, we can do it by using partial evaluation.
The partial evaluator or mix is a procedure which can generates a new optimized procedure for the given procedure and its fixed parameters as shown in this slide.
The main difference between the original procedure and the specialized one is that the loop is unrolled and values from the array are inlined.

4) We evaluate this approach by using AnyDSL framework for specialization.
Two algorithms are implemented and evaluated on GTX and Tesla GPUs

5) The first case is the substring matching. Here we can see that the partially evaluated version is significantly faster than manually created versions with different locations of patterns.

6) The next case is a convolution. Here we can see that the effect of specialization depends on GPU architecture and this case should be analyzed in the future.

7) Also, in the future, we plan to migrate to CUDA C partial evaluator,
to reduce specialization overhead, to use advanced register spilling technique and to evaluate our approach on real-world cases.

8) That's all. Thank you for attention.
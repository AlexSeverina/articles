1) Hi! My name is Semyon and I show you that partial evaluation can optimize GPU procedures.

2) One of the areas of GPU utilization is a big data analysis. Suppose generic procedure which takes data and some parameters for the filter. Say patterns or weights of the convolution filter.
In the case of big data processing, we split data and as a result, we have many procedure runs. But filter parameters are fixed during all these runs. 
Can we utilize this fact to optimize our procedure?

3) Yes, we can do it by using partial evaluation. 
The partial evaluator or mix is a procedure which can generates a new optimized procedure for the given procedure and its fixed parameters.

Suppose we have this procedure and fix the filter to be an array of two elements. 
The result of specialization is this procedure.
The main difference is that the loop is unrolled and values from the array are inlined.

4) We evaluate this approach by using AnyDSL for specialization.
Two simple algorithms are implemented and evaluated on GTX and Tesla GPUs

5) The first case is the substring matching. Here we can see that the partially evaluated version is significantly faster than manually created versions with different locations of patterns.

6) The next case is a convolution. Here we can see that effect depends on GPU architecture and this case should be analyzed in the future.

7) In the future, we plan to migrate to CUDA C partial evaluator,
to reduce specialization overhead, to use advanced register spilling technique and to evaluate our approach on real-world cases.

8) That's all. Thank you for attention.